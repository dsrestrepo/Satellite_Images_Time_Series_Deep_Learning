{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7234ba2",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3172bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b939911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b2514c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = 'Embeddings/embeddings_contrastive_learning_1024features.csv'\n",
    "labels = 'Tabular_data/dengue_tabular.csv'\n",
    "Municipality='Ibagu√©'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6708c26",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f45fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c870d4",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6859f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    #df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "    if Municipality:\n",
    "        print('Obtaining dataframe for the city of Medellin only...')\n",
    "        df = df[df['Municipality Code'] == Municipality]\n",
    "        \n",
    "    df.Date = df.Date.apply(epiweek_from_date)\n",
    "    \n",
    "    df = df.sort_values(by=['Date'])\n",
    "    \n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    if Municipality:\n",
    "        df.drop(columns=['Municipality Code'], inplace=True)\n",
    "        \n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f98f1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataframe for the city of Medellin only...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.914200</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.914200</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.914200</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.914200</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.914200</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>106.780690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.777737</td>\n",
       "      <td>18.379940</td>\n",
       "      <td>105.80126</td>\n",
       "      <td>94.180880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.702873</td>\n",
       "      <td>37.520320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.435520</td>\n",
       "      <td>88.691740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.226227</td>\n",
       "      <td>71.349020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>40.236237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.437395</td>\n",
       "      <td>6.630134</td>\n",
       "      <td>39.60790</td>\n",
       "      <td>34.530903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.765072</td>\n",
       "      <td>14.190913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.860176</td>\n",
       "      <td>31.293947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.149647</td>\n",
       "      <td>26.095455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>110.027596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.642426</td>\n",
       "      <td>18.998648</td>\n",
       "      <td>108.86624</td>\n",
       "      <td>97.187550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.270990</td>\n",
       "      <td>38.915524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.165210</td>\n",
       "      <td>91.725960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.233818</td>\n",
       "      <td>73.739680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>76.441780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.284721</td>\n",
       "      <td>12.792800</td>\n",
       "      <td>75.25716</td>\n",
       "      <td>66.796850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.122963</td>\n",
       "      <td>27.116320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.345436</td>\n",
       "      <td>62.035313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.364012</td>\n",
       "      <td>50.547592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>83.307630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.420490</td>\n",
       "      <td>14.106723</td>\n",
       "      <td>82.17116</td>\n",
       "      <td>73.125850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.778520</td>\n",
       "      <td>29.528585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83.929130</td>\n",
       "      <td>68.462006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.094310</td>\n",
       "      <td>55.446130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows √ó 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0    1          2          3          4          5    6  \\\n",
       "201544   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201545   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201546   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201547   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201548   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "...            ...  ...        ...        ...        ...        ...  ...   \n",
       "201848  106.780690  0.0  32.777737  18.379940  105.80126  94.180880  0.0   \n",
       "201849   40.236237  0.0  12.437395   6.630134   39.60790  34.530903  0.0   \n",
       "201850  110.027596  0.0  33.642426  18.998648  108.86624  97.187550  0.0   \n",
       "201851   76.441780  0.0  23.284721  12.792800   75.25716  66.796850  0.0   \n",
       "201852   83.307630  0.0  25.420490  14.106723   82.17116  73.125850  0.0   \n",
       "\n",
       "                7          8    9  ...        1014       1015  1016  1017  \\\n",
       "201544  28.799873  21.906380  0.0  ...   60.914200  49.309160   0.0   0.0   \n",
       "201545  28.799873  21.906380  0.0  ...   60.914200  49.309160   0.0   0.0   \n",
       "201546  28.799873  21.906380  0.0  ...   60.914200  49.309160   0.0   0.0   \n",
       "201547  28.799873  21.906380  0.0  ...   60.914200  49.309160   0.0   0.0   \n",
       "201548  28.799873  21.906380  0.0  ...   60.914200  49.309160   0.0   0.0   \n",
       "...           ...        ...  ...  ...         ...        ...   ...   ...   \n",
       "201848  51.702873  37.520320  0.0  ...  108.435520  88.691740   0.0   0.0   \n",
       "201849  18.765072  14.190913  0.0  ...   38.860176  31.293947   0.0   0.0   \n",
       "201850  53.270990  38.915524  0.0  ...  112.165210  91.725960   0.0   0.0   \n",
       "201851  36.122963  27.116320  0.0  ...   76.345436  62.035313   0.0   0.0   \n",
       "201852  39.778520  29.528585  0.0  ...   83.929130  68.462006   0.0   0.0   \n",
       "\n",
       "        1018  1019  1020  1021       1022       1023  \n",
       "201544   0.0   0.0   0.0   0.0  17.391779  40.532944  \n",
       "201545   0.0   0.0   0.0   0.0  17.391779  40.532944  \n",
       "201546   0.0   0.0   0.0   0.0  17.391779  40.532944  \n",
       "201547   0.0   0.0   0.0   0.0  17.391779  40.532944  \n",
       "201548   0.0   0.0   0.0   0.0  17.391779  40.532944  \n",
       "...      ...   ...   ...   ...        ...        ...  \n",
       "201848   0.0   0.0   0.0   0.0  33.226227  71.349020  \n",
       "201849   0.0   0.0   0.0   0.0  11.149647  26.095455  \n",
       "201850   0.0   0.0   0.0   0.0  34.233818  73.739680  \n",
       "201851   0.0   0.0   0.0   0.0  22.364012  50.547592  \n",
       "201852   0.0   0.0   0.0   0.0  25.094310  55.446130  \n",
       "\n",
       "[165 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = read_features(path=embeddings, Municipality=Municipality)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f38e20",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b73ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876b83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "        \n",
    "        df.index = pd.to_numeric(df.index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fb96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = read_labels(path=labels, Municipality=Municipality)\n",
    "labels_df = labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83305d1",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96970169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>61.768227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.816113</td>\n",
       "      <td>10.067684</td>\n",
       "      <td>60.65894</td>\n",
       "      <td>53.635525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.799873</td>\n",
       "      <td>21.906380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.309160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.391779</td>\n",
       "      <td>40.532944</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>106.780690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.777737</td>\n",
       "      <td>18.379940</td>\n",
       "      <td>105.80126</td>\n",
       "      <td>94.180880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.702873</td>\n",
       "      <td>37.520320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.691740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.226227</td>\n",
       "      <td>71.349020</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>40.236237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.437395</td>\n",
       "      <td>6.630134</td>\n",
       "      <td>39.60790</td>\n",
       "      <td>34.530903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.765072</td>\n",
       "      <td>14.190913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.293947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.149647</td>\n",
       "      <td>26.095455</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>110.027596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.642426</td>\n",
       "      <td>18.998648</td>\n",
       "      <td>108.86624</td>\n",
       "      <td>97.187550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.270990</td>\n",
       "      <td>38.915524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.725960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.233818</td>\n",
       "      <td>73.739680</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>76.441780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.284721</td>\n",
       "      <td>12.792800</td>\n",
       "      <td>75.25716</td>\n",
       "      <td>66.796850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.122963</td>\n",
       "      <td>27.116320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.035313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.364012</td>\n",
       "      <td>50.547592</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>83.307630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.420490</td>\n",
       "      <td>14.106723</td>\n",
       "      <td>82.17116</td>\n",
       "      <td>73.125850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.778520</td>\n",
       "      <td>29.528585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.462006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.094310</td>\n",
       "      <td>55.446130</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows √ó 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0    1          2          3          4          5    6  \\\n",
       "201544   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201545   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201546   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201547   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "201548   61.768227  0.0  18.816113  10.067684   60.65894  53.635525  0.0   \n",
       "...            ...  ...        ...        ...        ...        ...  ...   \n",
       "201848  106.780690  0.0  32.777737  18.379940  105.80126  94.180880  0.0   \n",
       "201849   40.236237  0.0  12.437395   6.630134   39.60790  34.530903  0.0   \n",
       "201850  110.027596  0.0  33.642426  18.998648  108.86624  97.187550  0.0   \n",
       "201851   76.441780  0.0  23.284721  12.792800   75.25716  66.796850  0.0   \n",
       "201852   83.307630  0.0  25.420490  14.106723   82.17116  73.125850  0.0   \n",
       "\n",
       "                7          8    9  ...       1015  1016  1017  1018  1019  \\\n",
       "201544  28.799873  21.906380  0.0  ...  49.309160   0.0   0.0   0.0   0.0   \n",
       "201545  28.799873  21.906380  0.0  ...  49.309160   0.0   0.0   0.0   0.0   \n",
       "201546  28.799873  21.906380  0.0  ...  49.309160   0.0   0.0   0.0   0.0   \n",
       "201547  28.799873  21.906380  0.0  ...  49.309160   0.0   0.0   0.0   0.0   \n",
       "201548  28.799873  21.906380  0.0  ...  49.309160   0.0   0.0   0.0   0.0   \n",
       "...           ...        ...  ...  ...        ...   ...   ...   ...   ...   \n",
       "201848  51.702873  37.520320  0.0  ...  88.691740   0.0   0.0   0.0   0.0   \n",
       "201849  18.765072  14.190913  0.0  ...  31.293947   0.0   0.0   0.0   0.0   \n",
       "201850  53.270990  38.915524  0.0  ...  91.725960   0.0   0.0   0.0   0.0   \n",
       "201851  36.122963  27.116320  0.0  ...  62.035313   0.0   0.0   0.0   0.0   \n",
       "201852  39.778520  29.528585  0.0  ...  68.462006   0.0   0.0   0.0   0.0   \n",
       "\n",
       "        1020  1021       1022       1023  Labels  \n",
       "201544   0.0   0.0  17.391779  40.532944     132  \n",
       "201545   0.0   0.0  17.391779  40.532944     115  \n",
       "201546   0.0   0.0  17.391779  40.532944     140  \n",
       "201547   0.0   0.0  17.391779  40.532944     112  \n",
       "201548   0.0   0.0  17.391779  40.532944     112  \n",
       "...      ...   ...        ...        ...     ...  \n",
       "201848   0.0   0.0  33.226227  71.349020      22  \n",
       "201849   0.0   0.0  11.149647  26.095455       9  \n",
       "201850   0.0   0.0  34.233818  73.739680      12  \n",
       "201851   0.0   0.0  22.364012  50.547592      16  \n",
       "201852   0.0   0.0  25.094310  55.446130      11  \n",
       "\n",
       "[165 rows x 1025 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc10df6",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12425f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30660bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (132, 1025)\n",
      "The test shape is: (33, 1025)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ecc74",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a15dc293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), scaler=True):\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, scaler=True):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "        \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c5e8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0        -1.0\n",
      "1        -1.0\n",
      "2        -1.0\n",
      "3        -1.0\n",
      "4        -1.0\n",
      "         ... \n",
      "1020     -1.0\n",
      "1021     -1.0\n",
      "1022     -1.0\n",
      "1023     -1.0\n",
      "Labels   -1.0\n",
      "Length: 1025, dtype: float64\n",
      " Max values are: \n",
      "0         1.0\n",
      "1        -1.0\n",
      "2         1.0\n",
      "3         1.0\n",
      "4         1.0\n",
      "         ... \n",
      "1020     -1.0\n",
      "1021     -1.0\n",
      "1022      1.0\n",
      "1023      1.0\n",
      "Labels    1.0\n",
      "Length: 1025, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412044</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.518853</td>\n",
       "      <td>-0.388338</td>\n",
       "      <td>0.643312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412044</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.518853</td>\n",
       "      <td>-0.388338</td>\n",
       "      <td>0.426752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412044</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.518853</td>\n",
       "      <td>-0.388338</td>\n",
       "      <td>0.745223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412044</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.518853</td>\n",
       "      <td>-0.388338</td>\n",
       "      <td>0.388535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412044</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.518853</td>\n",
       "      <td>-0.388338</td>\n",
       "      <td>0.388535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2         3         4         5    6         7  \\\n",
       "201544 -0.349643 -1.0 -0.367727 -0.466723 -0.372761 -0.380103 -1.0 -0.438428   \n",
       "201545 -0.349643 -1.0 -0.367727 -0.466723 -0.372761 -0.380103 -1.0 -0.438428   \n",
       "201546 -0.349643 -1.0 -0.367727 -0.466723 -0.372761 -0.380103 -1.0 -0.438428   \n",
       "201547 -0.349643 -1.0 -0.367727 -0.466723 -0.372761 -0.380103 -1.0 -0.438428   \n",
       "201548 -0.349643 -1.0 -0.367727 -0.466723 -0.372761 -0.380103 -1.0 -0.438428   \n",
       "\n",
       "               8    9  ...      1015  1016  1017  1018  1019  1020  1021  \\\n",
       "201544 -0.359381 -1.0  ... -0.412044  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201545 -0.359381 -1.0  ... -0.412044  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201546 -0.359381 -1.0  ... -0.412044  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201547 -0.359381 -1.0  ... -0.412044  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201548 -0.359381 -1.0  ... -0.412044  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "\n",
       "            1022      1023    Labels  \n",
       "201544 -0.518853 -0.388338  0.643312  \n",
       "201545 -0.518853 -0.388338  0.426752  \n",
       "201546 -0.518853 -0.388338  0.745223  \n",
       "201547 -0.518853 -0.388338  0.388535  \n",
       "201548 -0.518853 -0.388338  0.388535  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2214ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0        -0.934354\n",
      "1        -1.000000\n",
      "2        -0.921211\n",
      "3        -1.002218\n",
      "4        -0.920316\n",
      "            ...   \n",
      "1020     -1.000000\n",
      "1021     -1.000000\n",
      "1022     -1.058290\n",
      "1023     -0.932219\n",
      "Labels   -0.974522\n",
      "Length: 1025, dtype: float64\n",
      " Max values are: \n",
      "0         0.337786\n",
      "1        -1.000000\n",
      "2         0.325328\n",
      "3         0.280800\n",
      "4         0.325462\n",
      "            ...   \n",
      "1020     -1.000000\n",
      "1021     -1.000000\n",
      "1022      0.256944\n",
      "1023      0.318877\n",
      "Labels   -0.643312\n",
      "Length: 1025, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201820</th>\n",
       "      <td>-0.070800</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.088457</td>\n",
       "      <td>-0.162871</td>\n",
       "      <td>-0.091236</td>\n",
       "      <td>-0.096924</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.146969</td>\n",
       "      <td>-0.075745</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124182</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.217552</td>\n",
       "      <td>-0.103601</td>\n",
       "      <td>-0.885350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>-0.655070</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.667870</td>\n",
       "      <td>-0.785196</td>\n",
       "      <td>-0.680751</td>\n",
       "      <td>-0.690570</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.750535</td>\n",
       "      <td>-0.670693</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.728873</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.841691</td>\n",
       "      <td>-0.700669</td>\n",
       "      <td>-0.885350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>-0.034512</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.052641</td>\n",
       "      <td>-0.123214</td>\n",
       "      <td>-0.054633</td>\n",
       "      <td>-0.059581</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.109145</td>\n",
       "      <td>-0.037768</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086426</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.178473</td>\n",
       "      <td>-0.066690</td>\n",
       "      <td>-0.745223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>-0.172582</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.180206</td>\n",
       "      <td>-0.215014</td>\n",
       "      <td>-0.185240</td>\n",
       "      <td>-0.187097</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.214373</td>\n",
       "      <td>-0.180567</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201294</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.240884</td>\n",
       "      <td>-0.190443</td>\n",
       "      <td>-0.808917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>-0.934354</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.921211</td>\n",
       "      <td>-0.841198</td>\n",
       "      <td>-0.895381</td>\n",
       "      <td>-0.935771</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.896906</td>\n",
       "      <td>-0.893931</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.892583</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.715161</td>\n",
       "      <td>-0.918507</td>\n",
       "      <td>-0.643312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1         2         3         4         5    6         7  \\\n",
       "201820 -0.070800 -1.0 -0.088457 -0.162871 -0.091236 -0.096924 -1.0 -0.146969   \n",
       "201821 -0.655070 -1.0 -0.667870 -0.785196 -0.680751 -0.690570 -1.0 -0.750535   \n",
       "201822 -0.034512 -1.0 -0.052641 -0.123214 -0.054633 -0.059581 -1.0 -0.109145   \n",
       "201823 -0.172582 -1.0 -0.180206 -0.215014 -0.185240 -0.187097 -1.0 -0.214373   \n",
       "201824 -0.934354 -1.0 -0.921211 -0.841198 -0.895381 -0.935771 -1.0 -0.896906   \n",
       "\n",
       "               8    9  ...      1015  1016  1017  1018  1019  1020  1021  \\\n",
       "201820 -0.075745 -1.0  ... -0.124182  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201821 -0.670693 -1.0  ... -0.728873  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201822 -0.037768 -1.0  ... -0.086426  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201823 -0.180567 -1.0  ... -0.201294  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "201824 -0.893931 -1.0  ... -0.892583  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "\n",
       "            1022      1023    Labels  \n",
       "201820 -0.217552 -0.103601 -0.885350  \n",
       "201821 -0.841691 -0.700669 -0.885350  \n",
       "201822 -0.178473 -0.066690 -0.745223  \n",
       "201823 -0.240884 -0.190443 -0.808917  \n",
       "201824 -0.715161 -0.918507 -0.643312  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7dec81",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae57078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True, no_autoregressive=None):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        if no_autoregressive:\n",
    "            cols.append(df.shift(i).iloc[:,:-1])\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars-1)]\n",
    "        else:\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df7db957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var2(t-10)</th>\n",
       "      <th>var3(t-10)</th>\n",
       "      <th>var4(t-10)</th>\n",
       "      <th>var5(t-10)</th>\n",
       "      <th>var6(t-10)</th>\n",
       "      <th>var7(t-10)</th>\n",
       "      <th>var8(t-10)</th>\n",
       "      <th>var9(t-10)</th>\n",
       "      <th>var10(t-10)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1016(t)</th>\n",
       "      <th>var1017(t)</th>\n",
       "      <th>var1018(t)</th>\n",
       "      <th>var1019(t)</th>\n",
       "      <th>var1020(t)</th>\n",
       "      <th>var1021(t)</th>\n",
       "      <th>var1022(t)</th>\n",
       "      <th>var1023(t)</th>\n",
       "      <th>var1024(t)</th>\n",
       "      <th>var1025(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444635</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.399208</td>\n",
       "      <td>0.454903</td>\n",
       "      <td>0.541401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.977271</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.941639</td>\n",
       "      <td>-0.983859</td>\n",
       "      <td>0.987261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014250</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.063945</td>\n",
       "      <td>0.031219</td>\n",
       "      <td>0.515924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295909</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.400062</td>\n",
       "      <td>-0.272705</td>\n",
       "      <td>0.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201606</th>\n",
       "      <td>-0.349643</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.367727</td>\n",
       "      <td>-0.466723</td>\n",
       "      <td>-0.372761</td>\n",
       "      <td>-0.380103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.438428</td>\n",
       "      <td>-0.359381</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295909</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.400062</td>\n",
       "      <td>-0.272705</td>\n",
       "      <td>0.477707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201815</th>\n",
       "      <td>-0.113176</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.131262</td>\n",
       "      <td>-0.209810</td>\n",
       "      <td>-0.134218</td>\n",
       "      <td>-0.140931</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.194730</td>\n",
       "      <td>-0.118822</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094383</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.176988</td>\n",
       "      <td>-0.075835</td>\n",
       "      <td>-0.923567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201816</th>\n",
       "      <td>0.524182</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.514909</td>\n",
       "      <td>0.482473</td>\n",
       "      <td>0.514881</td>\n",
       "      <td>0.512282</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.488085</td>\n",
       "      <td>0.520630</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918008</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.922319</td>\n",
       "      <td>-0.909929</td>\n",
       "      <td>-0.974522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201817</th>\n",
       "      <td>0.439760</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.430217</td>\n",
       "      <td>0.391984</td>\n",
       "      <td>0.429475</td>\n",
       "      <td>0.425559</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.435679</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.338668</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.436189</td>\n",
       "      <td>-0.316921</td>\n",
       "      <td>-0.885350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201818</th>\n",
       "      <td>0.062085</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.048184</td>\n",
       "      <td>-0.017455</td>\n",
       "      <td>0.045933</td>\n",
       "      <td>0.039646</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.002730</td>\n",
       "      <td>0.052554</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011623</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.059368</td>\n",
       "      <td>0.027197</td>\n",
       "      <td>-0.910828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201819</th>\n",
       "      <td>-0.359060</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.377105</td>\n",
       "      <td>-0.477359</td>\n",
       "      <td>-0.382350</td>\n",
       "      <td>-0.390090</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.449122</td>\n",
       "      <td>-0.368820</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262262</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.355987</td>\n",
       "      <td>-0.242117</td>\n",
       "      <td>-0.949045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows √ó 11265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  \\\n",
       "201602   -0.349643        -1.0   -0.367727   -0.466723   -0.372761   \n",
       "201603   -0.349643        -1.0   -0.367727   -0.466723   -0.372761   \n",
       "201604   -0.349643        -1.0   -0.367727   -0.466723   -0.372761   \n",
       "201605   -0.349643        -1.0   -0.367727   -0.466723   -0.372761   \n",
       "201606   -0.349643        -1.0   -0.367727   -0.466723   -0.372761   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201815   -0.113176        -1.0   -0.131262   -0.209810   -0.134218   \n",
       "201816    0.524182        -1.0    0.514909    0.482473    0.514881   \n",
       "201817    0.439760        -1.0    0.430217    0.391984    0.429475   \n",
       "201818    0.062085        -1.0    0.048184   -0.017455    0.045933   \n",
       "201819   -0.359060        -1.0   -0.377105   -0.477359   -0.382350   \n",
       "\n",
       "        var6(t-10)  var7(t-10)  var8(t-10)  var9(t-10)  var10(t-10)  ...  \\\n",
       "201602   -0.380103        -1.0   -0.438428   -0.359381         -1.0  ...   \n",
       "201603   -0.380103        -1.0   -0.438428   -0.359381         -1.0  ...   \n",
       "201604   -0.380103        -1.0   -0.438428   -0.359381         -1.0  ...   \n",
       "201605   -0.380103        -1.0   -0.438428   -0.359381         -1.0  ...   \n",
       "201606   -0.380103        -1.0   -0.438428   -0.359381         -1.0  ...   \n",
       "...            ...         ...         ...         ...          ...  ...   \n",
       "201815   -0.140931        -1.0   -0.194730   -0.118822         -1.0  ...   \n",
       "201816    0.512282        -1.0    0.488085    0.520630         -1.0  ...   \n",
       "201817    0.425559        -1.0    0.398230    0.435679         -1.0  ...   \n",
       "201818    0.039646        -1.0   -0.002730    0.052554         -1.0  ...   \n",
       "201819   -0.390090        -1.0   -0.449122   -0.368820         -1.0  ...   \n",
       "\n",
       "        var1016(t)  var1017(t)  var1018(t)  var1019(t)  var1020(t)  \\\n",
       "201602    0.444635        -1.0        -1.0        -1.0        -1.0   \n",
       "201603   -0.977271        -1.0        -1.0        -1.0        -1.0   \n",
       "201604    0.014250        -1.0        -1.0        -1.0        -1.0   \n",
       "201605   -0.295909        -1.0        -1.0        -1.0        -1.0   \n",
       "201606   -0.295909        -1.0        -1.0        -1.0        -1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201815   -0.094383        -1.0        -1.0        -1.0        -1.0   \n",
       "201816   -0.918008        -1.0        -1.0        -1.0        -1.0   \n",
       "201817   -0.338668        -1.0        -1.0        -1.0        -1.0   \n",
       "201818    0.011623        -1.0        -1.0        -1.0        -1.0   \n",
       "201819   -0.262262        -1.0        -1.0        -1.0        -1.0   \n",
       "\n",
       "        var1021(t)  var1022(t)  var1023(t)  var1024(t)  var1025(t)  \n",
       "201602        -1.0        -1.0    0.399208    0.454903    0.541401  \n",
       "201603        -1.0        -1.0   -0.941639   -0.983859    0.987261  \n",
       "201604        -1.0        -1.0   -0.063945    0.031219    0.515924  \n",
       "201605        -1.0        -1.0   -0.400062   -0.272705    0.707006  \n",
       "201606        -1.0        -1.0   -0.400062   -0.272705    0.477707  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "201815        -1.0        -1.0   -0.176988   -0.075835   -0.923567  \n",
       "201816        -1.0        -1.0   -0.922319   -0.909929   -0.974522  \n",
       "201817        -1.0        -1.0   -0.436189   -0.316921   -0.885350  \n",
       "201818        -1.0        -1.0   -0.059368    0.027197   -0.910828  \n",
       "201819        -1.0        -1.0   -0.355987   -0.242117   -0.949045  \n",
       "\n",
       "[122 rows x 11265 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "no_autoregressive = True\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "test = series_to_supervised(test_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "\n",
    "DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f7d0e",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9eb5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (Cases and media cloud)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use Covid cases in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-1])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70421ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (122, 10240)\n",
      "The shape of the labels is (122, 1)\n",
      "Test:\n",
      "The shape of the features is (23, 10240)\n",
      "The shape of the labels is (23, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2c020a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d7b84fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features, no_autoregressive=None):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    if no_autoregressive:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features-1))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features-1))\n",
    "    \n",
    "    else:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9737de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (122, 10240)\n",
      "The test shape is (23, 10240)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (122, 10, 1024)\n",
      "The test shape is (23, 10, 1024)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features, no_autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1ef8c9",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b28eab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    epsilon = 0.1\n",
    "    summ = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
    "    smape = K.abs(y_pred - y_true) / summ * 2.0\n",
    "    return smape\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "        tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "        smape\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51430baf",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3485d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "521e9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, plot=None, epochs=50):\n",
    "    if monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80ac6d",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95523d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "def test_model(model, test_X, test_y, scaler, rnn = None):\n",
    "    \n",
    "    # If model is a classical machine learning model and test_X is a 3D tensor, then convert to 2D\n",
    "    if not rnn and (len(test_X.shape) == 3):\n",
    "        test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "    \n",
    "    # do the prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    # Invert scaling for forecast\n",
    "    # Inverse Scaler\n",
    "    \n",
    "    # Predicted\n",
    "    if not rnn:\n",
    "        yhat = yhat.reshape(-1, 1)\n",
    "        \n",
    "    if not scaler:\n",
    "        return yhat, test_y\n",
    "    \n",
    "    inv_yhat = scaler.inverse_transform(yhat)\n",
    "    \n",
    "    # Real:\n",
    "    inv_y = scaler.inverse_transform(test_y)\n",
    "    \n",
    "    return inv_yhat, inv_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adae66a",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "$$\n",
    "MAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n}\\left |\\frac{x_i-y_i}{y_t}\\right|\n",
    "$$\n",
    "\n",
    "MAPE has a problem if there are zeros in the test data, so other metrics can be explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ae6ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Test MAPE: %.3f' % mape)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8521b",
   "metadata": {},
   "source": [
    "### Symmetric Mean Absolute Percentage Error (sMAPE)\n",
    "\n",
    "$$\n",
    "sMAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n} \\frac{|x_i-y_i|}{|x_i|+|y_t|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ad32397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    smape = 1/len(y_true) * np.sum(2 * np.abs(y_pred-y_true) / (np.abs(y_true) + np.abs(y_pred))*100)\n",
    "    print('Test sMAPE: %.3f' % smape)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d0dfb",
   "metadata": {},
   "source": [
    "### Mean Absoulte Error (MAE)\n",
    "$$\n",
    "RMSE = \\sqrt{(\\frac{1}{n})\\sum_{i=1}^{n}(x_i-y_i)^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56336064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7851e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(inv_y, inv_yhat, model_name = ''):\n",
    "    data_predict = inv_yhat  ## predicted target cases\n",
    "    dataY_plot = inv_y  ##  real test-target cases\n",
    "\n",
    "    data_predict = data_predict.reshape(len(data_predict), 1)\n",
    "    dataY_plot = dataY_plot.reshape(len(dataY_plot), 1)\n",
    "\n",
    "    plt.plot(dataY_plot, label = 'actual')\n",
    "    plt.plot(data_predict, label = 'predicted')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.suptitle(f'Time-Series Prediction with {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff32511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_X, test_y, scaler):\n",
    "    stored_results = {}\n",
    "    \n",
    "    inv_yhat_lstm, inv_y_lstm = test_model(model=model, test_X=test_X, test_y=test_y, scaler=y_scaler, rnn = True)\n",
    "    stored_results['mape'] = mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['smape'] = symmetric_mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['rmse'] = root_mean_squared_error(inv_y_lstm, inv_yhat_lstm)\n",
    "\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f20f03b",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4108cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With LSTM:\n",
    "#print(f'The scalers are: {scalers.keys()}')\n",
    "y_scaler = scalers['scaler_Labels']\n",
    "\n",
    "def calculate_mean_std():\n",
    "    \n",
    "    metrics = {\n",
    "        \"rmse\": [],\n",
    "        \"mape\": [],\n",
    "        \"smape\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor)\n",
    "        stored_results = evaluate(model, test_X, test_y, y_scaler)\n",
    "        print(stored_results)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de7f9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 3s - loss: 1.3981 - rmse: 1.1824 - mape: 121.7983 - smape: 0.8671 - val_loss: 0.0537 - val_rmse: 0.2318 - val_mape: 25.0512 - val_smape: 0.2708\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.3362 - rmse: 0.5799 - mape: 71.4442 - smape: 0.8343 - val_loss: 0.0108 - val_rmse: 0.1040 - val_mape: 10.7108 - val_smape: 0.0950\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.1910 - rmse: 0.4370 - mape: 47.6743 - smape: 0.2871 - val_loss: 0.0095 - val_rmse: 0.0976 - val_mape: 9.9280 - val_smape: 0.0993\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1829 - rmse: 0.4276 - mape: 50.1839 - smape: 0.4070 - val_loss: 0.0437 - val_rmse: 0.2089 - val_mape: 22.5688 - val_smape: 0.2406\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1217 - rmse: 0.3488 - mape: 36.2427 - smape: 0.2867 - val_loss: 0.0037 - val_rmse: 0.0607 - val_mape: 5.8492 - val_smape: 0.0568\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1501 - rmse: 0.3875 - mape: 41.1339 - smape: 0.2817 - val_loss: 0.0111 - val_rmse: 0.1056 - val_mape: 10.8278 - val_smape: 0.1088\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1484 - rmse: 0.3853 - mape: 42.4591 - smape: 0.3223 - val_loss: 0.0183 - val_rmse: 0.1352 - val_mape: 14.0478 - val_smape: 0.1437\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1359 - rmse: 0.3686 - mape: 39.3086 - smape: 0.2940 - val_loss: 0.0091 - val_rmse: 0.0952 - val_mape: 9.5887 - val_smape: 0.0958\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1402 - rmse: 0.3745 - mape: 39.9237 - smape: 0.2946 - val_loss: 0.0103 - val_rmse: 0.1014 - val_mape: 10.2900 - val_smape: 0.1032\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1389 - rmse: 0.3728 - mape: 40.5069 - smape: 0.2980 - val_loss: 0.0115 - val_rmse: 0.1070 - val_mape: 10.9180 - val_smape: 0.1099\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1421 - rmse: 0.3769 - mape: 40.9594 - smape: 0.3027 - val_loss: 0.0113 - val_rmse: 0.1065 - val_mape: 10.8383 - val_smape: 0.1091\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1388 - rmse: 0.3726 - mape: 40.3198 - smape: 0.3027 - val_loss: 0.0100 - val_rmse: 0.1001 - val_mape: 10.0931 - val_smape: 0.1012\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1431 - rmse: 0.3783 - mape: 40.9206 - smape: 0.3018 - val_loss: 0.0103 - val_rmse: 0.1013 - val_mape: 10.1928 - val_smape: 0.1023\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1384 - rmse: 0.3720 - mape: 40.9942 - smape: 0.3052 - val_loss: 0.0097 - val_rmse: 0.0982 - val_mape: 9.7862 - val_smape: 0.0981\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1384 - rmse: 0.3720 - mape: 41.0170 - smape: 0.3044 - val_loss: 0.0095 - val_rmse: 0.0975 - val_mape: 9.6340 - val_smape: 0.0965\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1359 - rmse: 0.3686 - mape: 40.5244 - smape: 0.2999 - val_loss: 0.0095 - val_rmse: 0.0973 - val_mape: 9.5459 - val_smape: 0.0957\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1408 - rmse: 0.3752 - mape: 41.4423 - smape: 0.3072 - val_loss: 0.0116 - val_rmse: 0.1079 - val_mape: 10.7292 - val_smape: 0.1083\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1331 - rmse: 0.3649 - mape: 39.8208 - smape: 0.3007 - val_loss: 0.0086 - val_rmse: 0.0925 - val_mape: 8.9309 - val_smape: 0.0893\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1341 - rmse: 0.3662 - mape: 40.3780 - smape: 0.3006 - val_loss: 0.0091 - val_rmse: 0.0954 - val_mape: 9.1724 - val_smape: 0.0919\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1351 - rmse: 0.3675 - mape: 40.3337 - smape: 0.3018 - val_loss: 0.0109 - val_rmse: 0.1046 - val_mape: 10.1680 - val_smape: 0.1025\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1313 - rmse: 0.3623 - mape: 39.4921 - smape: 0.2972 - val_loss: 0.0089 - val_rmse: 0.0946 - val_mape: 9.0581 - val_smape: 0.0907\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1340 - rmse: 0.3660 - mape: 39.9655 - smape: 0.2979 - val_loss: 0.0099 - val_rmse: 0.0997 - val_mape: 9.5333 - val_smape: 0.0959\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1339 - rmse: 0.3659 - mape: 39.8363 - smape: 0.3031 - val_loss: 0.0096 - val_rmse: 0.0977 - val_mape: 9.3141 - val_smape: 0.0936\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1349 - rmse: 0.3673 - mape: 40.2825 - smape: 0.3039 - val_loss: 0.0112 - val_rmse: 0.1056 - val_mape: 10.1334 - val_smape: 0.1023\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1356 - rmse: 0.3683 - mape: 39.8461 - smape: 0.3005 - val_loss: 0.0093 - val_rmse: 0.0963 - val_mape: 9.1345 - val_smape: 0.0917\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test MAPE: 46.404\n",
      "Test sMAPE: 34.389\n",
      "Test RMSE: 4.764\n",
      "{'mape': 46.4040937484034, 'smape': 34.38876702222631, 'rmse': 4.763772086830826}\n",
      "Epoch 1/50\n",
      "8/8 - 2s - loss: 1.8537 - rmse: 1.3615 - mape: 122.9800 - smape: 0.8580 - val_loss: 0.1138 - val_rmse: 0.3374 - val_mape: 37.1988 - val_smape: 0.4289\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.2404 - rmse: 0.4903 - mape: 57.5420 - smape: 0.6508 - val_loss: 0.2318 - val_rmse: 0.4814 - val_mape: 54.0269 - val_smape: 0.4057\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.3928 - rmse: 0.6267 - mape: 80.6747 - smape: 0.5368 - val_loss: 0.1150 - val_rmse: 0.3391 - val_mape: 37.3860 - val_smape: 0.4315\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1133 - rmse: 0.3366 - mape: 36.7107 - smape: 0.3412 - val_loss: 0.0137 - val_rmse: 0.1172 - val_mape: 12.2382 - val_smape: 0.1079\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1806 - rmse: 0.4249 - mape: 47.3976 - smape: 0.3075 - val_loss: 0.0138 - val_rmse: 0.1175 - val_mape: 11.9652 - val_smape: 0.1213\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1579 - rmse: 0.3974 - mape: 45.7546 - smape: 0.3681 - val_loss: 0.0124 - val_rmse: 0.1112 - val_mape: 11.2451 - val_smape: 0.1136\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1331 - rmse: 0.3649 - mape: 38.5338 - smape: 0.2774 - val_loss: 0.0031 - val_rmse: 0.0556 - val_mape: 4.9459 - val_smape: 0.0476\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1528 - rmse: 0.3909 - mape: 44.0196 - smape: 0.3200 - val_loss: 0.0105 - val_rmse: 0.1024 - val_mape: 10.1923 - val_smape: 0.1025\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1441 - rmse: 0.3796 - mape: 41.9853 - smape: 0.3173 - val_loss: 0.0062 - val_rmse: 0.0788 - val_mape: 7.6201 - val_smape: 0.0753\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1435 - rmse: 0.3788 - mape: 41.4582 - smape: 0.3015 - val_loss: 0.0064 - val_rmse: 0.0801 - val_mape: 7.7217 - val_smape: 0.0764\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1459 - rmse: 0.3819 - mape: 42.2696 - smape: 0.3150 - val_loss: 0.0072 - val_rmse: 0.0846 - val_mape: 8.1565 - val_smape: 0.0810\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1409 - rmse: 0.3753 - mape: 40.9247 - smape: 0.2997 - val_loss: 0.0061 - val_rmse: 0.0784 - val_mape: 7.4647 - val_smape: 0.0738\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1441 - rmse: 0.3796 - mape: 42.3343 - smape: 0.3141 - val_loss: 0.0068 - val_rmse: 0.0823 - val_mape: 7.8528 - val_smape: 0.0779\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1429 - rmse: 0.3780 - mape: 41.7380 - smape: 0.3090 - val_loss: 0.0065 - val_rmse: 0.0807 - val_mape: 7.6473 - val_smape: 0.0757\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1412 - rmse: 0.3758 - mape: 41.5929 - smape: 0.3110 - val_loss: 0.0060 - val_rmse: 0.0776 - val_mape: 7.2577 - val_smape: 0.0717\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1408 - rmse: 0.3753 - mape: 41.9474 - smape: 0.3101 - val_loss: 0.0061 - val_rmse: 0.0784 - val_mape: 7.2977 - val_smape: 0.0721\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1400 - rmse: 0.3742 - mape: 41.6416 - smape: 0.3083 - val_loss: 0.0066 - val_rmse: 0.0812 - val_mape: 7.5823 - val_smape: 0.0751\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1377 - rmse: 0.3710 - mape: 41.1314 - smape: 0.3079 - val_loss: 0.0066 - val_rmse: 0.0814 - val_mape: 7.5696 - val_smape: 0.0750\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1420 - rmse: 0.3769 - mape: 42.1985 - smape: 0.3130 - val_loss: 0.0073 - val_rmse: 0.0852 - val_mape: 7.9027 - val_smape: 0.0786\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1366 - rmse: 0.3696 - mape: 41.3847 - smape: 0.3104 - val_loss: 0.0060 - val_rmse: 0.0772 - val_mape: 6.8874 - val_smape: 0.0680\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1371 - rmse: 0.3702 - mape: 41.6959 - smape: 0.3081 - val_loss: 0.0071 - val_rmse: 0.0841 - val_mape: 7.6787 - val_smape: 0.0763\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1353 - rmse: 0.3678 - mape: 41.3572 - smape: 0.3125 - val_loss: 0.0069 - val_rmse: 0.0829 - val_mape: 7.4711 - val_smape: 0.0742\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1397 - rmse: 0.3738 - mape: 42.1559 - smape: 0.3156 - val_loss: 0.0070 - val_rmse: 0.0839 - val_mape: 7.5970 - val_smape: 0.0755\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1362 - rmse: 0.3691 - mape: 41.3675 - smape: 0.3123 - val_loss: 0.0067 - val_rmse: 0.0822 - val_mape: 7.3868 - val_smape: 0.0733\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1351 - rmse: 0.3676 - mape: 41.4959 - smape: 0.3125 - val_loss: 0.0066 - val_rmse: 0.0812 - val_mape: 7.2394 - val_smape: 0.0718\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.1364 - rmse: 0.3693 - mape: 41.1363 - smape: 0.3095 - val_loss: 0.0072 - val_rmse: 0.0849 - val_mape: 7.6027 - val_smape: 0.0757\n",
      "Epoch 27/50\n",
      "8/8 - 0s - loss: 0.1349 - rmse: 0.3673 - mape: 41.3992 - smape: 0.3140 - val_loss: 0.0080 - val_rmse: 0.0895 - val_mape: 8.0644 - val_smape: 0.0806\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Test MAPE: 38.230\n",
      "Test sMAPE: 29.407\n",
      "Test RMSE: 4.364\n",
      "{'mape': 38.22984153517785, 'smape': 29.40730103213336, 'rmse': 4.3637125382018}\n",
      "Epoch 1/50\n",
      "8/8 - 2s - loss: 0.5765 - rmse: 0.7593 - mape: 82.6263 - smape: 0.7616 - val_loss: 0.1441 - val_rmse: 0.3795 - val_mape: 42.5302 - val_smape: 0.3335\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.3851 - rmse: 0.6205 - mape: 78.2306 - smape: 0.5974 - val_loss: 0.0924 - val_rmse: 0.3039 - val_mape: 33.3896 - val_smape: 0.3768\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.1022 - rmse: 0.3197 - mape: 31.3823 - smape: 0.2568 - val_loss: 0.0107 - val_rmse: 0.1033 - val_mape: 10.6143 - val_smape: 0.0942\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1952 - rmse: 0.4418 - mape: 50.1390 - smape: 0.3340 - val_loss: 0.0309 - val_rmse: 0.1757 - val_mape: 18.7281 - val_smape: 0.1959\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1464 - rmse: 0.3826 - mape: 43.1796 - smape: 0.3540 - val_loss: 0.0117 - val_rmse: 0.1080 - val_mape: 11.1065 - val_smape: 0.1118\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1364 - rmse: 0.3693 - mape: 38.1198 - smape: 0.2701 - val_loss: 0.0043 - val_rmse: 0.0658 - val_mape: 6.3370 - val_smape: 0.0620\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1554 - rmse: 0.3942 - mape: 43.8257 - smape: 0.3202 - val_loss: 0.0137 - val_rmse: 0.1171 - val_mape: 12.0496 - val_smape: 0.1220\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1402 - rmse: 0.3745 - mape: 40.9497 - smape: 0.3110 - val_loss: 0.0072 - val_rmse: 0.0850 - val_mape: 8.3668 - val_smape: 0.0831\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1416 - rmse: 0.3763 - mape: 41.5393 - smape: 0.3062 - val_loss: 0.0066 - val_rmse: 0.0811 - val_mape: 7.9311 - val_smape: 0.0786\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1491 - rmse: 0.3861 - mape: 42.4164 - smape: 0.3125 - val_loss: 0.0089 - val_rmse: 0.0942 - val_mape: 9.3069 - val_smape: 0.0931\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1430 - rmse: 0.3782 - mape: 41.1548 - smape: 0.3056 - val_loss: 0.0072 - val_rmse: 0.0848 - val_mape: 8.2504 - val_smape: 0.0820\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1422 - rmse: 0.3771 - mape: 41.6649 - smape: 0.3056 - val_loss: 0.0071 - val_rmse: 0.0841 - val_mape: 8.1536 - val_smape: 0.0810\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1483 - rmse: 0.3851 - mape: 42.2584 - smape: 0.3148 - val_loss: 0.0093 - val_rmse: 0.0966 - val_mape: 9.4439 - val_smape: 0.0947\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1387 - rmse: 0.3725 - mape: 40.6693 - smape: 0.3036 - val_loss: 0.0069 - val_rmse: 0.0828 - val_mape: 7.9603 - val_smape: 0.0790\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1423 - rmse: 0.3772 - mape: 41.9797 - smape: 0.3091 - val_loss: 0.0087 - val_rmse: 0.0932 - val_mape: 8.9973 - val_smape: 0.0900\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1398 - rmse: 0.3738 - mape: 41.4015 - smape: 0.3099 - val_loss: 0.0078 - val_rmse: 0.0881 - val_mape: 8.4458 - val_smape: 0.0842\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1418 - rmse: 0.3766 - mape: 41.6907 - smape: 0.3076 - val_loss: 0.0077 - val_rmse: 0.0879 - val_mape: 8.4008 - val_smape: 0.0838\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1357 - rmse: 0.3683 - mape: 40.6203 - smape: 0.3055 - val_loss: 0.0078 - val_rmse: 0.0883 - val_mape: 8.4038 - val_smape: 0.0838\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1387 - rmse: 0.3725 - mape: 41.3636 - smape: 0.3115 - val_loss: 0.0077 - val_rmse: 0.0878 - val_mape: 8.2959 - val_smape: 0.0827\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1404 - rmse: 0.3746 - mape: 41.7996 - smape: 0.3113 - val_loss: 0.0073 - val_rmse: 0.0855 - val_mape: 7.9754 - val_smape: 0.0794\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1377 - rmse: 0.3711 - mape: 41.4096 - smape: 0.3122 - val_loss: 0.0084 - val_rmse: 0.0914 - val_mape: 8.5583 - val_smape: 0.0856\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1362 - rmse: 0.3690 - mape: 40.9243 - smape: 0.3074 - val_loss: 0.0084 - val_rmse: 0.0918 - val_mape: 8.5906 - val_smape: 0.0860\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1340 - rmse: 0.3660 - mape: 40.1983 - smape: 0.3070 - val_loss: 0.0064 - val_rmse: 0.0801 - val_mape: 7.2349 - val_smape: 0.0718\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1348 - rmse: 0.3671 - mape: 40.3377 - smape: 0.3060 - val_loss: 0.0071 - val_rmse: 0.0845 - val_mape: 7.6317 - val_smape: 0.0760\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1304 - rmse: 0.3612 - mape: 39.9638 - smape: 0.3042 - val_loss: 0.0074 - val_rmse: 0.0858 - val_mape: 7.5689 - val_smape: 0.0756\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.1329 - rmse: 0.3646 - mape: 40.0742 - smape: 0.3028 - val_loss: 0.0078 - val_rmse: 0.0884 - val_mape: 7.5785 - val_smape: 0.0759\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test MAPE: 50.892\n",
      "Test sMAPE: 36.671\n",
      "Test RMSE: 5.165\n",
      "{'mape': 50.89228727504141, 'smape': 36.67079322006547, 'rmse': 5.165224098624506}\n",
      "Epoch 1/50\n",
      "8/8 - 3s - loss: 1.3507 - rmse: 1.1622 - mape: 107.7529 - smape: 0.8149 - val_loss: 0.1141 - val_rmse: 0.3378 - val_mape: 37.1588 - val_smape: 0.4289\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.1440 - rmse: 0.3795 - mape: 43.1972 - smape: 0.4236 - val_loss: 0.1122 - val_rmse: 0.3350 - val_mape: 37.3870 - val_smape: 0.2990\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.3135 - rmse: 0.5599 - mape: 70.5333 - smape: 0.4904 - val_loss: 0.0770 - val_rmse: 0.2775 - val_mape: 30.3258 - val_smape: 0.3369\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1150 - rmse: 0.3392 - mape: 36.2849 - smape: 0.3092 - val_loss: 0.0067 - val_rmse: 0.0821 - val_mape: 7.8605 - val_smape: 0.0704\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1795 - rmse: 0.4237 - mape: 48.0799 - smape: 0.3171 - val_loss: 0.0160 - val_rmse: 0.1265 - val_mape: 12.7789 - val_smape: 0.1304\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1488 - rmse: 0.3858 - mape: 44.0168 - smape: 0.3502 - val_loss: 0.0105 - val_rmse: 0.1023 - val_mape: 10.0492 - val_smape: 0.1011\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1376 - rmse: 0.3710 - mape: 39.9952 - smape: 0.2901 - val_loss: 0.0044 - val_rmse: 0.0663 - val_mape: 6.0615 - val_smape: 0.0592\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1548 - rmse: 0.3934 - mape: 44.4089 - smape: 0.3257 - val_loss: 0.0119 - val_rmse: 0.1090 - val_mape: 10.7579 - val_smape: 0.1087\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1335 - rmse: 0.3654 - mape: 40.3988 - smape: 0.3059 - val_loss: 0.0055 - val_rmse: 0.0743 - val_mape: 6.9506 - val_smape: 0.0685\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1508 - rmse: 0.3884 - mape: 43.2309 - smape: 0.3142 - val_loss: 0.0100 - val_rmse: 0.1001 - val_mape: 9.7297 - val_smape: 0.0978\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1382 - rmse: 0.3717 - mape: 41.1398 - smape: 0.3089 - val_loss: 0.0069 - val_rmse: 0.0830 - val_mape: 7.8563 - val_smape: 0.0780\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1444 - rmse: 0.3799 - mape: 42.0779 - smape: 0.3091 - val_loss: 0.0070 - val_rmse: 0.0834 - val_mape: 7.8623 - val_smape: 0.0781\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1421 - rmse: 0.3770 - mape: 41.7518 - smape: 0.3104 - val_loss: 0.0077 - val_rmse: 0.0878 - val_mape: 8.2559 - val_smape: 0.0823\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1414 - rmse: 0.3760 - mape: 41.9657 - smape: 0.3116 - val_loss: 0.0080 - val_rmse: 0.0897 - val_mape: 8.4158 - val_smape: 0.0840\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1413 - rmse: 0.3758 - mape: 41.7413 - smape: 0.3124 - val_loss: 0.0072 - val_rmse: 0.0851 - val_mape: 7.8988 - val_smape: 0.0786\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1442 - rmse: 0.3797 - mape: 42.6011 - smape: 0.3140 - val_loss: 0.0086 - val_rmse: 0.0928 - val_mape: 8.7332 - val_smape: 0.0874\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1403 - rmse: 0.3746 - mape: 41.4091 - smape: 0.3092 - val_loss: 0.0073 - val_rmse: 0.0857 - val_mape: 7.9195 - val_smape: 0.0788\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1396 - rmse: 0.3736 - mape: 41.5313 - smape: 0.3090 - val_loss: 0.0077 - val_rmse: 0.0879 - val_mape: 8.1782 - val_smape: 0.0815\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1419 - rmse: 0.3767 - mape: 42.4174 - smape: 0.3190 - val_loss: 0.0087 - val_rmse: 0.0935 - val_mape: 8.7736 - val_smape: 0.0879\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1387 - rmse: 0.3725 - mape: 41.0703 - smape: 0.3069 - val_loss: 0.0077 - val_rmse: 0.0878 - val_mape: 8.1389 - val_smape: 0.0811\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1424 - rmse: 0.3773 - mape: 42.5516 - smape: 0.3184 - val_loss: 0.0093 - val_rmse: 0.0967 - val_mape: 9.1029 - val_smape: 0.0914\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1359 - rmse: 0.3687 - mape: 41.0510 - smape: 0.3059 - val_loss: 0.0083 - val_rmse: 0.0912 - val_mape: 8.5201 - val_smape: 0.0852\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1366 - rmse: 0.3696 - mape: 41.4257 - smape: 0.3089 - val_loss: 0.0082 - val_rmse: 0.0908 - val_mape: 8.4673 - val_smape: 0.0846\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1381 - rmse: 0.3716 - mape: 41.4550 - smape: 0.3112 - val_loss: 0.0079 - val_rmse: 0.0890 - val_mape: 8.2258 - val_smape: 0.0821\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1354 - rmse: 0.3680 - mape: 40.1732 - smape: 0.3018 - val_loss: 0.0075 - val_rmse: 0.0866 - val_mape: 7.9389 - val_smape: 0.0791\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.1344 - rmse: 0.3666 - mape: 40.7384 - smape: 0.3073 - val_loss: 0.0079 - val_rmse: 0.0891 - val_mape: 8.1731 - val_smape: 0.0816\n",
      "Epoch 27/50\n",
      "8/8 - 0s - loss: 0.1363 - rmse: 0.3691 - mape: 40.8836 - smape: 0.3089 - val_loss: 0.0083 - val_rmse: 0.0912 - val_mape: 8.3110 - val_smape: 0.0831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Test MAPE: 47.735\n",
      "Test sMAPE: 34.435\n",
      "Test RMSE: 5.206\n",
      "{'mape': 47.735355407183874, 'smape': 34.43516320186857, 'rmse': 5.205691428556294}\n",
      "Epoch 1/50\n",
      "8/8 - 2s - loss: 1.5832 - rmse: 1.2582 - mape: 114.1440 - smape: 0.8298 - val_loss: 0.1356 - val_rmse: 0.3682 - val_mape: 40.6917 - val_smape: 0.4786\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.2198 - rmse: 0.4688 - mape: 54.9957 - smape: 0.6193 - val_loss: 0.2004 - val_rmse: 0.4477 - val_mape: 50.1762 - val_smape: 0.3822\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.3511 - rmse: 0.5926 - mape: 74.7105 - smape: 0.4794 - val_loss: 0.1080 - val_rmse: 0.3286 - val_mape: 36.2023 - val_smape: 0.4150\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1353 - rmse: 0.3678 - mape: 42.3061 - smape: 0.3953 - val_loss: 0.0023 - val_rmse: 0.0484 - val_mape: 4.1942 - val_smape: 0.0395\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1508 - rmse: 0.3884 - mape: 40.9519 - smape: 0.2655 - val_loss: 0.0047 - val_rmse: 0.0682 - val_mape: 6.5361 - val_smape: 0.0640\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1643 - rmse: 0.4053 - mape: 46.2175 - smape: 0.3501 - val_loss: 0.0280 - val_rmse: 0.1673 - val_mape: 17.6961 - val_smape: 0.1843\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1327 - rmse: 0.3643 - mape: 39.7686 - smape: 0.3120 - val_loss: 0.0066 - val_rmse: 0.0813 - val_mape: 7.9267 - val_smape: 0.0785\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1377 - rmse: 0.3711 - mape: 39.2583 - smape: 0.2778 - val_loss: 0.0073 - val_rmse: 0.0852 - val_mape: 8.3417 - val_smape: 0.0829\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1506 - rmse: 0.3881 - mape: 43.5459 - smape: 0.3223 - val_loss: 0.0153 - val_rmse: 0.1238 - val_mape: 12.6363 - val_smape: 0.1286\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1384 - rmse: 0.3720 - mape: 40.6031 - smape: 0.3071 - val_loss: 0.0090 - val_rmse: 0.0947 - val_mape: 9.3438 - val_smape: 0.0935\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1371 - rmse: 0.3703 - mape: 40.4985 - smape: 0.2971 - val_loss: 0.0084 - val_rmse: 0.0916 - val_mape: 8.9888 - val_smape: 0.0897\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1459 - rmse: 0.3820 - mape: 42.1981 - smape: 0.3128 - val_loss: 0.0103 - val_rmse: 0.1013 - val_mape: 10.0112 - val_smape: 0.1006\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1407 - rmse: 0.3751 - mape: 40.7792 - smape: 0.3053 - val_loss: 0.0082 - val_rmse: 0.0904 - val_mape: 8.7930 - val_smape: 0.0877\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1391 - rmse: 0.3729 - mape: 40.7558 - smape: 0.2997 - val_loss: 0.0086 - val_rmse: 0.0928 - val_mape: 9.0253 - val_smape: 0.0902\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1417 - rmse: 0.3764 - mape: 41.5078 - smape: 0.3111 - val_loss: 0.0101 - val_rmse: 0.1003 - val_mape: 9.8220 - val_smape: 0.0987\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1396 - rmse: 0.3736 - mape: 40.8770 - smape: 0.3062 - val_loss: 0.0083 - val_rmse: 0.0910 - val_mape: 8.7864 - val_smape: 0.0878\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1410 - rmse: 0.3755 - mape: 41.4421 - smape: 0.3066 - val_loss: 0.0081 - val_rmse: 0.0901 - val_mape: 8.6327 - val_smape: 0.0862\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1406 - rmse: 0.3750 - mape: 41.4930 - smape: 0.3099 - val_loss: 0.0095 - val_rmse: 0.0974 - val_mape: 9.3902 - val_smape: 0.0943\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1420 - rmse: 0.3768 - mape: 41.7341 - smape: 0.3136 - val_loss: 0.0098 - val_rmse: 0.0989 - val_mape: 9.5235 - val_smape: 0.0957\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1334 - rmse: 0.3652 - mape: 40.2909 - smape: 0.3002 - val_loss: 0.0083 - val_rmse: 0.0910 - val_mape: 8.6666 - val_smape: 0.0866\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1381 - rmse: 0.3716 - mape: 41.0563 - smape: 0.3046 - val_loss: 0.0087 - val_rmse: 0.0935 - val_mape: 8.8873 - val_smape: 0.0890\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1376 - rmse: 0.3710 - mape: 40.7148 - smape: 0.3060 - val_loss: 0.0082 - val_rmse: 0.0906 - val_mape: 8.5641 - val_smape: 0.0856\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1311 - rmse: 0.3621 - mape: 39.4049 - smape: 0.2984 - val_loss: 0.0074 - val_rmse: 0.0859 - val_mape: 8.0217 - val_smape: 0.0799\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1382 - rmse: 0.3717 - mape: 40.9405 - smape: 0.3105 - val_loss: 0.0095 - val_rmse: 0.0975 - val_mape: 9.1993 - val_smape: 0.0925\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f43b4640b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test MAPE: 30.101\n",
      "Test sMAPE: 25.368\n",
      "Test RMSE: 3.803\n",
      "{'mape': 30.100850641338837, 'smape': 25.368460265909757, 'rmse': 3.8027707773010695}\n",
      "Epoch 1/50\n",
      "8/8 - 2s - loss: 0.9774 - rmse: 0.9886 - mape: 98.5764 - smape: 0.9358 - val_loss: 0.1992 - val_rmse: 0.4464 - val_mape: 50.0253 - val_smape: 0.3811\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.4000 - rmse: 0.6325 - mape: 79.5527 - smape: 0.5678 - val_loss: 0.0583 - val_rmse: 0.2414 - val_mape: 26.2202 - val_smape: 0.2850\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.1095 - rmse: 0.3309 - mape: 30.9801 - smape: 0.2372 - val_loss: 0.0079 - val_rmse: 0.0889 - val_mape: 8.7758 - val_smape: 0.0783\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1992 - rmse: 0.4463 - mape: 50.9722 - smape: 0.3534 - val_loss: 0.0308 - val_rmse: 0.1754 - val_mape: 18.6871 - val_smape: 0.1955\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1403 - rmse: 0.3745 - mape: 41.1335 - smape: 0.3277 - val_loss: 0.0045 - val_rmse: 0.0670 - val_mape: 6.4861 - val_smape: 0.0635\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1489 - rmse: 0.3859 - mape: 40.9900 - smape: 0.2840 - val_loss: 0.0066 - val_rmse: 0.0811 - val_mape: 7.9873 - val_smape: 0.0791\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1595 - rmse: 0.3993 - mape: 44.8070 - smape: 0.3323 - val_loss: 0.0122 - val_rmse: 0.1104 - val_mape: 11.3483 - val_smape: 0.1144\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1409 - rmse: 0.3754 - mape: 40.5189 - smape: 0.2995 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mape: 6.7994 - val_smape: 0.0668\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1504 - rmse: 0.3878 - mape: 42.3128 - smape: 0.3059 - val_loss: 0.0094 - val_rmse: 0.0968 - val_mape: 9.7612 - val_smape: 0.0977\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1471 - rmse: 0.3835 - mape: 42.0967 - smape: 0.3154 - val_loss: 0.0067 - val_rmse: 0.0817 - val_mape: 8.0206 - val_smape: 0.0795\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1477 - rmse: 0.3843 - mape: 42.1698 - smape: 0.3100 - val_loss: 0.0055 - val_rmse: 0.0740 - val_mape: 7.1912 - val_smape: 0.0709\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1505 - rmse: 0.3880 - mape: 42.9665 - smape: 0.3148 - val_loss: 0.0072 - val_rmse: 0.0851 - val_mape: 8.3320 - val_smape: 0.0828\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1480 - rmse: 0.3847 - mape: 42.7560 - smape: 0.3169 - val_loss: 0.0060 - val_rmse: 0.0774 - val_mape: 7.4750 - val_smape: 0.0739\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1467 - rmse: 0.3830 - mape: 42.4493 - smape: 0.3116 - val_loss: 0.0060 - val_rmse: 0.0777 - val_mape: 7.4537 - val_smape: 0.0737\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1464 - rmse: 0.3826 - mape: 42.8996 - smape: 0.3169 - val_loss: 0.0067 - val_rmse: 0.0816 - val_mape: 7.7988 - val_smape: 0.0774\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1412 - rmse: 0.3758 - mape: 41.6987 - smape: 0.3093 - val_loss: 0.0057 - val_rmse: 0.0758 - val_mape: 7.1277 - val_smape: 0.0704\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1452 - rmse: 0.3811 - mape: 42.3463 - smape: 0.3130 - val_loss: 0.0076 - val_rmse: 0.0870 - val_mape: 8.2730 - val_smape: 0.0825\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1380 - rmse: 0.3715 - mape: 40.8404 - smape: 0.3088 - val_loss: 0.0060 - val_rmse: 0.0774 - val_mape: 7.1845 - val_smape: 0.0711\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1385 - rmse: 0.3721 - mape: 41.4180 - smape: 0.3086 - val_loss: 0.0065 - val_rmse: 0.0807 - val_mape: 7.4627 - val_smape: 0.0740\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1402 - rmse: 0.3744 - mape: 41.6310 - smape: 0.3101 - val_loss: 0.0064 - val_rmse: 0.0798 - val_mape: 7.3149 - val_smape: 0.0725\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1389 - rmse: 0.3726 - mape: 41.1973 - smape: 0.3066 - val_loss: 0.0068 - val_rmse: 0.0823 - val_mape: 7.5374 - val_smape: 0.0749\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1394 - rmse: 0.3734 - mape: 41.5176 - smape: 0.3075 - val_loss: 0.0072 - val_rmse: 0.0846 - val_mape: 7.7858 - val_smape: 0.0775\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1376 - rmse: 0.3710 - mape: 41.0508 - smape: 0.3077 - val_loss: 0.0067 - val_rmse: 0.0818 - val_mape: 7.4121 - val_smape: 0.0736\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1402 - rmse: 0.3744 - mape: 41.6714 - smape: 0.3118 - val_loss: 0.0080 - val_rmse: 0.0897 - val_mape: 8.2906 - val_smape: 0.0829\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1344 - rmse: 0.3665 - mape: 40.3032 - smape: 0.3065 - val_loss: 0.0061 - val_rmse: 0.0780 - val_mape: 6.8478 - val_smape: 0.0678\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f43b457fef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Test MAPE: 52.074\n",
      "Test sMAPE: 37.356\n",
      "Test RMSE: 5.261\n",
      "{'mape': 52.07396600944026, 'smape': 37.356413521218435, 'rmse': 5.261314461499095}\n",
      "Epoch 1/50\n",
      "8/8 - 3s - loss: 0.6279 - rmse: 0.7924 - mape: 86.0792 - smape: 0.8098 - val_loss: 0.1399 - val_rmse: 0.3740 - val_mape: 41.9378 - val_smape: 0.3297\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.3389 - rmse: 0.5821 - mape: 72.4214 - smape: 0.5008 - val_loss: 0.0843 - val_rmse: 0.2903 - val_mape: 31.8422 - val_smape: 0.3563\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.1111 - rmse: 0.3333 - mape: 34.2764 - smape: 0.2869 - val_loss: 0.0061 - val_rmse: 0.0784 - val_mape: 7.5556 - val_smape: 0.0677\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1832 - rmse: 0.4280 - mape: 47.2128 - smape: 0.3114 - val_loss: 0.0235 - val_rmse: 0.1534 - val_mape: 16.1320 - val_smape: 0.1667\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1495 - rmse: 0.3867 - mape: 44.1869 - smape: 0.3558 - val_loss: 0.0122 - val_rmse: 0.1104 - val_mape: 11.3596 - val_smape: 0.1145\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1362 - rmse: 0.3691 - mape: 38.6336 - smape: 0.2782 - val_loss: 0.0038 - val_rmse: 0.0617 - val_mape: 5.8995 - val_smape: 0.0575\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1566 - rmse: 0.3958 - mape: 43.7736 - smape: 0.3176 - val_loss: 0.0129 - val_rmse: 0.1137 - val_mape: 11.6526 - val_smape: 0.1178\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1382 - rmse: 0.3717 - mape: 40.8572 - smape: 0.3124 - val_loss: 0.0068 - val_rmse: 0.0824 - val_mape: 8.0708 - val_smape: 0.0801\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1427 - rmse: 0.3777 - mape: 41.2600 - smape: 0.3028 - val_loss: 0.0076 - val_rmse: 0.0870 - val_mape: 8.5264 - val_smape: 0.0849\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1401 - rmse: 0.3744 - mape: 41.5472 - smape: 0.3092 - val_loss: 0.0074 - val_rmse: 0.0860 - val_mape: 8.3504 - val_smape: 0.0831\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1464 - rmse: 0.3826 - mape: 42.0797 - smape: 0.3103 - val_loss: 0.0085 - val_rmse: 0.0923 - val_mape: 8.9859 - val_smape: 0.0898\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1382 - rmse: 0.3717 - mape: 40.7968 - smape: 0.3061 - val_loss: 0.0065 - val_rmse: 0.0806 - val_mape: 7.7455 - val_smape: 0.0768\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1445 - rmse: 0.3802 - mape: 41.6507 - smape: 0.3084 - val_loss: 0.0086 - val_rmse: 0.0927 - val_mape: 8.9764 - val_smape: 0.0898\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1381 - rmse: 0.3717 - mape: 41.2057 - smape: 0.3076 - val_loss: 0.0074 - val_rmse: 0.0863 - val_mape: 8.2818 - val_smape: 0.0825\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1422 - rmse: 0.3772 - mape: 41.4058 - smape: 0.3116 - val_loss: 0.0081 - val_rmse: 0.0903 - val_mape: 8.6566 - val_smape: 0.0865\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1349 - rmse: 0.3673 - mape: 40.4932 - smape: 0.3022 - val_loss: 0.0063 - val_rmse: 0.0797 - val_mape: 7.5196 - val_smape: 0.0745\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1412 - rmse: 0.3757 - mape: 41.3236 - smape: 0.3060 - val_loss: 0.0091 - val_rmse: 0.0955 - val_mape: 9.1157 - val_smape: 0.0914\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1346 - rmse: 0.3668 - mape: 40.4543 - smape: 0.3069 - val_loss: 0.0079 - val_rmse: 0.0887 - val_mape: 8.3820 - val_smape: 0.0837\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1365 - rmse: 0.3695 - mape: 40.7688 - smape: 0.3054 - val_loss: 0.0073 - val_rmse: 0.0855 - val_mape: 7.9630 - val_smape: 0.0793\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1435 - rmse: 0.3789 - mape: 41.7960 - smape: 0.3124 - val_loss: 0.0082 - val_rmse: 0.0908 - val_mape: 8.4657 - val_smape: 0.0847\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1369 - rmse: 0.3700 - mape: 40.9318 - smape: 0.3060 - val_loss: 0.0095 - val_rmse: 0.0973 - val_mape: 9.1072 - val_smape: 0.0916\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1335 - rmse: 0.3653 - mape: 40.4503 - smape: 0.3075 - val_loss: 0.0082 - val_rmse: 0.0908 - val_mape: 8.3923 - val_smape: 0.0840\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1339 - rmse: 0.3659 - mape: 40.4099 - smape: 0.3040 - val_loss: 0.0080 - val_rmse: 0.0895 - val_mape: 8.2089 - val_smape: 0.0821\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1396 - rmse: 0.3736 - mape: 41.7716 - smape: 0.3117 - val_loss: 0.0093 - val_rmse: 0.0966 - val_mape: 8.9330 - val_smape: 0.0898\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1389 - rmse: 0.3727 - mape: 41.1786 - smape: 0.3089 - val_loss: 0.0090 - val_rmse: 0.0946 - val_mape: 8.6985 - val_smape: 0.0873\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.1345 - rmse: 0.3667 - mape: 40.7479 - smape: 0.3082 - val_loss: 0.0081 - val_rmse: 0.0903 - val_mape: 8.0865 - val_smape: 0.0810\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test MAPE: 47.213\n",
      "Test sMAPE: 34.624\n",
      "Test RMSE: 4.840\n",
      "{'mape': 47.21295649838376, 'smape': 34.62360711745799, 'rmse': 4.839844399752432}\n",
      "Epoch 1/50\n",
      "8/8 - 3s - loss: 0.6084 - rmse: 0.7800 - mape: 81.8873 - smape: 0.7941 - val_loss: 0.1584 - val_rmse: 0.3980 - val_mape: 44.5886 - val_smape: 0.3468\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.3735 - rmse: 0.6112 - mape: 77.0996 - smape: 0.5598 - val_loss: 0.0717 - val_rmse: 0.2678 - val_mape: 29.3018 - val_smape: 0.3234\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.1128 - rmse: 0.3358 - mape: 34.2167 - smape: 0.2763 - val_loss: 0.0037 - val_rmse: 0.0607 - val_mape: 5.4056 - val_smape: 0.0489\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1806 - rmse: 0.4250 - mape: 47.1715 - smape: 0.3147 - val_loss: 0.0213 - val_rmse: 0.1461 - val_mape: 15.2809 - val_smape: 0.1573\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1465 - rmse: 0.3828 - mape: 43.2931 - smape: 0.3438 - val_loss: 0.0179 - val_rmse: 0.1339 - val_mape: 13.9299 - val_smape: 0.1424\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1329 - rmse: 0.3646 - mape: 38.3648 - smape: 0.2874 - val_loss: 0.0055 - val_rmse: 0.0742 - val_mape: 7.2325 - val_smape: 0.0712\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1485 - rmse: 0.3853 - mape: 41.8730 - smape: 0.3034 - val_loss: 0.0106 - val_rmse: 0.1029 - val_mape: 10.4574 - val_smape: 0.1050\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1429 - rmse: 0.3780 - mape: 41.2995 - smape: 0.3100 - val_loss: 0.0112 - val_rmse: 0.1060 - val_mape: 10.7382 - val_smape: 0.1081\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1436 - rmse: 0.3790 - mape: 41.4308 - smape: 0.3108 - val_loss: 0.0081 - val_rmse: 0.0902 - val_mape: 8.8340 - val_smape: 0.0881\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1413 - rmse: 0.3759 - mape: 41.5602 - smape: 0.3061 - val_loss: 0.0075 - val_rmse: 0.0867 - val_mape: 8.4544 - val_smape: 0.0841\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1428 - rmse: 0.3779 - mape: 41.5841 - smape: 0.3116 - val_loss: 0.0088 - val_rmse: 0.0938 - val_mape: 9.1794 - val_smape: 0.0918\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1382 - rmse: 0.3717 - mape: 40.6203 - smape: 0.3021 - val_loss: 0.0088 - val_rmse: 0.0938 - val_mape: 9.1326 - val_smape: 0.0914\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1376 - rmse: 0.3709 - mape: 40.4153 - smape: 0.3015 - val_loss: 0.0086 - val_rmse: 0.0929 - val_mape: 9.0202 - val_smape: 0.0902\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1380 - rmse: 0.3715 - mape: 40.1272 - smape: 0.3018 - val_loss: 0.0088 - val_rmse: 0.0938 - val_mape: 9.0932 - val_smape: 0.0910\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1402 - rmse: 0.3745 - mape: 40.8730 - smape: 0.3061 - val_loss: 0.0085 - val_rmse: 0.0924 - val_mape: 8.9256 - val_smape: 0.0892\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1366 - rmse: 0.3696 - mape: 40.8485 - smape: 0.3038 - val_loss: 0.0100 - val_rmse: 0.1000 - val_mape: 9.7314 - val_smape: 0.0978\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1385 - rmse: 0.3721 - mape: 41.1624 - smape: 0.3103 - val_loss: 0.0094 - val_rmse: 0.0969 - val_mape: 9.3496 - val_smape: 0.0938\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1339 - rmse: 0.3659 - mape: 40.0305 - smape: 0.2979 - val_loss: 0.0065 - val_rmse: 0.0809 - val_mape: 7.6619 - val_smape: 0.0760\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1399 - rmse: 0.3740 - mape: 41.6496 - smape: 0.3079 - val_loss: 0.0092 - val_rmse: 0.0957 - val_mape: 9.1551 - val_smape: 0.0918\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1327 - rmse: 0.3643 - mape: 40.1877 - smape: 0.3023 - val_loss: 0.0101 - val_rmse: 0.1003 - val_mape: 9.5938 - val_smape: 0.0966\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1352 - rmse: 0.3678 - mape: 40.3852 - smape: 0.3114 - val_loss: 0.0085 - val_rmse: 0.0923 - val_mape: 8.7104 - val_smape: 0.0872\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1337 - rmse: 0.3656 - mape: 39.7276 - smape: 0.2981 - val_loss: 0.0077 - val_rmse: 0.0880 - val_mape: 8.2292 - val_smape: 0.0821\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1384 - rmse: 0.3720 - mape: 40.6235 - smape: 0.3053 - val_loss: 0.0105 - val_rmse: 0.1022 - val_mape: 9.6724 - val_smape: 0.0976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Test MAPE: 28.917\n",
      "Test sMAPE: 33.740\n",
      "Test RMSE: 4.763\n",
      "{'mape': 28.91723278724544, 'smape': 33.73987969904519, 'rmse': 4.763204602321973}\n",
      "Epoch 1/50\n",
      "8/8 - 4s - loss: 0.7755 - rmse: 0.8806 - mape: 91.1567 - smape: 0.8863 - val_loss: 0.1773 - val_rmse: 0.4211 - val_mape: 47.1920 - val_smape: 0.3634\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.4062 - rmse: 0.6374 - mape: 80.8794 - smape: 0.6054 - val_loss: 0.1111 - val_rmse: 0.3333 - val_mape: 36.6707 - val_smape: 0.4217\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.1011 - rmse: 0.3179 - mape: 30.7057 - smape: 0.2602 - val_loss: 0.0120 - val_rmse: 0.1095 - val_mape: 11.3593 - val_smape: 0.1005\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1933 - rmse: 0.4397 - mape: 49.7319 - smape: 0.3273 - val_loss: 0.0295 - val_rmse: 0.1717 - val_mape: 18.2622 - val_smape: 0.1906\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1504 - rmse: 0.3879 - mape: 43.7584 - smape: 0.3654 - val_loss: 0.0125 - val_rmse: 0.1120 - val_mape: 11.4816 - val_smape: 0.1159\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1313 - rmse: 0.3623 - mape: 37.2114 - smape: 0.2675 - val_loss: 0.0033 - val_rmse: 0.0571 - val_mape: 5.2316 - val_smape: 0.0507\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1563 - rmse: 0.3953 - mape: 44.4635 - smape: 0.3223 - val_loss: 0.0156 - val_rmse: 0.1247 - val_mape: 12.7655 - val_smape: 0.1299\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1350 - rmse: 0.3675 - mape: 40.3318 - smape: 0.3102 - val_loss: 0.0063 - val_rmse: 0.0793 - val_mape: 7.6842 - val_smape: 0.0761\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1412 - rmse: 0.3758 - mape: 41.5185 - smape: 0.3018 - val_loss: 0.0071 - val_rmse: 0.0840 - val_mape: 8.1365 - val_smape: 0.0808\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1485 - rmse: 0.3854 - mape: 42.9610 - smape: 0.3175 - val_loss: 0.0100 - val_rmse: 0.1002 - val_mape: 9.8762 - val_smape: 0.0992\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1405 - rmse: 0.3749 - mape: 40.5430 - smape: 0.3052 - val_loss: 0.0069 - val_rmse: 0.0832 - val_mape: 8.0321 - val_smape: 0.0798\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1413 - rmse: 0.3759 - mape: 40.5434 - smape: 0.2975 - val_loss: 0.0081 - val_rmse: 0.0899 - val_mape: 8.7052 - val_smape: 0.0869\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1391 - rmse: 0.3729 - mape: 41.0221 - smape: 0.3084 - val_loss: 0.0096 - val_rmse: 0.0980 - val_mape: 9.5522 - val_smape: 0.0959\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1402 - rmse: 0.3744 - mape: 41.1497 - smape: 0.3101 - val_loss: 0.0083 - val_rmse: 0.0909 - val_mape: 8.7271 - val_smape: 0.0872\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1361 - rmse: 0.3689 - mape: 40.2616 - smape: 0.3017 - val_loss: 0.0073 - val_rmse: 0.0854 - val_mape: 8.1222 - val_smape: 0.0808\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1440 - rmse: 0.3795 - mape: 42.2931 - smape: 0.3125 - val_loss: 0.0095 - val_rmse: 0.0976 - val_mape: 9.3541 - val_smape: 0.0939\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1398 - rmse: 0.3739 - mape: 41.0438 - smape: 0.3110 - val_loss: 0.0085 - val_rmse: 0.0922 - val_mape: 8.7573 - val_smape: 0.0876\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1382 - rmse: 0.3717 - mape: 40.8637 - smape: 0.3026 - val_loss: 0.0077 - val_rmse: 0.0875 - val_mape: 8.2262 - val_smape: 0.0820\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1380 - rmse: 0.3715 - mape: 40.9833 - smape: 0.3093 - val_loss: 0.0085 - val_rmse: 0.0923 - val_mape: 8.6681 - val_smape: 0.0868\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1359 - rmse: 0.3686 - mape: 41.0338 - smape: 0.3063 - val_loss: 0.0091 - val_rmse: 0.0952 - val_mape: 8.9080 - val_smape: 0.0894\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1348 - rmse: 0.3672 - mape: 40.3999 - smape: 0.3034 - val_loss: 0.0082 - val_rmse: 0.0904 - val_mape: 8.3679 - val_smape: 0.0837\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1293 - rmse: 0.3595 - mape: 39.6084 - smape: 0.2975 - val_loss: 0.0074 - val_rmse: 0.0863 - val_mape: 7.8436 - val_smape: 0.0782\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1373 - rmse: 0.3706 - mape: 41.2688 - smape: 0.3088 - val_loss: 0.0088 - val_rmse: 0.0938 - val_mape: 8.6790 - val_smape: 0.0871\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1308 - rmse: 0.3616 - mape: 39.7678 - smape: 0.3039 - val_loss: 0.0089 - val_rmse: 0.0944 - val_mape: 8.7266 - val_smape: 0.0876\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1332 - rmse: 0.3649 - mape: 40.5932 - smape: 0.3076 - val_loss: 0.0093 - val_rmse: 0.0963 - val_mape: 8.9244 - val_smape: 0.0897\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.1334 - rmse: 0.3653 - mape: 40.1840 - smape: 0.2987 - val_loss: 0.0097 - val_rmse: 0.0985 - val_mape: 9.0946 - val_smape: 0.0916\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test MAPE: 41.521\n",
      "Test sMAPE: 31.157\n",
      "Test RMSE: 4.479\n",
      "{'mape': 41.52100186356664, 'smape': 31.15682904834224, 'rmse': 4.4794279365262595}\n",
      "Epoch 1/50\n",
      "8/8 - 4s - loss: 1.3744 - rmse: 1.1723 - mape: 107.2869 - smape: 0.8458 - val_loss: 0.0866 - val_rmse: 0.2942 - val_mape: 32.2650 - val_smape: 0.3622\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 0.1858 - rmse: 0.4310 - mape: 49.5418 - smape: 0.5013 - val_loss: 0.1690 - val_rmse: 0.4111 - val_mape: 46.0395 - val_smape: 0.3562\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 0.3612 - rmse: 0.6010 - mape: 77.1650 - smape: 0.5397 - val_loss: 0.0967 - val_rmse: 0.3110 - val_mape: 34.1926 - val_smape: 0.3877\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 0.1085 - rmse: 0.3294 - mape: 34.5493 - smape: 0.2981 - val_loss: 0.0088 - val_rmse: 0.0936 - val_mape: 9.2984 - val_smape: 0.0828\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 0.1841 - rmse: 0.4291 - mape: 48.7316 - smape: 0.3147 - val_loss: 0.0166 - val_rmse: 0.1289 - val_mape: 13.2130 - val_smape: 0.1348\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 0.1544 - rmse: 0.3929 - mape: 45.0117 - smape: 0.3610 - val_loss: 0.0147 - val_rmse: 0.1211 - val_mape: 12.3647 - val_smape: 0.1256\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 0.1298 - rmse: 0.3603 - mape: 38.6121 - smape: 0.2825 - val_loss: 0.0039 - val_rmse: 0.0622 - val_mape: 5.7777 - val_smape: 0.0563\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 0.1525 - rmse: 0.3906 - mape: 43.3378 - smape: 0.3123 - val_loss: 0.0116 - val_rmse: 0.1078 - val_mape: 10.8228 - val_smape: 0.1091\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 0.1437 - rmse: 0.3791 - mape: 41.7999 - smape: 0.3163 - val_loss: 0.0084 - val_rmse: 0.0915 - val_mape: 8.9630 - val_smape: 0.0895\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 0.1441 - rmse: 0.3796 - mape: 41.5212 - smape: 0.3041 - val_loss: 0.0071 - val_rmse: 0.0845 - val_mape: 8.1741 - val_smape: 0.0812\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 0.1445 - rmse: 0.3801 - mape: 41.5345 - smape: 0.3101 - val_loss: 0.0084 - val_rmse: 0.0915 - val_mape: 8.9057 - val_smape: 0.0890\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 0.1456 - rmse: 0.3816 - mape: 41.9676 - smape: 0.3112 - val_loss: 0.0075 - val_rmse: 0.0864 - val_mape: 8.3340 - val_smape: 0.0830\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.1430 - rmse: 0.3782 - mape: 41.5179 - smape: 0.3060 - val_loss: 0.0063 - val_rmse: 0.0794 - val_mape: 7.6016 - val_smape: 0.0752\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.1427 - rmse: 0.3778 - mape: 42.3325 - smape: 0.3105 - val_loss: 0.0091 - val_rmse: 0.0952 - val_mape: 9.2499 - val_smape: 0.0927\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.1408 - rmse: 0.3752 - mape: 41.6700 - smape: 0.3136 - val_loss: 0.0070 - val_rmse: 0.0839 - val_mape: 8.0323 - val_smape: 0.0798\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.1420 - rmse: 0.3769 - mape: 41.6144 - smape: 0.3048 - val_loss: 0.0072 - val_rmse: 0.0846 - val_mape: 8.0452 - val_smape: 0.0800\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.1432 - rmse: 0.3784 - mape: 42.1529 - smape: 0.3113 - val_loss: 0.0077 - val_rmse: 0.0880 - val_mape: 8.4406 - val_smape: 0.0841\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.1404 - rmse: 0.3747 - mape: 41.3792 - smape: 0.3091 - val_loss: 0.0065 - val_rmse: 0.0808 - val_mape: 7.6838 - val_smape: 0.0761\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.1421 - rmse: 0.3770 - mape: 41.7088 - smape: 0.3063 - val_loss: 0.0086 - val_rmse: 0.0925 - val_mape: 8.8657 - val_smape: 0.0887\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.1379 - rmse: 0.3714 - mape: 41.3065 - smape: 0.3103 - val_loss: 0.0074 - val_rmse: 0.0861 - val_mape: 8.1927 - val_smape: 0.0815\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.1423 - rmse: 0.3772 - mape: 41.9907 - smape: 0.3112 - val_loss: 0.0071 - val_rmse: 0.0845 - val_mape: 7.9828 - val_smape: 0.0794\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.1426 - rmse: 0.3777 - mape: 42.1212 - smape: 0.3140 - val_loss: 0.0072 - val_rmse: 0.0850 - val_mape: 7.9930 - val_smape: 0.0795\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.1397 - rmse: 0.3737 - mape: 41.5133 - smape: 0.3084 - val_loss: 0.0080 - val_rmse: 0.0897 - val_mape: 8.4388 - val_smape: 0.0843\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.1389 - rmse: 0.3727 - mape: 41.4666 - smape: 0.3107 - val_loss: 0.0078 - val_rmse: 0.0884 - val_mape: 8.2351 - val_smape: 0.0821\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1372 - rmse: 0.3704 - mape: 40.7704 - smape: 0.3056 - val_loss: 0.0081 - val_rmse: 0.0899 - val_mape: 8.3343 - val_smape: 0.0833\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.1348 - rmse: 0.3672 - mape: 40.8162 - smape: 0.3074 - val_loss: 0.0074 - val_rmse: 0.0859 - val_mape: 7.8756 - val_smape: 0.0784\n",
      "Epoch 27/50\n",
      "8/8 - 0s - loss: 0.1363 - rmse: 0.3692 - mape: 40.6787 - smape: 0.3049 - val_loss: 0.0068 - val_rmse: 0.0822 - val_mape: 7.3295 - val_smape: 0.0728\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Test MAPE: 46.056\n",
      "Test sMAPE: 33.637\n",
      "Test RMSE: 4.885\n",
      "{'mape': 46.056327714512854, 'smape': 33.636607567309255, 'rmse': 4.88501843651298}\n",
      "rmse : average=4.753, std=0.423\n",
      "mape : average=42.914, std=7.716\n",
      "smape : average=33.078, std=3.384\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59548a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
