{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "613bda42",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cc63b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c289b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e21096",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = 'Tabular_data/precipitation_all.csv'\n",
    "features2 = 'Tabular_data/temperature_all 2.csv'\n",
    "labels = 'Tabular_data/Label_CSV_All_Municipality.csv'\n",
    "MUNICIPALITY = 'Cali'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "966d827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities =  {\n",
    "  \"76001\":\t\"Cali\",\n",
    "  \"05001\":\t\"Medellín\",\n",
    "  \"50001\":\t\"Villavicencio\",\n",
    "  \"54001\":\t\"Cúcuta\",\n",
    "  \"73001\":\t\"Ibagué\",\n",
    "  \"68001\":\t\"Bucaramanga\",\n",
    "  \"05360\":\t\"Itagüí\",\n",
    "  \"08001\":\t\"Barranquilla\",\n",
    "  \"41001\":\t\"Neiva\",\n",
    "  \"23001\":\t\"Montería\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784529a",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0306db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19e27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b59e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Cases']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b3c23a",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f91e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(MUNICIPALITY):\n",
    "    for code, city in cities.items():\n",
    "        if city == MUNICIPALITY:\n",
    "            return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff53e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_76001</th>\n",
       "      <th>precipitation_76001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200701</th>\n",
       "      <td>26.798994</td>\n",
       "      <td>2.351892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200702</th>\n",
       "      <td>27.445338</td>\n",
       "      <td>4.404588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200703</th>\n",
       "      <td>26.663907</td>\n",
       "      <td>9.273447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200704</th>\n",
       "      <td>28.156202</td>\n",
       "      <td>6.406617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200705</th>\n",
       "      <td>26.317674</td>\n",
       "      <td>0.016323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201949</th>\n",
       "      <td>22.310196</td>\n",
       "      <td>3.819546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201950</th>\n",
       "      <td>23.566368</td>\n",
       "      <td>2.027720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201951</th>\n",
       "      <td>26.581760</td>\n",
       "      <td>9.874010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201952</th>\n",
       "      <td>26.583045</td>\n",
       "      <td>7.529475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202001</th>\n",
       "      <td>29.372542</td>\n",
       "      <td>11.742798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>679 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature_76001  precipitation_76001\n",
       "200701          26.798994             2.351892\n",
       "200702          27.445338             4.404588\n",
       "200703          26.663907             9.273447\n",
       "200704          28.156202             6.406617\n",
       "200705          26.317674             0.016323\n",
       "...                   ...                  ...\n",
       "201949          22.310196             3.819546\n",
       "201950          23.566368             2.027720\n",
       "201951          26.581760             9.874010\n",
       "201952          26.583045             7.529475\n",
       "202001          29.372542            11.742798\n",
       "\n",
       "[679 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = get_code(MUNICIPALITY)\n",
    "\n",
    "# Precipitation\n",
    "for col in pd.read_csv(features1).columns:\n",
    "    if code in col:\n",
    "        column = col\n",
    "        continue\n",
    "        \n",
    "precipitation_df = pd.read_csv(features1)[['LastDayWeek', column]]\n",
    "\n",
    "# Temperature\n",
    "for col in pd.read_csv(features2).columns:\n",
    "    if code in col:\n",
    "        column = col\n",
    "        continue\n",
    "        \n",
    "temperature_df = pd.read_csv(features2)[['LastDayWeek', column]]\n",
    "\n",
    "features_df = temperature_df.merge(precipitation_df, how='inner', on='LastDayWeek')\n",
    "\n",
    "features_df['LastDayWeek'] = features_df['LastDayWeek'].apply(epiweek_from_date)\n",
    "\n",
    "features_df = features_df.set_index('LastDayWeek')\n",
    "features_df.index.name = None\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f51005a",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f150701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "201601  1  0  0\n",
       "201602  0  1  0\n",
       "201603  0  1  0\n",
       "201604  0  1  0\n",
       "201605  0  1  0\n",
       "...    .. .. ..\n",
       "201848  1  0  0\n",
       "201849  1  0  0\n",
       "201850  1  0  0\n",
       "201851  1  0  0\n",
       "201852  1  0  0\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = read_labels(path=labels, Municipality=MUNICIPALITY)\n",
    "labels_df_orig = labels_df\n",
    "labels_df = pd.get_dummies(labels_df['Cases'])\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcab590",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f71ccbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2699a969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_76001</th>\n",
       "      <th>precipitation_76001</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>23.840761</td>\n",
       "      <td>13.893864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>24.552385</td>\n",
       "      <td>1.694592</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>22.452635</td>\n",
       "      <td>3.308565</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>28.260753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>26.890879</td>\n",
       "      <td>0.626154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>22.129020</td>\n",
       "      <td>10.406382</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>24.505446</td>\n",
       "      <td>1.638980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>28.386873</td>\n",
       "      <td>4.215898</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>25.932081</td>\n",
       "      <td>3.315602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>26.726455</td>\n",
       "      <td>4.884603</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature_76001  precipitation_76001  0  1  2\n",
       "201601          23.840761            13.893864  1  0  0\n",
       "201602          24.552385             1.694592  0  1  0\n",
       "201603          22.452635             3.308565  0  1  0\n",
       "201604          28.260753             0.000000  0  1  0\n",
       "201605          26.890879             0.626154  0  1  0\n",
       "...                   ...                  ... .. .. ..\n",
       "201848          22.129020            10.406382  1  0  0\n",
       "201849          24.505446             1.638980  1  0  0\n",
       "201850          28.386873             4.215898  1  0  0\n",
       "201851          25.932081             3.315602  1  0  0\n",
       "201852          26.726455             4.884603  1  0  0\n",
       "\n",
       "[156 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b759d",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91032796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a83a3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (124, 5)\n",
      "The test shape is: (32, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a039e7",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf28b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), n_labels=None):\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, n_labels=None):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e3e26f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "temperature_76001     -1.0\n",
      "precipitation_76001   -1.0\n",
      "0                      0.0\n",
      "1                      0.0\n",
      "2                      0.0\n",
      "dtype: float64\n",
      " Max values are: \n",
      "temperature_76001      1.0\n",
      "precipitation_76001    1.0\n",
      "0                      1.0\n",
      "1                      1.0\n",
      "2                      1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_76001</th>\n",
       "      <th>precipitation_76001</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>0.302420</td>\n",
       "      <td>0.720816</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0.376799</td>\n",
       "      <td>-0.790117</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0.157332</td>\n",
       "      <td>-0.590220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.764398</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>0.621219</td>\n",
       "      <td>-0.922448</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature_76001  precipitation_76001  0  1  2\n",
       "201601           0.302420             0.720816  1  0  0\n",
       "201602           0.376799            -0.790117  0  1  0\n",
       "201603           0.157332            -0.590220  0  1  0\n",
       "201604           0.764398            -1.000000  0  1  0\n",
       "201605           0.621219            -0.922448  0  1  0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range, n_labels=n_labels)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "968b09b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "temperature_76001      0.123508\n",
      "precipitation_76001   -1.000000\n",
      "0                      1.000000\n",
      "1                      0.000000\n",
      "2                      0.000000\n",
      "dtype: float64\n",
      " Max values are: \n",
      "temperature_76001      0.892130\n",
      "precipitation_76001    0.288876\n",
      "0                      1.000000\n",
      "1                      0.000000\n",
      "2                      0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_76001</th>\n",
       "      <th>precipitation_76001</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>0.333954</td>\n",
       "      <td>-0.172734</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>0.359457</td>\n",
       "      <td>-0.351993</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>0.564495</td>\n",
       "      <td>-0.953846</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>0.578864</td>\n",
       "      <td>-0.406403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201825</th>\n",
       "      <td>0.609580</td>\n",
       "      <td>-0.897911</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        temperature_76001  precipitation_76001  0  1  2\n",
       "201821           0.333954            -0.172734  1  0  0\n",
       "201822           0.359457            -0.351993  1  0  0\n",
       "201823           0.564495            -0.953846  1  0  0\n",
       "201824           0.578864            -0.406403  1  0  0\n",
       "201825           0.609580            -0.897911  1  0  0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers, n_labels=n_labels)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e3065",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e94304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True, no_autoregressive=None):\n",
    "    if no_autoregressive:\n",
    "        n_in = n_in - 1\n",
    "        \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        if no_autoregressive:\n",
    "            cols.append(df.shift(i).iloc[:,:-n_labels])\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars-n_labels)]\n",
    "        else:\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d9f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "no_autoregressive = True\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "test = series_to_supervised(test_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "\n",
    "#DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599916e",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b669fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df, n_labels, no_autoregressive):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (features and labels)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    if no_autoregressive:\n",
    "        features_set = DataFrame(timeseries_data.values[:,:-n_labels])\n",
    "    else:    \n",
    "        features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use labels in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-n_labels:])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ef68f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (115, 20)\n",
      "The shape of the labels is (115, 3)\n",
      "Test:\n",
      "The shape of the features is (23, 20)\n",
      "The shape of the labels is (23, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df, n_labels=n_labels, no_autoregressive=no_autoregressive)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df, n_labels=n_labels, no_autoregressive=no_autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfff9d8b",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9930522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ba9e9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (115, 20)\n",
      "The test shape is (23, 20)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (115, 10, 2)\n",
      "The test shape is (23, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "if no_autoregressive:\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X, test_X = reshape_tensor(train_X, test_X, n_features-n_labels)\n",
    "else:\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X, test_X = reshape_tensor(train_X, test_X, n_features-n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d872902",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31061e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    metrics = [\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=3),\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.CategoricalCrossentropy(name='entropy')\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d103b80",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "816a5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2da04fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 127, ones: 12, twos: 17, total: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.2283464566929134, 1: 13.0, 2: 9.176470588235293}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imbalanced data\n",
    "n_zeros = (labels_df_orig.to_numpy() == 0).sum()\n",
    "n_ones = (labels_df_orig.to_numpy() == 1).sum()\n",
    "n_twos = (labels_df_orig.to_numpy() == 2).sum()\n",
    "n_total = n_zeros + n_ones + n_twos\n",
    "\n",
    "weights = {0: n_total/n_zeros, 1: n_total/n_ones, 2: n_total/n_twos}\n",
    "print(f'zeros: {n_zeros}, ones: {n_ones}, twos: {n_twos}, total: {n_total}')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35389414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, weights, plot=None, epochs=20):\n",
    "    if monitor and weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor], class_weight=weights)\n",
    "    elif monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    elif weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, class_weight=weights)\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdf358",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83d113",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "942a2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also evaluate or predict on a dataset.\n",
    "def evaluate(model, verbose = None):\n",
    "    if verbose:\n",
    "        print('Evaluate: ')\n",
    "    result = model.evaluate(test_X, test_y)\n",
    "    stored_results = {}\n",
    "    for i, metric in enumerate(model.metrics_names):\n",
    "        stored_results[metric] = result[i]\n",
    "        if verbose:\n",
    "            print(f'{metric}: {result[i]}')\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fddda9d",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f78d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(weights):\n",
    "    \n",
    "    metrics = {\n",
    "        \"auc\": [],\n",
    "        \"acc\": [],\n",
    "        \"entropy\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(3):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor, weights=weights)\n",
    "        stored_results = evaluate(model=model)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcf74214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.7380 - auc: 0.8211 - acc: 0.8087 - entropy: 0.7380 - val_loss: 0.0014 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.0014\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.1145 - auc: 0.1937 - acc: 0.8087 - entropy: 1.1145 - val_loss: 0.2925 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.2925\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.7015 - auc: 0.4622 - acc: 0.8087 - entropy: 0.7015 - val_loss: 0.3136 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.3136\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.6243 - auc: 0.6353 - acc: 0.8087 - entropy: 0.6243 - val_loss: 0.1384 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1384\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.6097 - auc: 0.5859 - acc: 0.8087 - entropy: 0.6097 - val_loss: 0.0837 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.0837\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.6653 - auc: 0.3928 - acc: 0.8087 - entropy: 0.6653 - val_loss: 0.1269 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1269\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.6440 - auc: 0.4119 - acc: 0.8087 - entropy: 0.6440 - val_loss: 0.1599 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1599\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.6140 - auc: 0.5154 - acc: 0.8087 - entropy: 0.6140 - val_loss: 0.1391 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1391\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.6290 - auc: 0.4801 - acc: 0.8087 - entropy: 0.6290 - val_loss: 0.1284 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1284\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.6277 - auc: 0.4895 - acc: 0.8087 - entropy: 0.6277 - val_loss: 0.1352 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1352\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.6411 - auc: 0.4205 - acc: 0.8087 - entropy: 0.6411 - val_loss: 0.1506 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1506\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.6269 - auc: 0.4755 - acc: 0.8087 - entropy: 0.6269 - val_loss: 0.1497 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1497\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6278 - auc: 0.4521 - acc: 0.8087 - entropy: 0.6278 - val_loss: 0.1513 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1513\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.6375 - auc: 0.4079 - acc: 0.8087 - entropy: 0.6375 - val_loss: 0.1590 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1590\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6225 - auc: 0.4687 - acc: 0.8087 - entropy: 0.6225 - val_loss: 0.1557 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1557\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.6299 - auc: 0.4336 - acc: 0.8087 - entropy: 0.6299 - val_loss: 0.1585 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1585\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.6263 - auc: 0.4305 - acc: 0.8087 - entropy: 0.6263 - val_loss: 0.1599 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1599\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.6241 - auc: 0.4233 - acc: 0.8087 - entropy: 0.6241 - val_loss: 0.1591 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1591\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.6174 - auc: 0.4695 - acc: 0.8087 - entropy: 0.6174 - val_loss: 0.1573 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1573\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.6212 - auc: 0.4463 - acc: 0.8087 - entropy: 0.6212 - val_loss: 0.1601 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1601\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1601 - auc: 0.0000e+00 - acc: 1.0000 - entropy: 0.1601\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.7151 - auc: 0.8203 - acc: 0.8087 - entropy: 0.7151 - val_loss: 0.0016 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.0016\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.0991 - auc: 0.1932 - acc: 0.8087 - entropy: 1.0991 - val_loss: 0.2497 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.2497\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6968 - auc: 0.4413 - acc: 0.8087 - entropy: 0.6968 - val_loss: 0.2906 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.2906\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.6260 - auc: 0.6234 - acc: 0.8087 - entropy: 0.6260 - val_loss: 0.1403 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1403\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.6135 - auc: 0.5816 - acc: 0.8087 - entropy: 0.6135 - val_loss: 0.0859 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.0859\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.6807 - auc: 0.3638 - acc: 0.8087 - entropy: 0.6807 - val_loss: 0.1279 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1279\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.6391 - auc: 0.4558 - acc: 0.8087 - entropy: 0.6391 - val_loss: 0.1525 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1525\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.6274 - auc: 0.4575 - acc: 0.8087 - entropy: 0.6274 - val_loss: 0.1415 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1415\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.6215 - auc: 0.5149 - acc: 0.8087 - entropy: 0.6215 - val_loss: 0.1287 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1287\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.6354 - auc: 0.4319 - acc: 0.8087 - entropy: 0.6354 - val_loss: 0.1354 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1354\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.6282 - auc: 0.4492 - acc: 0.8087 - entropy: 0.6282 - val_loss: 0.1439 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1439\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.6324 - auc: 0.4486 - acc: 0.8087 - entropy: 0.6324 - val_loss: 0.1515 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1515\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6254 - auc: 0.4445 - acc: 0.8087 - entropy: 0.6254 - val_loss: 0.1523 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1523\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.6238 - auc: 0.4784 - acc: 0.8087 - entropy: 0.6238 - val_loss: 0.1509 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1509\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6116 - auc: 0.5146 - acc: 0.8087 - entropy: 0.6116 - val_loss: 0.1455 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1455\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.6286 - auc: 0.4423 - acc: 0.8087 - entropy: 0.6286 - val_loss: 0.1561 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1561\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.6293 - auc: 0.4357 - acc: 0.8087 - entropy: 0.6293 - val_loss: 0.1694 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1694\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.6324 - auc: 0.3803 - acc: 0.8087 - entropy: 0.6324 - val_loss: 0.1715 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1715\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.6241 - auc: 0.4270 - acc: 0.8087 - entropy: 0.6241 - val_loss: 0.1678 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1678\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.6245 - auc: 0.4264 - acc: 0.8087 - entropy: 0.6245 - val_loss: 0.1666 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1666\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1666 - auc: 0.0000e+00 - acc: 1.0000 - entropy: 0.1666\n",
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 0.7337 - auc: 0.8139 - acc: 0.7913 - entropy: 0.7337 - val_loss: 0.0013 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.0013\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.0864 - auc: 0.2114 - acc: 0.7913 - entropy: 1.0864 - val_loss: 0.2613 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.2613\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.7008 - auc: 0.4300 - acc: 0.8087 - entropy: 0.7008 - val_loss: 0.2957 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.2957\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.6167 - auc: 0.6540 - acc: 0.8087 - entropy: 0.6167 - val_loss: 0.1250 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1250\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.6377 - auc: 0.4942 - acc: 0.8087 - entropy: 0.6377 - val_loss: 0.0888 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.0888\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.6590 - auc: 0.4461 - acc: 0.8087 - entropy: 0.6590 - val_loss: 0.1249 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1249\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.6518 - auc: 0.4088 - acc: 0.8087 - entropy: 0.6518 - val_loss: 0.1551 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1551\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.6281 - auc: 0.4836 - acc: 0.8087 - entropy: 0.6281 - val_loss: 0.1470 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1470\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.6266 - auc: 0.5007 - acc: 0.8087 - entropy: 0.6266 - val_loss: 0.1363 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1363\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.6300 - auc: 0.4758 - acc: 0.8087 - entropy: 0.6300 - val_loss: 0.1365 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1365\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.6295 - auc: 0.4697 - acc: 0.8087 - entropy: 0.6295 - val_loss: 0.1410 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1410\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.6393 - auc: 0.3980 - acc: 0.8087 - entropy: 0.6393 - val_loss: 0.1525 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1525\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6284 - auc: 0.4552 - acc: 0.8087 - entropy: 0.6284 - val_loss: 0.1526 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1526\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.6137 - auc: 0.5225 - acc: 0.8087 - entropy: 0.6137 - val_loss: 0.1453 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1453\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6250 - auc: 0.4694 - acc: 0.8087 - entropy: 0.6250 - val_loss: 0.1479 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1479\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.6207 - auc: 0.4880 - acc: 0.8087 - entropy: 0.6207 - val_loss: 0.1540 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1540\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.6262 - auc: 0.4322 - acc: 0.8087 - entropy: 0.6262 - val_loss: 0.1585 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1585\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.6255 - auc: 0.4483 - acc: 0.8087 - entropy: 0.6255 - val_loss: 0.1567 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1567\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.6197 - auc: 0.4810 - acc: 0.8087 - entropy: 0.6197 - val_loss: 0.1581 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1581\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.6262 - auc: 0.4438 - acc: 0.8087 - entropy: 0.6262 - val_loss: 0.1657 - val_auc: 0.0000e+00 - val_acc: 1.0000 - val_entropy: 0.1657\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1657 - auc: 0.0000e+00 - acc: 1.0000 - entropy: 0.1657\n",
      "auc : average=0.000, std=0.000\n",
      "acc : average=1.000, std=0.000\n",
      "entropy : average=0.164, std=0.003\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eeb66854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 5s - loss: 3.3759 - auc: 0.3516 - acc: 0.0783 - entropy: 1.2726 - val_loss: 1.1521 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 1.1521\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.1201 - auc: 0.6440 - acc: 0.1391 - entropy: 1.0865 - val_loss: 0.9897 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9897\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.1222 - auc: 0.5446 - acc: 0.1478 - entropy: 1.0288 - val_loss: 0.9398 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9398\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.1070 - auc: 0.5213 - acc: 0.1652 - entropy: 1.0127 - val_loss: 0.9529 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9529\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.1042 - auc: 0.5211 - acc: 0.2174 - entropy: 1.0197 - val_loss: 0.9644 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9644\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.0817 - auc: 0.5074 - acc: 0.2000 - entropy: 1.0224 - val_loss: 0.9752 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9752\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.0776 - auc: 0.5357 - acc: 0.2522 - entropy: 1.0247 - val_loss: 0.9658 - val_auc: 0.0000e+00 - val_acc: 0.0435 - val_entropy: 0.9658\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.0585 - auc: 0.5476 - acc: 0.2783 - entropy: 1.0205 - val_loss: 0.9508 - val_auc: 0.0000e+00 - val_acc: 0.1739 - val_entropy: 0.9508\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 2.9939 - auc: 0.5473 - acc: 0.2870 - entropy: 1.0255 - val_loss: 0.9806 - val_auc: 0.0000e+00 - val_acc: 0.1304 - val_entropy: 0.9806\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 2.9849 - auc: 0.5563 - acc: 0.3043 - entropy: 1.0437 - val_loss: 0.9316 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9316\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 2.9202 - auc: 0.5700 - acc: 0.2783 - entropy: 1.0520 - val_loss: 0.9325 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9325\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 2.9913 - auc: 0.5545 - acc: 0.2783 - entropy: 1.0475 - val_loss: 0.9391 - val_auc: 0.0000e+00 - val_acc: 0.3478 - val_entropy: 0.9391\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 2.9312 - auc: 0.5647 - acc: 0.3130 - entropy: 1.0333 - val_loss: 0.9520 - val_auc: 0.0000e+00 - val_acc: 0.3913 - val_entropy: 0.9520\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 2.9580 - auc: 0.5724 - acc: 0.2696 - entropy: 1.0343 - val_loss: 0.9336 - val_auc: 0.0000e+00 - val_acc: 0.3913 - val_entropy: 0.9336\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 2.8702 - auc: 0.5845 - acc: 0.2870 - entropy: 1.0117 - val_loss: 0.8885 - val_auc: 0.0000e+00 - val_acc: 0.4783 - val_entropy: 0.8885\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 2.9124 - auc: 0.5815 - acc: 0.3130 - entropy: 1.0214 - val_loss: 0.9137 - val_auc: 0.0000e+00 - val_acc: 0.3913 - val_entropy: 0.9137\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 2.8455 - auc: 0.6083 - acc: 0.3391 - entropy: 0.9930 - val_loss: 0.9071 - val_auc: 0.0000e+00 - val_acc: 0.4783 - val_entropy: 0.9071\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 2.9233 - auc: 0.5952 - acc: 0.4000 - entropy: 0.9961 - val_loss: 0.8610 - val_auc: 0.0000e+00 - val_acc: 0.4783 - val_entropy: 0.8610\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 2.8391 - auc: 0.6130 - acc: 0.3565 - entropy: 0.9763 - val_loss: 0.7753 - val_auc: 0.0000e+00 - val_acc: 0.6087 - val_entropy: 0.7753\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 2.8498 - auc: 0.6065 - acc: 0.3913 - entropy: 0.9673 - val_loss: 0.9362 - val_auc: 0.0000e+00 - val_acc: 0.4783 - val_entropy: 0.9362\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9362 - auc: 0.0000e+00 - acc: 0.4783 - entropy: 0.9362\n",
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 3.3571 - auc: 0.3563 - acc: 0.1391 - entropy: 1.2815 - val_loss: 1.1808 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 1.1808\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.0935 - auc: 0.6145 - acc: 0.1391 - entropy: 1.1014 - val_loss: 1.0323 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 1.0323\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.0539 - auc: 0.5682 - acc: 0.1478 - entropy: 1.0484 - val_loss: 0.9977 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9977\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.0954 - auc: 0.5119 - acc: 0.1739 - entropy: 1.0409 - val_loss: 0.9979 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9979\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.0214 - auc: 0.5586 - acc: 0.1913 - entropy: 1.0339 - val_loss: 1.0161 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 1.0161\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 2.9855 - auc: 0.5606 - acc: 0.2348 - entropy: 1.0366 - val_loss: 1.0248 - val_auc: 0.0000e+00 - val_acc: 0.0435 - val_entropy: 1.0248\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.0241 - auc: 0.5459 - acc: 0.2435 - entropy: 1.0476 - val_loss: 0.9890 - val_auc: 0.0000e+00 - val_acc: 0.1739 - val_entropy: 0.9890\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.0057 - auc: 0.5471 - acc: 0.2957 - entropy: 1.0445 - val_loss: 0.9595 - val_auc: 0.0000e+00 - val_acc: 0.3478 - val_entropy: 0.9595\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 2.9955 - auc: 0.5652 - acc: 0.2870 - entropy: 1.0449 - val_loss: 1.0018 - val_auc: 0.0000e+00 - val_acc: 0.1304 - val_entropy: 1.0018\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.0013 - auc: 0.5600 - acc: 0.2957 - entropy: 1.0610 - val_loss: 0.9592 - val_auc: 0.0000e+00 - val_acc: 0.2174 - val_entropy: 0.9592\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 2.9872 - auc: 0.5535 - acc: 0.3217 - entropy: 1.0354 - val_loss: 0.9165 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9165\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 2.9388 - auc: 0.5905 - acc: 0.3565 - entropy: 1.0129 - val_loss: 0.8827 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.8827\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 2.9193 - auc: 0.5676 - acc: 0.3043 - entropy: 1.0508 - val_loss: 0.9053 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9053\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 2.9785 - auc: 0.5607 - acc: 0.3217 - entropy: 1.0452 - val_loss: 0.9483 - val_auc: 0.0000e+00 - val_acc: 0.3913 - val_entropy: 0.9483\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 2.9264 - auc: 0.5915 - acc: 0.2870 - entropy: 1.0259 - val_loss: 0.9091 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9091\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 2.9443 - auc: 0.5900 - acc: 0.3391 - entropy: 1.0253 - val_loss: 0.9194 - val_auc: 0.0000e+00 - val_acc: 0.3913 - val_entropy: 0.9194\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 2.9390 - auc: 0.5704 - acc: 0.2870 - entropy: 1.0255 - val_loss: 0.8775 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.8775\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 2.9400 - auc: 0.5766 - acc: 0.3565 - entropy: 1.0023 - val_loss: 0.8849 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.8849\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 2.8067 - auc: 0.6134 - acc: 0.3217 - entropy: 1.0007 - val_loss: 0.8158 - val_auc: 0.0000e+00 - val_acc: 0.4783 - val_entropy: 0.8158\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 2.9336 - auc: 0.5903 - acc: 0.3130 - entropy: 0.9833 - val_loss: 0.9804 - val_auc: 0.0000e+00 - val_acc: 0.3913 - val_entropy: 0.9804\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9804 - auc: 0.0000e+00 - acc: 0.3913 - entropy: 0.9804\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.3964 - auc: 0.3724 - acc: 0.0696 - entropy: 1.3089 - val_loss: 1.1282 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 1.1282\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.1164 - auc: 0.6306 - acc: 0.1478 - entropy: 1.0769 - val_loss: 0.9560 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9560\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.1153 - auc: 0.5386 - acc: 0.1652 - entropy: 1.0161 - val_loss: 0.9100 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9100\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.1276 - auc: 0.5012 - acc: 0.1739 - entropy: 1.0076 - val_loss: 0.9429 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9429\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.1153 - auc: 0.4984 - acc: 0.1478 - entropy: 1.0225 - val_loss: 0.9750 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9750\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.0924 - auc: 0.5079 - acc: 0.2000 - entropy: 1.0317 - val_loss: 1.0022 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 1.0022\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.0863 - auc: 0.5246 - acc: 0.2261 - entropy: 1.0406 - val_loss: 0.9998 - val_auc: 0.0000e+00 - val_acc: 0.0000e+00 - val_entropy: 0.9998\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.0875 - auc: 0.5385 - acc: 0.2609 - entropy: 1.0354 - val_loss: 0.9765 - val_auc: 0.0000e+00 - val_acc: 0.1304 - val_entropy: 0.9765\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.0531 - auc: 0.5472 - acc: 0.2870 - entropy: 1.0283 - val_loss: 0.9586 - val_auc: 0.0000e+00 - val_acc: 0.1739 - val_entropy: 0.9586\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.0467 - auc: 0.5382 - acc: 0.3130 - entropy: 1.0345 - val_loss: 0.9588 - val_auc: 0.0000e+00 - val_acc: 0.3478 - val_entropy: 0.9588\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.0276 - auc: 0.5511 - acc: 0.3565 - entropy: 1.0388 - val_loss: 0.9690 - val_auc: 0.0000e+00 - val_acc: 0.3913 - val_entropy: 0.9690\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 2.9782 - auc: 0.5745 - acc: 0.3565 - entropy: 1.0528 - val_loss: 0.9195 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9195\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 2.9499 - auc: 0.5765 - acc: 0.2696 - entropy: 1.0623 - val_loss: 0.9665 - val_auc: 0.0000e+00 - val_acc: 0.3043 - val_entropy: 0.9665\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 2.9101 - auc: 0.6018 - acc: 0.3130 - entropy: 1.0229 - val_loss: 0.8738 - val_auc: 0.0000e+00 - val_acc: 0.6087 - val_entropy: 0.8738\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 2.9550 - auc: 0.5727 - acc: 0.2957 - entropy: 1.0199 - val_loss: 0.9015 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9015\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 2.9388 - auc: 0.5751 - acc: 0.3130 - entropy: 1.0390 - val_loss: 0.9083 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9083\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 2.8622 - auc: 0.5876 - acc: 0.2696 - entropy: 1.0122 - val_loss: 0.9052 - val_auc: 0.0000e+00 - val_acc: 0.4783 - val_entropy: 0.9052\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 2.9039 - auc: 0.5870 - acc: 0.2696 - entropy: 1.0203 - val_loss: 0.9009 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9009\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 2.8283 - auc: 0.6214 - acc: 0.3130 - entropy: 0.9928 - val_loss: 0.9054 - val_auc: 0.0000e+00 - val_acc: 0.4348 - val_entropy: 0.9054\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 2.8252 - auc: 0.6053 - acc: 0.3565 - entropy: 1.0073 - val_loss: 0.8112 - val_auc: 0.0000e+00 - val_acc: 0.8261 - val_entropy: 0.8112\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8112 - auc: 0.0000e+00 - acc: 0.8261 - entropy: 0.8112\n",
      "auc : average=0.000, std=0.000\n",
      "acc : average=0.565, std=0.188\n",
      "entropy : average=0.909, std=0.072\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1e8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
