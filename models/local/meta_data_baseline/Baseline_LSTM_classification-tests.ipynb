{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26e8fdb",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5633c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cff6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e829368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 'Tabular_data/dengue_tabular.csv'\n",
    "labels = 'Tabular_data/Label_CSV_All_Municipality.csv'\n",
    "MUNICIPALITY = 'Medellín'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad0250",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63dd95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667e602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Cases']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7cfb7",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72153ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200701</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200702</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200703</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200704</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200705</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201948</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201949</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201950</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201951</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201952</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cases\n",
       "200701      1\n",
       "200702      0\n",
       "200703      0\n",
       "200704      0\n",
       "200705      0\n",
       "...       ...\n",
       "201948     15\n",
       "201949     20\n",
       "201950     30\n",
       "201951     14\n",
       "201952      5\n",
       "\n",
       "[676 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = read_labels(path=features, Municipality=MUNICIPALITY)\n",
    "features_df.index = features_df.index.astype(int)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa0851",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76775d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "201601  1  0  0\n",
       "201602  0  1  0\n",
       "201603  0  0  1\n",
       "201604  1  0  0\n",
       "201605  1  0  0\n",
       "...    .. .. ..\n",
       "201848  1  0  0\n",
       "201849  0  0  1\n",
       "201850  0  1  0\n",
       "201851  1  0  0\n",
       "201852  1  0  0\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = read_labels(path=labels, Municipality=MUNICIPALITY)\n",
    "labels_df_orig = labels_df\n",
    "labels_df = pd.get_dummies(labels_df['Cases'])\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4a7ae",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98335e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "406c7851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cases  0  1  2\n",
       "201601    235  1  0  0\n",
       "201602    274  0  1  0\n",
       "201603    252  0  0  1\n",
       "201604    262  1  0  0\n",
       "201605    274  1  0  0\n",
       "...       ... .. .. ..\n",
       "201848     28  1  0  0\n",
       "201849     12  0  0  1\n",
       "201850     27  0  1  0\n",
       "201851     17  1  0  0\n",
       "201852     17  1  0  0\n",
       "\n",
       "[156 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9f9cc",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e71e29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d2f8848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (124, 4)\n",
      "The test shape is: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a34183",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f9aee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), n_labels=None):\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, n_labels=None):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c24507e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "Cases   -1.0\n",
      "0        0.0\n",
      "1        0.0\n",
      "2        0.0\n",
      "dtype: float64\n",
      " Max values are: \n",
      "Cases    1.0\n",
      "0        1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>-0.235294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-0.100346</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>-0.176471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>-0.141869</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.100346</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cases  0  1  2\n",
       "201601 -0.235294  1  0  0\n",
       "201602 -0.100346  0  1  0\n",
       "201603 -0.176471  0  0  1\n",
       "201604 -0.141869  1  0  0\n",
       "201605 -0.100346  1  0  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range, n_labels=n_labels)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf3e9113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "Cases   -1.00692\n",
      "0        0.00000\n",
      "1        0.00000\n",
      "2        0.00000\n",
      "dtype: float64\n",
      " Max values are: \n",
      "Cases   -0.906574\n",
      "0        1.000000\n",
      "1        1.000000\n",
      "2        1.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cases</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>-0.989619</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>-0.982699</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>-0.968858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>-0.972318</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201825</th>\n",
       "      <td>-0.968858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cases  0  1  2\n",
       "201821 -0.989619  1  0  0\n",
       "201822 -0.982699  1  0  0\n",
       "201823 -0.968858  1  0  0\n",
       "201824 -0.972318  1  0  0\n",
       "201825 -0.968858  1  0  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers, n_labels=n_labels)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d247cb",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3334371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True, no_autoregressive=None):\n",
    "    if no_autoregressive:\n",
    "        n_in = n_in - 1\n",
    "        \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        if no_autoregressive:\n",
    "            cols.append(df.shift(i).iloc[:,:-n_labels])\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars-n_labels)]\n",
    "        else:\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5eb20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "no_autoregressive = True\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "test = series_to_supervised(test_df, n_in=days, no_autoregressive=no_autoregressive)\n",
    "\n",
    "#DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea102201",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11881b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df, n_labels, no_autoregressive):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (features and labels)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    if no_autoregressive:\n",
    "        features_set = DataFrame(timeseries_data.values[:,:-n_labels])\n",
    "    else:    \n",
    "        features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use labels in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-n_labels:])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05e25e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (115, 10)\n",
      "The shape of the labels is (115, 3)\n",
      "Test:\n",
      "The shape of the features is (23, 10)\n",
      "The shape of the labels is (23, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df, n_labels=n_labels, no_autoregressive=no_autoregressive)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df, n_labels=n_labels, no_autoregressive=no_autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfe29d",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e03095af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1b45a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (115, 10)\n",
      "The test shape is (23, 10)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (115, 10, 1)\n",
      "The test shape is (23, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "if no_autoregressive:\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X, test_X = reshape_tensor(train_X, test_X, n_features-n_labels)\n",
    "else:\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X, test_X = reshape_tensor(train_X, test_X, n_features-n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68476fa3",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be92bc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    metrics = [\n",
    "        tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=3),\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='acc'),\n",
    "        tf.keras.metrics.CategoricalCrossentropy(name='entropy')\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb697e",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ecd3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20cc973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 113, ones: 20, twos: 23, total: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.3805309734513274, 1: 7.8, 2: 6.782608695652174}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imbalanced data\n",
    "n_zeros = (labels_df_orig.to_numpy() == 0).sum()\n",
    "n_ones = (labels_df_orig.to_numpy() == 1).sum()\n",
    "n_twos = (labels_df_orig.to_numpy() == 2).sum()\n",
    "n_total = n_zeros + n_ones + n_twos\n",
    "\n",
    "weights = {0: n_total/n_zeros, 1: n_total/n_ones, 2: n_total/n_twos}\n",
    "print(f'zeros: {n_zeros}, ones: {n_ones}, twos: {n_twos}, total: {n_total}')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a134653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, weights, plot=None, epochs=20):\n",
    "    if monitor and weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor], class_weight=weights)\n",
    "    elif monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    elif weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, class_weight=weights)\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef352afa",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f4cd5",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "057b7d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also evaluate or predict on a dataset.\n",
    "def evaluate(model, verbose = None):\n",
    "    if verbose:\n",
    "        print('Evaluate: ')\n",
    "    result = model.evaluate(test_X, test_y)\n",
    "    stored_results = {}\n",
    "    for i, metric in enumerate(model.metrics_names):\n",
    "        stored_results[metric] = result[i]\n",
    "        if verbose:\n",
    "            print(f'{metric}: {result[i]}')\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c23165",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d272f3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(weights):\n",
    "    \n",
    "    metrics = {\n",
    "        \"auc\": [],\n",
    "        \"acc\": [],\n",
    "        \"entropy\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(3):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor, weights=weights)\n",
    "        stored_results = evaluate(model=model)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edf89944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 1.0312 - auc: 0.5602 - acc: 0.4696 - entropy: 1.0312 - val_loss: 0.5699 - val_auc: 0.5667 - val_acc: 0.8696 - val_entropy: 0.5699\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 0.6910 - auc: 0.7788 - acc: 0.6609 - entropy: 0.6910 - val_loss: 0.5226 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.5226\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.7130 - auc: 0.7501 - acc: 0.6696 - entropy: 0.7130 - val_loss: 0.4925 - val_auc: 0.5333 - val_acc: 0.8696 - val_entropy: 0.4925\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.6983 - auc: 0.7651 - acc: 0.6783 - entropy: 0.6983 - val_loss: 0.5020 - val_auc: 0.4545 - val_acc: 0.8696 - val_entropy: 0.5020\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.7013 - auc: 0.7676 - acc: 0.6783 - entropy: 0.7013 - val_loss: 0.5015 - val_auc: 0.4848 - val_acc: 0.8696 - val_entropy: 0.5015\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.6888 - auc: 0.7863 - acc: 0.6957 - entropy: 0.6888 - val_loss: 0.5136 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.5136\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.7104 - auc: 0.7358 - acc: 0.6870 - entropy: 0.7104 - val_loss: 0.5007 - val_auc: 0.5278 - val_acc: 0.8696 - val_entropy: 0.5007\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.6916 - auc: 0.7651 - acc: 0.6957 - entropy: 0.6916 - val_loss: 0.5113 - val_auc: 0.5061 - val_acc: 0.8696 - val_entropy: 0.5113\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.7010 - auc: 0.7555 - acc: 0.6957 - entropy: 0.7010 - val_loss: 0.4911 - val_auc: 0.6597 - val_acc: 0.8696 - val_entropy: 0.4911\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.6762 - auc: 0.7906 - acc: 0.6870 - entropy: 0.6762 - val_loss: 0.5261 - val_auc: 0.4667 - val_acc: 0.8696 - val_entropy: 0.5261\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.7183 - auc: 0.7392 - acc: 0.6696 - entropy: 0.7183 - val_loss: 0.4890 - val_auc: 0.5053 - val_acc: 0.8696 - val_entropy: 0.4890\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.6971 - auc: 0.7503 - acc: 0.7043 - entropy: 0.6971 - val_loss: 0.5112 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.5112\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6954 - auc: 0.7736 - acc: 0.7043 - entropy: 0.6954 - val_loss: 0.4981 - val_auc: 0.4583 - val_acc: 0.8696 - val_entropy: 0.4981\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.6932 - auc: 0.7692 - acc: 0.6957 - entropy: 0.6932 - val_loss: 0.5056 - val_auc: 0.5197 - val_acc: 0.8696 - val_entropy: 0.5056\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6897 - auc: 0.7642 - acc: 0.6870 - entropy: 0.6897 - val_loss: 0.5047 - val_auc: 0.5227 - val_acc: 0.8696 - val_entropy: 0.5047\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.6748 - auc: 0.7961 - acc: 0.6957 - entropy: 0.6748 - val_loss: 0.5001 - val_auc: 0.5270 - val_acc: 0.8696 - val_entropy: 0.5001\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.6886 - auc: 0.7671 - acc: 0.6870 - entropy: 0.6886 - val_loss: 0.5146 - val_auc: 0.5455 - val_acc: 0.8696 - val_entropy: 0.5146\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.6990 - auc: 0.7504 - acc: 0.6870 - entropy: 0.6990 - val_loss: 0.4862 - val_auc: 0.5690 - val_acc: 0.8696 - val_entropy: 0.4862\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.6909 - auc: 0.7662 - acc: 0.6870 - entropy: 0.6909 - val_loss: 0.5329 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.5329\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.6753 - auc: 0.7774 - acc: 0.6957 - entropy: 0.6753 - val_loss: 0.4983 - val_auc: 0.5448 - val_acc: 0.8696 - val_entropy: 0.4983\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4983 - auc: 0.5448 - acc: 0.8696 - entropy: 0.4983\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 1.0471 - auc: 0.5350 - acc: 0.4696 - entropy: 1.0471 - val_loss: 0.6503 - val_auc: 0.5079 - val_acc: 0.8696 - val_entropy: 0.6503\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 0.6784 - auc: 0.7902 - acc: 0.6783 - entropy: 0.6784 - val_loss: 0.5923 - val_auc: 0.4972 - val_acc: 0.8696 - val_entropy: 0.5923\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.7501 - auc: 0.7255 - acc: 0.6609 - entropy: 0.7501 - val_loss: 0.4908 - val_auc: 0.5667 - val_acc: 0.8696 - val_entropy: 0.4908\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.6908 - auc: 0.7810 - acc: 0.6696 - entropy: 0.6908 - val_loss: 0.5324 - val_auc: 0.5159 - val_acc: 0.8696 - val_entropy: 0.5324\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.7104 - auc: 0.7625 - acc: 0.6696 - entropy: 0.7104 - val_loss: 0.4887 - val_auc: 0.5747 - val_acc: 0.8696 - val_entropy: 0.4887\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.7046 - auc: 0.7595 - acc: 0.6957 - entropy: 0.7046 - val_loss: 0.4898 - val_auc: 0.5379 - val_acc: 0.8696 - val_entropy: 0.4898\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.6977 - auc: 0.7581 - acc: 0.6957 - entropy: 0.6977 - val_loss: 0.5053 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.5053\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.6910 - auc: 0.7656 - acc: 0.6957 - entropy: 0.6910 - val_loss: 0.5015 - val_auc: 0.5977 - val_acc: 0.8696 - val_entropy: 0.5015\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.6972 - auc: 0.7555 - acc: 0.7043 - entropy: 0.6972 - val_loss: 0.4964 - val_auc: 0.4833 - val_acc: 0.8696 - val_entropy: 0.4964\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.6898 - auc: 0.7697 - acc: 0.6870 - entropy: 0.6898 - val_loss: 0.5012 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.5012\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.6976 - auc: 0.7528 - acc: 0.6783 - entropy: 0.6976 - val_loss: 0.5051 - val_auc: 0.5379 - val_acc: 0.8696 - val_entropy: 0.5051\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.6947 - auc: 0.7542 - acc: 0.6783 - entropy: 0.6947 - val_loss: 0.5065 - val_auc: 0.5278 - val_acc: 0.8696 - val_entropy: 0.5065\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6891 - auc: 0.7555 - acc: 0.7043 - entropy: 0.6891 - val_loss: 0.4931 - val_auc: 0.4873 - val_acc: 0.8696 - val_entropy: 0.4931\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.6899 - auc: 0.7671 - acc: 0.6957 - entropy: 0.6899 - val_loss: 0.5082 - val_auc: 0.5524 - val_acc: 0.8696 - val_entropy: 0.5082\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6832 - auc: 0.7757 - acc: 0.6870 - entropy: 0.6832 - val_loss: 0.5137 - val_auc: 0.4889 - val_acc: 0.8696 - val_entropy: 0.5137\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.6988 - auc: 0.7414 - acc: 0.6783 - entropy: 0.6988 - val_loss: 0.4982 - val_auc: 0.4417 - val_acc: 0.8696 - val_entropy: 0.4982\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.6674 - auc: 0.7918 - acc: 0.6957 - entropy: 0.6674 - val_loss: 0.5115 - val_auc: 0.4750 - val_acc: 0.8696 - val_entropy: 0.5115\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.6820 - auc: 0.7796 - acc: 0.6957 - entropy: 0.6820 - val_loss: 0.5098 - val_auc: 0.5250 - val_acc: 0.8696 - val_entropy: 0.5098\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.6543 - auc: 0.8101 - acc: 0.7043 - entropy: 0.6543 - val_loss: 0.5181 - val_auc: 0.5278 - val_acc: 0.8696 - val_entropy: 0.5181\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.7011 - auc: 0.7522 - acc: 0.7043 - entropy: 0.7011 - val_loss: 0.4983 - val_auc: 0.5250 - val_acc: 0.8696 - val_entropy: 0.4983\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4983 - auc: 0.5250 - acc: 0.8696 - entropy: 0.4983\n",
      "Epoch 1/20\n",
      "8/8 - 4s - loss: 1.0614 - auc: 0.5090 - acc: 0.4261 - entropy: 1.0614 - val_loss: 0.6706 - val_auc: 0.5119 - val_acc: 0.8696 - val_entropy: 0.6706\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 0.6842 - auc: 0.7807 - acc: 0.6696 - entropy: 0.6842 - val_loss: 0.6179 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.6179\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.7442 - auc: 0.7355 - acc: 0.6609 - entropy: 0.7442 - val_loss: 0.4845 - val_auc: 0.5606 - val_acc: 0.8696 - val_entropy: 0.4845\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.6935 - auc: 0.7768 - acc: 0.6783 - entropy: 0.6935 - val_loss: 0.5340 - val_auc: 0.6438 - val_acc: 0.8696 - val_entropy: 0.5340\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.7090 - auc: 0.7670 - acc: 0.6783 - entropy: 0.7090 - val_loss: 0.4957 - val_auc: 0.5250 - val_acc: 0.8696 - val_entropy: 0.4957\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.7075 - auc: 0.7481 - acc: 0.6870 - entropy: 0.7075 - val_loss: 0.5036 - val_auc: 0.4889 - val_acc: 0.8696 - val_entropy: 0.5036\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.7033 - auc: 0.7541 - acc: 0.7130 - entropy: 0.7033 - val_loss: 0.4993 - val_auc: 0.5289 - val_acc: 0.8696 - val_entropy: 0.4993\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.6972 - auc: 0.7541 - acc: 0.7130 - entropy: 0.6972 - val_loss: 0.4970 - val_auc: 0.5417 - val_acc: 0.8696 - val_entropy: 0.4970\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.6966 - auc: 0.7505 - acc: 0.6957 - entropy: 0.6966 - val_loss: 0.5027 - val_auc: 0.4667 - val_acc: 0.8696 - val_entropy: 0.5027\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.6863 - auc: 0.7697 - acc: 0.6957 - entropy: 0.6863 - val_loss: 0.4993 - val_auc: 0.5476 - val_acc: 0.8696 - val_entropy: 0.4993\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.6904 - auc: 0.7676 - acc: 0.6870 - entropy: 0.6904 - val_loss: 0.4992 - val_auc: 0.6005 - val_acc: 0.8696 - val_entropy: 0.4992\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.6991 - auc: 0.7444 - acc: 0.6870 - entropy: 0.6991 - val_loss: 0.4940 - val_auc: 0.5477 - val_acc: 0.8696 - val_entropy: 0.4940\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6847 - auc: 0.7749 - acc: 0.6957 - entropy: 0.6847 - val_loss: 0.5168 - val_auc: 0.5238 - val_acc: 0.8696 - val_entropy: 0.5168\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.7081 - auc: 0.7403 - acc: 0.6783 - entropy: 0.7081 - val_loss: 0.4930 - val_auc: 0.5500 - val_acc: 0.8696 - val_entropy: 0.4930\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6838 - auc: 0.7764 - acc: 0.6783 - entropy: 0.6838 - val_loss: 0.5270 - val_auc: 0.5227 - val_acc: 0.8696 - val_entropy: 0.5270\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.7052 - auc: 0.7586 - acc: 0.6870 - entropy: 0.7052 - val_loss: 0.4892 - val_auc: 0.5500 - val_acc: 0.8696 - val_entropy: 0.4892\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.6935 - auc: 0.7725 - acc: 0.6957 - entropy: 0.6935 - val_loss: 0.5201 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.5201\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.7188 - auc: 0.7402 - acc: 0.7043 - entropy: 0.7188 - val_loss: 0.5020 - val_auc: 0.4917 - val_acc: 0.8696 - val_entropy: 0.5020\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.6901 - auc: 0.7666 - acc: 0.6696 - entropy: 0.6901 - val_loss: 0.4941 - val_auc: 0.4960 - val_acc: 0.8696 - val_entropy: 0.4941\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.6983 - auc: 0.7458 - acc: 0.7130 - entropy: 0.6983 - val_loss: 0.5049 - val_auc: 0.4417 - val_acc: 0.8696 - val_entropy: 0.5049\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5049 - auc: 0.4417 - acc: 0.8696 - entropy: 0.5049\n",
      "auc : average=0.504, std=0.045\n",
      "acc : average=0.870, std=0.000\n",
      "entropy : average=0.500, std=0.003\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3715b7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.4792 - auc: 0.5696 - acc: 0.5217 - entropy: 1.0260 - val_loss: 0.6800 - val_auc: 0.4917 - val_acc: 0.8696 - val_entropy: 0.6800\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.2457 - auc: 0.7666 - acc: 0.6783 - entropy: 0.7476 - val_loss: 0.6208 - val_auc: 0.4750 - val_acc: 0.8696 - val_entropy: 0.6208\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.1442 - auc: 0.7757 - acc: 0.7043 - entropy: 0.8361 - val_loss: 0.6402 - val_auc: 0.5106 - val_acc: 0.8696 - val_entropy: 0.6402\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.1129 - auc: 0.7701 - acc: 0.7043 - entropy: 0.8199 - val_loss: 0.5885 - val_auc: 0.5099 - val_acc: 0.8696 - val_entropy: 0.5885\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.0543 - auc: 0.7858 - acc: 0.6870 - entropy: 0.8641 - val_loss: 0.5984 - val_auc: 0.5444 - val_acc: 0.8696 - val_entropy: 0.5984\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.1393 - auc: 0.7348 - acc: 0.6783 - entropy: 0.9300 - val_loss: 0.6917 - val_auc: 0.5405 - val_acc: 0.8696 - val_entropy: 0.6917\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.0356 - auc: 0.7819 - acc: 0.6957 - entropy: 0.9019 - val_loss: 0.6172 - val_auc: 0.5470 - val_acc: 0.8696 - val_entropy: 0.6172\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.0801 - auc: 0.7558 - acc: 0.7130 - entropy: 0.8555 - val_loss: 0.6250 - val_auc: 0.5045 - val_acc: 0.8696 - val_entropy: 0.6250\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.0041 - auc: 0.7817 - acc: 0.6957 - entropy: 0.8840 - val_loss: 0.5950 - val_auc: 0.4889 - val_acc: 0.8696 - val_entropy: 0.5950\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.0617 - auc: 0.7678 - acc: 0.7043 - entropy: 0.8706 - val_loss: 0.6064 - val_auc: 0.5625 - val_acc: 0.8696 - val_entropy: 0.6064\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.0436 - auc: 0.7655 - acc: 0.6783 - entropy: 0.8809 - val_loss: 0.6374 - val_auc: 0.5234 - val_acc: 0.8696 - val_entropy: 0.6374\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 2.9135 - auc: 0.8105 - acc: 0.7391 - entropy: 0.8501 - val_loss: 0.5665 - val_auc: 0.5689 - val_acc: 0.8696 - val_entropy: 0.5665\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 2.9665 - auc: 0.7988 - acc: 0.7304 - entropy: 0.8233 - val_loss: 0.5681 - val_auc: 0.4082 - val_acc: 0.8696 - val_entropy: 0.5681\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.0383 - auc: 0.7661 - acc: 0.7043 - entropy: 0.8947 - val_loss: 0.6829 - val_auc: 0.5455 - val_acc: 0.8696 - val_entropy: 0.6829\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.3110 - auc: 0.7211 - acc: 0.6783 - entropy: 0.9927 - val_loss: 0.7295 - val_auc: 0.5587 - val_acc: 0.8696 - val_entropy: 0.7295\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 3.1895 - auc: 0.6914 - acc: 0.6696 - entropy: 0.8924 - val_loss: 0.6456 - val_auc: 0.6562 - val_acc: 0.8696 - val_entropy: 0.6456\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.0883 - auc: 0.7673 - acc: 0.6957 - entropy: 0.8350 - val_loss: 0.6076 - val_auc: 0.5444 - val_acc: 0.8696 - val_entropy: 0.6076\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.0708 - auc: 0.7685 - acc: 0.7217 - entropy: 0.8347 - val_loss: 0.6083 - val_auc: 0.5538 - val_acc: 0.8696 - val_entropy: 0.6083\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 3.0265 - auc: 0.7811 - acc: 0.7130 - entropy: 0.8247 - val_loss: 0.5972 - val_auc: 0.5863 - val_acc: 0.8696 - val_entropy: 0.5972\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 3.0334 - auc: 0.7715 - acc: 0.7043 - entropy: 0.8643 - val_loss: 0.6351 - val_auc: 0.4875 - val_acc: 0.8696 - val_entropy: 0.6351\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6351 - auc: 0.4875 - acc: 0.8696 - entropy: 0.6351\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.4916 - auc: 0.5917 - acc: 0.4957 - entropy: 1.0329 - val_loss: 0.6399 - val_auc: 0.4524 - val_acc: 0.8696 - val_entropy: 0.6399\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.2676 - auc: 0.7634 - acc: 0.6957 - entropy: 0.7493 - val_loss: 0.6231 - val_auc: 0.5833 - val_acc: 0.8696 - val_entropy: 0.6231\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.1473 - auc: 0.7597 - acc: 0.7043 - entropy: 0.8539 - val_loss: 0.6719 - val_auc: 0.5500 - val_acc: 0.8696 - val_entropy: 0.6719\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.1026 - auc: 0.7704 - acc: 0.7043 - entropy: 0.8513 - val_loss: 0.5879 - val_auc: 0.5278 - val_acc: 0.8696 - val_entropy: 0.5879\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.1067 - auc: 0.7572 - acc: 0.7304 - entropy: 0.8745 - val_loss: 0.6202 - val_auc: 0.6127 - val_acc: 0.8696 - val_entropy: 0.6202\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.0888 - auc: 0.7479 - acc: 0.7043 - entropy: 0.9038 - val_loss: 0.6586 - val_auc: 0.6379 - val_acc: 0.8696 - val_entropy: 0.6586\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.0724 - auc: 0.7598 - acc: 0.6870 - entropy: 0.9016 - val_loss: 0.6246 - val_auc: 0.5977 - val_acc: 0.8696 - val_entropy: 0.6246\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.0666 - auc: 0.7723 - acc: 0.7043 - entropy: 0.8807 - val_loss: 0.6070 - val_auc: 0.5750 - val_acc: 0.8696 - val_entropy: 0.6070\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.0465 - auc: 0.7786 - acc: 0.7043 - entropy: 0.8739 - val_loss: 0.6081 - val_auc: 0.5258 - val_acc: 0.8696 - val_entropy: 0.6081\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 3.0189 - auc: 0.7903 - acc: 0.6783 - entropy: 0.8579 - val_loss: 0.5930 - val_auc: 0.5030 - val_acc: 0.8696 - val_entropy: 0.5930\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.0767 - auc: 0.7576 - acc: 0.6957 - entropy: 0.8735 - val_loss: 0.6459 - val_auc: 0.5319 - val_acc: 0.8696 - val_entropy: 0.6459\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 2.9867 - auc: 0.7800 - acc: 0.7043 - entropy: 0.9056 - val_loss: 0.6207 - val_auc: 0.5667 - val_acc: 0.8696 - val_entropy: 0.6207\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 2.9804 - auc: 0.7983 - acc: 0.7130 - entropy: 0.8316 - val_loss: 0.5647 - val_auc: 0.5288 - val_acc: 0.8696 - val_entropy: 0.5647\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.0388 - auc: 0.7604 - acc: 0.6957 - entropy: 0.8939 - val_loss: 0.6980 - val_auc: 0.4946 - val_acc: 0.8696 - val_entropy: 0.6980\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.1534 - auc: 0.7454 - acc: 0.6522 - entropy: 0.9862 - val_loss: 0.7578 - val_auc: 0.4587 - val_acc: 0.8696 - val_entropy: 0.7578\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 3.1621 - auc: 0.7191 - acc: 0.6870 - entropy: 0.9015 - val_loss: 0.5936 - val_auc: 0.4947 - val_acc: 0.8696 - val_entropy: 0.5936\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.0017 - auc: 0.8013 - acc: 0.6957 - entropy: 0.7827 - val_loss: 0.5611 - val_auc: 0.6479 - val_acc: 0.8696 - val_entropy: 0.5611\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.0050 - auc: 0.7934 - acc: 0.7217 - entropy: 0.8349 - val_loss: 0.5800 - val_auc: 0.5979 - val_acc: 0.8696 - val_entropy: 0.5800\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 3.0481 - auc: 0.7664 - acc: 0.7043 - entropy: 0.8404 - val_loss: 0.6282 - val_auc: 0.5506 - val_acc: 0.8696 - val_entropy: 0.6282\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 2.9416 - auc: 0.8001 - acc: 0.7217 - entropy: 0.8574 - val_loss: 0.5730 - val_auc: 0.5038 - val_acc: 0.8696 - val_entropy: 0.5730\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5730 - auc: 0.5038 - acc: 0.8696 - entropy: 0.5730\n",
      "Epoch 1/20\n",
      "8/8 - 5s - loss: 3.4854 - auc: 0.5686 - acc: 0.4522 - entropy: 1.0341 - val_loss: 0.6888 - val_auc: 0.5714 - val_acc: 0.8696 - val_entropy: 0.6888\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.2704 - auc: 0.7521 - acc: 0.6870 - entropy: 0.7662 - val_loss: 0.6231 - val_auc: 0.5278 - val_acc: 0.8696 - val_entropy: 0.6231\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 3.1735 - auc: 0.7541 - acc: 0.7043 - entropy: 0.8491 - val_loss: 0.6379 - val_auc: 0.5000 - val_acc: 0.8696 - val_entropy: 0.6379\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 3.0970 - auc: 0.7657 - acc: 0.7217 - entropy: 0.8248 - val_loss: 0.6018 - val_auc: 0.5369 - val_acc: 0.8696 - val_entropy: 0.6018\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 3.1009 - auc: 0.7535 - acc: 0.6870 - entropy: 0.8940 - val_loss: 0.6400 - val_auc: 0.6462 - val_acc: 0.8696 - val_entropy: 0.6400\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 3.1171 - auc: 0.7321 - acc: 0.7043 - entropy: 0.9350 - val_loss: 0.6655 - val_auc: 0.5545 - val_acc: 0.8696 - val_entropy: 0.6655\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 3.0191 - auc: 0.7913 - acc: 0.6696 - entropy: 0.8945 - val_loss: 0.6046 - val_auc: 0.5508 - val_acc: 0.8696 - val_entropy: 0.6046\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 3.0887 - auc: 0.7600 - acc: 0.7043 - entropy: 0.8490 - val_loss: 0.6475 - val_auc: 0.6348 - val_acc: 0.8696 - val_entropy: 0.6475\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.0617 - auc: 0.7565 - acc: 0.6957 - entropy: 0.9053 - val_loss: 0.6681 - val_auc: 0.5361 - val_acc: 0.8696 - val_entropy: 0.6681\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 2.9879 - auc: 0.7951 - acc: 0.7043 - entropy: 0.8564 - val_loss: 0.5674 - val_auc: 0.5260 - val_acc: 0.8696 - val_entropy: 0.5674\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 3.0070 - auc: 0.7865 - acc: 0.7043 - entropy: 0.8560 - val_loss: 0.5836 - val_auc: 0.6307 - val_acc: 0.8696 - val_entropy: 0.5836\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 3.0229 - auc: 0.7974 - acc: 0.6957 - entropy: 0.8676 - val_loss: 0.6339 - val_auc: 0.5805 - val_acc: 0.8696 - val_entropy: 0.6339\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 3.3405 - auc: 0.7144 - acc: 0.6609 - entropy: 0.9664 - val_loss: 0.6436 - val_auc: 0.6015 - val_acc: 0.8696 - val_entropy: 0.6436\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 3.0545 - auc: 0.7729 - acc: 0.7043 - entropy: 0.8380 - val_loss: 0.5976 - val_auc: 0.4542 - val_acc: 0.8696 - val_entropy: 0.5976\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 3.1334 - auc: 0.7546 - acc: 0.6957 - entropy: 0.8604 - val_loss: 0.6709 - val_auc: 0.5214 - val_acc: 0.8696 - val_entropy: 0.6709\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 2.9727 - auc: 0.8037 - acc: 0.6870 - entropy: 0.8706 - val_loss: 0.5611 - val_auc: 0.6091 - val_acc: 0.8696 - val_entropy: 0.5611\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 3.1729 - auc: 0.7567 - acc: 0.6870 - entropy: 0.8461 - val_loss: 0.7183 - val_auc: 0.5197 - val_acc: 0.8696 - val_entropy: 0.7183\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 3.0745 - auc: 0.7712 - acc: 0.6522 - entropy: 1.0089 - val_loss: 0.7567 - val_auc: 0.5528 - val_acc: 0.8696 - val_entropy: 0.7567\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 2.9260 - auc: 0.8100 - acc: 0.7130 - entropy: 0.8565 - val_loss: 0.5309 - val_auc: 0.6488 - val_acc: 0.8696 - val_entropy: 0.5309\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 3.0893 - auc: 0.7767 - acc: 0.7217 - entropy: 0.8085 - val_loss: 0.5924 - val_auc: 0.5058 - val_acc: 0.8696 - val_entropy: 0.5924\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5924 - auc: 0.5058 - acc: 0.8696 - entropy: 0.5924\n",
      "auc : average=0.499, std=0.008\n",
      "acc : average=0.870, std=0.000\n",
      "entropy : average=0.600, std=0.026\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e7724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
