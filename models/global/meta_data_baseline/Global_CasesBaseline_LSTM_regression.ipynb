{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a84dcba",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f257abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e62cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3eceef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'Tabular_data/dengue_tabular.csv'\n",
    "Municipalities = ['Medellín', 'Cali', 'Villavicencio', 'Cúcuta', 'Ibagué']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ccf50",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa15f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5a4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d4510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "        \n",
    "        df.index = pd.to_numeric(df.index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0a60b",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ffc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = [read_labels(path=labels, Municipality=municipality) for municipality in Municipalities]\n",
    "#labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217aace",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0248137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = labels_df\n",
    "#dengue_df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3de52",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78023e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e4c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (132, 1025)\n",
      "The test shape is: (33, 1025)\n",
      "The train shape is: (132, 1025)\n",
      "The test shape is: (33, 1025)\n",
      "The train shape is: (132, 1025)\n",
      "The test shape is: (33, 1025)\n",
      "The train shape is: (132, 1025)\n",
      "The test shape is: (33, 1025)\n",
      "The train shape is: (132, 1025)\n",
      "The test shape is: (33, 1025)\n"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "test_df = []\n",
    "\n",
    "for i in range(len(dengue_df)):\n",
    "    train_df_aux, test_df_aux = train_test_split(dengue_df[i], train_percentage = 80)\n",
    "    train_df.append(train_df_aux)\n",
    "    test_df.append(test_df_aux)\n",
    "#test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fdace",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fafd65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), scaler=True):\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, scaler=True):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "        \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c95bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge:\n",
    "train_df = pd.concat([train_df[0], train_df[1], train_df[2], train_df[3], train_df[4]], keys=Municipalities)\n",
    "test_df = pd.concat([test_df[0], test_df[1], test_df[2], test_df[3], test_df[4]], keys=Municipalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aac00159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0        -1.0\n",
      "1        -1.0\n",
      "2        -1.0\n",
      "3        -1.0\n",
      "4        -1.0\n",
      "         ... \n",
      "1020     -1.0\n",
      "1021     -1.0\n",
      "1022     -1.0\n",
      "1023     -1.0\n",
      "Labels   -1.0\n",
      "Length: 1025, dtype: float64\n",
      " Max values are: \n",
      "0        -1.0\n",
      "1         1.0\n",
      "2        -1.0\n",
      "3        -1.0\n",
      "4         1.0\n",
      "         ... \n",
      "1020      1.0\n",
      "1021      1.0\n",
      "1022      1.0\n",
      "1023      1.0\n",
      "Labels    1.0\n",
      "Length: 1025, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Medellín</th>\n",
       "      <th>201544</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57639</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.860931</td>\n",
       "      <td>-0.209915</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.758662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.57639</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.860931</td>\n",
       "      <td>-0.209915</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.715651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.777743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32718</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.765288</td>\n",
       "      <td>-0.970793</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.753883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.777743</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.32718</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.765288</td>\n",
       "      <td>-0.970793</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.772999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.95999</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.928244</td>\n",
       "      <td>-0.956246</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.682198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0        1    2    3    4    5    6    7         8    9  \\\n",
       "Medellín 201544 -1.0 -1.00000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.000000 -1.0   \n",
       "         201545 -1.0 -1.00000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.000000 -1.0   \n",
       "         201546 -1.0 -1.00000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -0.777743 -1.0   \n",
       "         201547 -1.0 -1.00000 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -0.777743 -1.0   \n",
       "         201548 -1.0 -0.95999 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.000000 -1.0   \n",
       "\n",
       "                 ...     1015  1016  1017  1018  1019      1020      1021  \\\n",
       "Medellín 201544  ... -0.57639  -1.0  -1.0  -1.0  -1.0 -0.860931 -0.209915   \n",
       "         201545  ... -0.57639  -1.0  -1.0  -1.0  -1.0 -0.860931 -0.209915   \n",
       "         201546  ... -0.32718  -1.0  -1.0  -1.0  -1.0 -0.765288 -0.970793   \n",
       "         201547  ... -0.32718  -1.0  -1.0  -1.0  -1.0 -0.765288 -0.970793   \n",
       "         201548  ... -1.00000  -1.0  -1.0  -1.0  -1.0 -0.928244 -0.956246   \n",
       "\n",
       "                 1022  1023    Labels  \n",
       "Medellín 201544  -1.0  -1.0 -0.758662  \n",
       "         201545  -1.0  -1.0 -0.715651  \n",
       "         201546  -1.0  -1.0 -0.753883  \n",
       "         201547  -1.0  -1.0 -0.772999  \n",
       "         201548  -1.0  -1.0 -0.682198  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range)\n",
    "train_df = [train_df[train_df.index.get_level_values(0) == municipality] for municipality in Municipalities]\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4043b2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0        -1.000000\n",
      "1        -1.000000\n",
      "2        -1.000000\n",
      "3        -1.000000\n",
      "4        -1.000000\n",
      "            ...   \n",
      "1020     -1.000000\n",
      "1021     -1.000000\n",
      "1022     -1.000000\n",
      "1023     -1.000000\n",
      "Labels   -0.992832\n",
      "Length: 1025, dtype: float64\n",
      " Max values are: \n",
      "0        -1.000000\n",
      "1         0.901489\n",
      "2        -1.000000\n",
      "3        -1.000000\n",
      "4         0.368049\n",
      "            ...   \n",
      "1020      0.600774\n",
      "1021      1.247058\n",
      "1022      0.933052\n",
      "1023     -1.000000\n",
      "Labels   -0.569892\n",
      "Length: 1025, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Medellín</th>\n",
       "      <th>201820</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.188178</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.139095</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.130241</td>\n",
       "      <td>0.259938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.462724</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.099275</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.992644</td>\n",
       "      <td>0.221404</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.658391</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.300150</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.298219</td>\n",
       "      <td>-0.342267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341122</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.498781</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.873163</td>\n",
       "      <td>-0.400018</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.964158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.802239</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.974172</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.959379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.950289</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.689458</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.949821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307777</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.952210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0    1    2    3         4    5         6    7         8  \\\n",
       "Medellín 201820 -1.0 -1.0 -1.0 -1.0 -0.188178 -1.0  0.139095 -1.0  0.130241   \n",
       "         201821 -1.0 -1.0 -1.0 -1.0 -0.658391 -1.0 -0.300150 -1.0 -0.298219   \n",
       "         201822 -1.0 -1.0 -1.0 -1.0 -1.000000 -1.0 -1.000000 -1.0 -1.000000   \n",
       "         201823 -1.0 -1.0 -1.0 -1.0 -1.000000 -1.0 -1.000000 -1.0 -1.000000   \n",
       "         201824 -1.0 -1.0 -1.0 -1.0 -1.000000 -1.0 -1.000000 -1.0 -1.000000   \n",
       "\n",
       "                        9  ...      1015  1016      1017  1018  1019  1020  \\\n",
       "Medellín 201820  0.259938  ... -0.462724  -1.0 -0.099275  -1.0  -1.0  -1.0   \n",
       "         201821 -0.342267  ... -0.341122  -1.0 -0.498781  -1.0  -1.0  -1.0   \n",
       "         201822 -1.000000  ... -0.802239  -1.0 -1.000000  -1.0  -1.0  -1.0   \n",
       "         201823 -1.000000  ... -0.950289  -1.0 -1.000000  -1.0  -1.0  -1.0   \n",
       "         201824 -1.000000  ... -0.307777  -1.0 -1.000000  -1.0  -1.0  -1.0   \n",
       "\n",
       "                     1021      1022  1023    Labels  \n",
       "Medellín 201820 -0.992644  0.221404  -1.0 -0.954600  \n",
       "         201821 -0.873163 -0.400018  -1.0 -0.964158  \n",
       "         201822 -0.974172 -1.000000  -1.0 -0.959379  \n",
       "         201823 -0.689458 -1.000000  -1.0 -0.949821  \n",
       "         201824 -1.000000 -1.000000  -1.0 -0.952210  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers)\n",
    "test_df = [test_df[test_df.index.get_level_values(0) == municipality] for municipality in Municipalities]\n",
    "\n",
    "test_df[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27be9d",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12c2f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True, no_autoregressive=None):\n",
    "    if no_autoregressive:\n",
    "        n_in = n_in - 1\n",
    "        \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        if no_autoregressive:\n",
    "            cols.append(df.shift(i).iloc[:,:-1])\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars-1)]\n",
    "        else:\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07eee698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "no_autoregressive = True\n",
    "\n",
    "# frame as supervised learning\n",
    "train = [series_to_supervised(df, n_in=days, no_autoregressive=no_autoregressive) for df in train_df]\n",
    "test = [series_to_supervised(df, n_in=days, no_autoregressive=no_autoregressive) for df in test_df]\n",
    "\n",
    "#DataFrame(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec4e79",
   "metadata": {},
   "source": [
    "### Merge train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49d8de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge:\n",
    "train = pd.concat([train[0], train[1], train[2], train[3], train[4]], keys=Municipalities)\n",
    "test = pd.concat([test[0], test[1], test[2], test[3], test[4]], keys=Municipalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0428d264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615, 10241)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4454d9c",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c004da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (Cases and media cloud)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-1])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use Covid cases in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-1])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7fd486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (615, 10240)\n",
      "The shape of the labels is (615, 1)\n",
      "Test:\n",
      "The shape of the features is (120, 10240)\n",
      "The shape of the labels is (120, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df[0])\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef9195",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92e954f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features, no_autoregressive=None):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    if no_autoregressive:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features-1))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features-1))\n",
    "    \n",
    "    else:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54ff1239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (615, 10240)\n",
      "The test shape is (120, 10240)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (615, 10, 1024)\n",
      "The test shape is (120, 10, 1024)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features, no_autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa6786f",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39990ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    epsilon = 0.1\n",
    "    summ = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
    "    smape = K.abs(y_pred - y_true) / summ * 2.0\n",
    "    return smape\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "        tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "        smape\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba31573",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b8ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e378009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, plot=None, epochs=50):\n",
    "    if monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44915e3d",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25578489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "def test_model(model, test_X, test_y, scaler, rnn = None):\n",
    "    \n",
    "    # If model is a classical machine learning model and test_X is a 3D tensor, then convert to 2D\n",
    "    if not rnn and (len(test_X.shape) == 3):\n",
    "        test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "    \n",
    "    # do the prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    # Invert scaling for forecast\n",
    "    # Inverse Scaler\n",
    "    \n",
    "    # Predicted\n",
    "    if not rnn:\n",
    "        yhat = yhat.reshape(-1, 1)\n",
    "        \n",
    "    if not scaler:\n",
    "        return yhat, test_y\n",
    "    \n",
    "    inv_yhat = scaler.inverse_transform(yhat)\n",
    "    \n",
    "    # Real:\n",
    "    inv_y = scaler.inverse_transform(test_y)\n",
    "    \n",
    "    return inv_yhat, inv_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f6c24",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "$$\n",
    "MAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n}\\left |\\frac{x_i-y_i}{y_t}\\right|\n",
    "$$\n",
    "\n",
    "MAPE has a problem if there are zeros in the test data, so other metrics can be explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d3d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Test MAPE: %.3f' % mape)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf664e",
   "metadata": {},
   "source": [
    "### Symmetric Mean Absolute Percentage Error (sMAPE)\n",
    "\n",
    "$$\n",
    "sMAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n} \\frac{|x_i-y_i|}{|x_i|+|y_t|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e632c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    smape = 1/len(y_true) * np.sum(2 * np.abs(y_pred-y_true) / (np.abs(y_true) + np.abs(y_pred))*100)\n",
    "    print('Test sMAPE: %.3f' % smape)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bd2b3",
   "metadata": {},
   "source": [
    "### Mean Absoulte Error (MAE)\n",
    "$$\n",
    "RMSE = \\sqrt{(\\frac{1}{n})\\sum_{i=1}^{n}(x_i-y_i)^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61a3201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c20e0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(inv_y, inv_yhat, model_name = ''):\n",
    "    data_predict = inv_yhat  ## predicted target cases\n",
    "    dataY_plot = inv_y  ##  real test-target cases\n",
    "\n",
    "    data_predict = data_predict.reshape(len(data_predict), 1)\n",
    "    dataY_plot = dataY_plot.reshape(len(dataY_plot), 1)\n",
    "\n",
    "    plt.plot(dataY_plot, label = 'actual')\n",
    "    plt.plot(data_predict, label = 'predicted')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.suptitle(f'Time-Series Prediction with {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04690e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_X, test_y, scaler):\n",
    "    stored_results = {}\n",
    "    \n",
    "    inv_yhat_lstm, inv_y_lstm = test_model(model=model, test_X=test_X, test_y=test_y, scaler=y_scaler, rnn = True)\n",
    "    stored_results['mape'] = mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['smape'] = symmetric_mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['rmse'] = root_mean_squared_error(inv_y_lstm, inv_yhat_lstm)\n",
    "\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee16bd",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb7723ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With LSTM:\n",
    "#print(f'The scalers are: {scalers.keys()}')\n",
    "y_scaler = scalers['scaler_Labels']\n",
    "\n",
    "def calculate_mean_std():\n",
    "    \n",
    "    metrics = {\n",
    "        \"rmse\": [],\n",
    "        \"mape\": [],\n",
    "        \"smape\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor)\n",
    "        stored_results = evaluate(model, test_X, test_y, y_scaler)\n",
    "        print(stored_results)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "034f1cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "39/39 - 9s - loss: 0.4031 - rmse: 0.6349 - mape: 167.2044 - smape: 0.4874 - val_loss: 0.0170 - val_rmse: 0.1302 - val_mape: 11.5803 - val_smape: 0.0960\n",
      "Epoch 2/50\n",
      "39/39 - 1s - loss: 0.1638 - rmse: 0.4047 - mape: 100.0506 - smape: 0.4444 - val_loss: 0.0145 - val_rmse: 0.1205 - val_mape: 12.6547 - val_smape: 0.1226\n",
      "Epoch 3/50\n",
      "39/39 - 2s - loss: 0.1408 - rmse: 0.3752 - mape: 92.2614 - smape: 0.4016 - val_loss: 0.0125 - val_rmse: 0.1119 - val_mape: 11.6051 - val_smape: 0.1106\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1383 - rmse: 0.3719 - mape: 91.1304 - smape: 0.4046 - val_loss: 0.0099 - val_rmse: 0.0996 - val_mape: 9.7881 - val_smape: 0.0904\n",
      "Epoch 5/50\n",
      "39/39 - 1s - loss: 0.1458 - rmse: 0.3818 - mape: 93.1419 - smape: 0.4094 - val_loss: 0.0091 - val_rmse: 0.0956 - val_mape: 7.7002 - val_smape: 0.0655\n",
      "Epoch 6/50\n",
      "39/39 - 2s - loss: 0.1574 - rmse: 0.3968 - mape: 97.3937 - smape: 0.4264 - val_loss: 0.0184 - val_rmse: 0.1355 - val_mape: 12.4244 - val_smape: 0.1032\n",
      "Epoch 7/50\n",
      "39/39 - 2s - loss: 0.1673 - rmse: 0.4091 - mape: 101.6418 - smape: 0.4281 - val_loss: 0.0233 - val_rmse: 0.1526 - val_mape: 14.8815 - val_smape: 0.1236\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1709 - rmse: 0.4134 - mape: 105.4251 - smape: 0.4207 - val_loss: 0.0301 - val_rmse: 0.1734 - val_mape: 17.7550 - val_smape: 0.1470\n",
      "Epoch 9/50\n",
      "39/39 - 1s - loss: 0.1804 - rmse: 0.4247 - mape: 111.3290 - smape: 0.4203 - val_loss: 0.0378 - val_rmse: 0.1944 - val_mape: 20.4687 - val_smape: 0.1686\n",
      "Epoch 10/50\n",
      "39/39 - 2s - loss: 0.1835 - rmse: 0.4284 - mape: 114.4774 - smape: 0.3982 - val_loss: 0.0318 - val_rmse: 0.1784 - val_mape: 18.4350 - val_smape: 0.1525\n",
      "Epoch 11/50\n",
      "39/39 - 2s - loss: 0.1794 - rmse: 0.4235 - mape: 115.1032 - smape: 0.3840 - val_loss: 0.0217 - val_rmse: 0.1472 - val_mape: 14.1568 - val_smape: 0.1176\n",
      "Epoch 12/50\n",
      "39/39 - 2s - loss: 0.1735 - rmse: 0.4165 - mape: 114.6051 - smape: 0.3721 - val_loss: 0.0148 - val_rmse: 0.1218 - val_mape: 10.2453 - val_smape: 0.0846\n",
      "Epoch 13/50\n",
      "39/39 - 2s - loss: 0.1658 - rmse: 0.4072 - mape: 112.8619 - smape: 0.3596 - val_loss: 0.0125 - val_rmse: 0.1119 - val_mape: 8.8201 - val_smape: 0.0727\n",
      "Epoch 14/50\n",
      "39/39 - 2s - loss: 0.1632 - rmse: 0.4040 - mape: 111.9049 - smape: 0.3554 - val_loss: 0.0113 - val_rmse: 0.1062 - val_mape: 8.1263 - val_smape: 0.0670\n",
      "Epoch 15/50\n",
      "39/39 - 2s - loss: 0.1607 - rmse: 0.4009 - mape: 111.9020 - smape: 0.3522 - val_loss: 0.0107 - val_rmse: 0.1033 - val_mape: 7.8142 - val_smape: 0.0646\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1582 - rmse: 0.3977 - mape: 110.8288 - smape: 0.3491 - val_loss: 0.0102 - val_rmse: 0.1008 - val_mape: 7.6348 - val_smape: 0.0633\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1567 - rmse: 0.3959 - mape: 109.5582 - smape: 0.3458 - val_loss: 0.0097 - val_rmse: 0.0984 - val_mape: 7.5270 - val_smape: 0.0628\n",
      "Epoch 18/50\n",
      "39/39 - 2s - loss: 0.1544 - rmse: 0.3930 - mape: 109.8312 - smape: 0.3426 - val_loss: 0.0095 - val_rmse: 0.0975 - val_mape: 7.5346 - val_smape: 0.0631\n",
      "Epoch 19/50\n",
      "39/39 - 1s - loss: 0.1544 - rmse: 0.3929 - mape: 108.8531 - smape: 0.3416 - val_loss: 0.0093 - val_rmse: 0.0966 - val_mape: 7.5139 - val_smape: 0.0632\n",
      "Epoch 20/50\n",
      "39/39 - 2s - loss: 0.1529 - rmse: 0.3911 - mape: 109.0252 - smape: 0.3389 - val_loss: 0.0093 - val_rmse: 0.0965 - val_mape: 7.5543 - val_smape: 0.0636\n",
      "Epoch 21/50\n",
      "39/39 - 1s - loss: 0.1523 - rmse: 0.3902 - mape: 108.8805 - smape: 0.3373 - val_loss: 0.0093 - val_rmse: 0.0963 - val_mape: 7.5808 - val_smape: 0.0639\n",
      "Epoch 22/50\n",
      "39/39 - 2s - loss: 0.1515 - rmse: 0.3893 - mape: 108.4548 - smape: 0.3359 - val_loss: 0.0094 - val_rmse: 0.0970 - val_mape: 7.5336 - val_smape: 0.0633\n",
      "Epoch 23/50\n",
      "39/39 - 1s - loss: 0.1501 - rmse: 0.3874 - mape: 107.8191 - smape: 0.3319 - val_loss: 0.0099 - val_rmse: 0.0994 - val_mape: 7.5838 - val_smape: 0.0632\n",
      "Epoch 24/50\n",
      "39/39 - 2s - loss: 0.1526 - rmse: 0.3906 - mape: 108.6078 - smape: 0.3393 - val_loss: 0.0090 - val_rmse: 0.0947 - val_mape: 7.6183 - val_smape: 0.0648\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test MAPE: 165.318\n",
      "Test sMAPE: 75.813\n",
      "Test RMSE: 41.670\n",
      "{'mape': 165.31799462797713, 'smape': 75.81304491555531, 'rmse': 41.67034123488713}\n",
      "Epoch 1/50\n",
      "39/39 - 8s - loss: 0.5841 - rmse: 0.7642 - mape: 215.7627 - smape: 0.5350 - val_loss: 0.0123 - val_rmse: 0.1107 - val_mape: 11.4506 - val_smape: 0.1089\n",
      "Epoch 2/50\n",
      "39/39 - 2s - loss: 0.1419 - rmse: 0.3767 - mape: 94.2731 - smape: 0.4018 - val_loss: 0.0088 - val_rmse: 0.0936 - val_mape: 8.5234 - val_smape: 0.0761\n",
      "Epoch 3/50\n",
      "39/39 - 1s - loss: 0.1504 - rmse: 0.3878 - mape: 97.2233 - smape: 0.4148 - val_loss: 0.0130 - val_rmse: 0.1142 - val_mape: 11.8897 - val_smape: 0.1139\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1380 - rmse: 0.3715 - mape: 92.5958 - smape: 0.3967 - val_loss: 0.0101 - val_rmse: 0.1003 - val_mape: 9.9347 - val_smape: 0.0919\n",
      "Epoch 5/50\n",
      "39/39 - 2s - loss: 0.1470 - rmse: 0.3835 - mape: 94.8884 - smape: 0.4103 - val_loss: 0.0091 - val_rmse: 0.0954 - val_mape: 7.6954 - val_smape: 0.0655\n",
      "Epoch 6/50\n",
      "39/39 - 1s - loss: 0.1621 - rmse: 0.4026 - mape: 98.2735 - smape: 0.4344 - val_loss: 0.0178 - val_rmse: 0.1333 - val_mape: 11.9722 - val_smape: 0.0993\n",
      "Epoch 7/50\n",
      "39/39 - 1s - loss: 0.1699 - rmse: 0.4122 - mape: 102.6811 - smape: 0.4384 - val_loss: 0.0306 - val_rmse: 0.1751 - val_mape: 17.9050 - val_smape: 0.1482\n",
      "Epoch 8/50\n",
      "39/39 - 2s - loss: 0.1823 - rmse: 0.4269 - mape: 109.3389 - smape: 0.4330 - val_loss: 0.0372 - val_rmse: 0.1928 - val_mape: 20.2361 - val_smape: 0.1667\n",
      "Epoch 9/50\n",
      "39/39 - 2s - loss: 0.1838 - rmse: 0.4288 - mape: 112.7392 - smape: 0.4111 - val_loss: 0.0384 - val_rmse: 0.1959 - val_mape: 20.6460 - val_smape: 0.1700\n",
      "Epoch 10/50\n",
      "39/39 - 1s - loss: 0.1819 - rmse: 0.4265 - mape: 114.7251 - smape: 0.3898 - val_loss: 0.0262 - val_rmse: 0.1617 - val_mape: 16.1724 - val_smape: 0.1342\n",
      "Epoch 11/50\n",
      "39/39 - 1s - loss: 0.1777 - rmse: 0.4216 - mape: 116.2759 - smape: 0.3785 - val_loss: 0.0153 - val_rmse: 0.1236 - val_mape: 10.4917 - val_smape: 0.0867\n",
      "Epoch 12/50\n",
      "39/39 - 1s - loss: 0.1678 - rmse: 0.4097 - mape: 113.3789 - smape: 0.3617 - val_loss: 0.0122 - val_rmse: 0.1107 - val_mape: 8.6460 - val_smape: 0.0712\n",
      "Epoch 13/50\n",
      "39/39 - 2s - loss: 0.1622 - rmse: 0.4027 - mape: 111.8075 - smape: 0.3533 - val_loss: 0.0110 - val_rmse: 0.1051 - val_mape: 8.0194 - val_smape: 0.0662\n",
      "Epoch 14/50\n",
      "39/39 - 1s - loss: 0.1591 - rmse: 0.3989 - mape: 109.4399 - smape: 0.3502 - val_loss: 0.0104 - val_rmse: 0.1017 - val_mape: 7.7383 - val_smape: 0.0642\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1577 - rmse: 0.3971 - mape: 110.4949 - smape: 0.3475 - val_loss: 0.0099 - val_rmse: 0.0993 - val_mape: 7.6012 - val_smape: 0.0634\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1564 - rmse: 0.3954 - mape: 109.8847 - smape: 0.3461 - val_loss: 0.0094 - val_rmse: 0.0970 - val_mape: 7.6030 - val_smape: 0.0640\n",
      "Epoch 17/50\n",
      "39/39 - 2s - loss: 0.1552 - rmse: 0.3940 - mape: 109.3318 - smape: 0.3435 - val_loss: 0.0093 - val_rmse: 0.0965 - val_mape: 7.6241 - val_smape: 0.0644\n",
      "Epoch 18/50\n",
      "39/39 - 2s - loss: 0.1529 - rmse: 0.3911 - mape: 108.8185 - smape: 0.3402 - val_loss: 0.0092 - val_rmse: 0.0961 - val_mape: 7.6382 - val_smape: 0.0647\n",
      "Epoch 19/50\n",
      "39/39 - 1s - loss: 0.1523 - rmse: 0.3903 - mape: 109.0409 - smape: 0.3392 - val_loss: 0.0091 - val_rmse: 0.0956 - val_mape: 7.6569 - val_smape: 0.0650\n",
      "Epoch 20/50\n",
      "39/39 - 1s - loss: 0.1517 - rmse: 0.3895 - mape: 108.2998 - smape: 0.3384 - val_loss: 0.0092 - val_rmse: 0.0958 - val_mape: 7.6593 - val_smape: 0.0650\n",
      "Epoch 21/50\n",
      "39/39 - 2s - loss: 0.1511 - rmse: 0.3887 - mape: 107.9504 - smape: 0.3362 - val_loss: 0.0094 - val_rmse: 0.0969 - val_mape: 7.6659 - val_smape: 0.0647\n",
      "Epoch 22/50\n",
      "39/39 - 1s - loss: 0.1503 - rmse: 0.3877 - mape: 108.1798 - smape: 0.3349 - val_loss: 0.0096 - val_rmse: 0.0978 - val_mape: 7.6443 - val_smape: 0.0642\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "Test MAPE: 126.680\n",
      "Test sMAPE: 67.466\n",
      "Test RMSE: 39.157\n",
      "{'mape': 126.68044766963425, 'smape': 67.46611280407187, 'rmse': 39.15670125223055}\n",
      "Epoch 1/50\n",
      "39/39 - 8s - loss: 0.4498 - rmse: 0.6707 - mape: 181.6191 - smape: 0.4857 - val_loss: 0.0086 - val_rmse: 0.0928 - val_mape: 7.9077 - val_smape: 0.0690\n",
      "Epoch 2/50\n",
      "39/39 - 2s - loss: 0.1562 - rmse: 0.3952 - mape: 97.8515 - smape: 0.4310 - val_loss: 0.0148 - val_rmse: 0.1215 - val_mape: 12.7653 - val_smape: 0.1237\n",
      "Epoch 3/50\n",
      "39/39 - 2s - loss: 0.1446 - rmse: 0.3802 - mape: 93.5858 - smape: 0.4109 - val_loss: 0.0127 - val_rmse: 0.1127 - val_mape: 11.6999 - val_smape: 0.1117\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1445 - rmse: 0.3802 - mape: 90.7582 - smape: 0.4184 - val_loss: 0.0099 - val_rmse: 0.0992 - val_mape: 9.7166 - val_smape: 0.0896\n",
      "Epoch 5/50\n",
      "39/39 - 1s - loss: 0.1514 - rmse: 0.3891 - mape: 94.5618 - smape: 0.4193 - val_loss: 0.0098 - val_rmse: 0.0988 - val_mape: 7.6254 - val_smape: 0.0638\n",
      "Epoch 6/50\n",
      "39/39 - 1s - loss: 0.1638 - rmse: 0.4048 - mape: 99.5315 - smape: 0.4348 - val_loss: 0.0086 - val_rmse: 0.0927 - val_mape: 8.0226 - val_smape: 0.0704\n",
      "Epoch 7/50\n",
      "39/39 - 1s - loss: 0.1498 - rmse: 0.3871 - mape: 94.8038 - smape: 0.4120 - val_loss: 0.0143 - val_rmse: 0.1195 - val_mape: 9.8301 - val_smape: 0.0811\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1699 - rmse: 0.4121 - mape: 102.6373 - smape: 0.4253 - val_loss: 0.0147 - val_rmse: 0.1213 - val_mape: 10.1615 - val_smape: 0.0839\n",
      "Epoch 9/50\n",
      "39/39 - 2s - loss: 0.1633 - rmse: 0.4040 - mape: 101.5396 - smape: 0.4234 - val_loss: 0.0138 - val_rmse: 0.1175 - val_mape: 9.5887 - val_smape: 0.0791\n",
      "Epoch 10/50\n",
      "39/39 - 2s - loss: 0.1638 - rmse: 0.4047 - mape: 100.9077 - smape: 0.4200 - val_loss: 0.0201 - val_rmse: 0.1418 - val_mape: 13.3814 - val_smape: 0.1112\n",
      "Epoch 11/50\n",
      "39/39 - 1s - loss: 0.1672 - rmse: 0.4089 - mape: 103.0573 - smape: 0.4179 - val_loss: 0.0239 - val_rmse: 0.1544 - val_mape: 15.1848 - val_smape: 0.1261\n",
      "Epoch 12/50\n",
      "39/39 - 1s - loss: 0.1757 - rmse: 0.4192 - mape: 109.4974 - smape: 0.4134 - val_loss: 0.0289 - val_rmse: 0.1699 - val_mape: 17.2735 - val_smape: 0.1431\n",
      "Epoch 13/50\n",
      "39/39 - 1s - loss: 0.1790 - rmse: 0.4231 - mape: 112.2771 - smape: 0.3915 - val_loss: 0.0279 - val_rmse: 0.1670 - val_mape: 16.9049 - val_smape: 0.1402\n",
      "Epoch 14/50\n",
      "39/39 - 1s - loss: 0.1781 - rmse: 0.4220 - mape: 115.5884 - smape: 0.3830 - val_loss: 0.0161 - val_rmse: 0.1269 - val_mape: 11.0723 - val_smape: 0.0917\n",
      "Epoch 15/50\n",
      "39/39 - 2s - loss: 0.1678 - rmse: 0.4096 - mape: 112.3393 - smape: 0.3640 - val_loss: 0.0109 - val_rmse: 0.1046 - val_mape: 7.9504 - val_smape: 0.0656\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1608 - rmse: 0.4010 - mape: 111.0962 - smape: 0.3527 - val_loss: 0.0097 - val_rmse: 0.0986 - val_mape: 7.5157 - val_smape: 0.0627\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1577 - rmse: 0.3971 - mape: 110.5148 - smape: 0.3484 - val_loss: 0.0094 - val_rmse: 0.0968 - val_mape: 7.5034 - val_smape: 0.0630\n",
      "Epoch 18/50\n",
      "39/39 - 1s - loss: 0.1549 - rmse: 0.3936 - mape: 109.4328 - smape: 0.3446 - val_loss: 0.0091 - val_rmse: 0.0957 - val_mape: 7.5116 - val_smape: 0.0634\n",
      "Epoch 19/50\n",
      "39/39 - 2s - loss: 0.1537 - rmse: 0.3920 - mape: 108.9758 - smape: 0.3432 - val_loss: 0.0090 - val_rmse: 0.0948 - val_mape: 7.5299 - val_smape: 0.0639\n",
      "Epoch 20/50\n",
      "39/39 - 1s - loss: 0.1531 - rmse: 0.3912 - mape: 108.2553 - smape: 0.3429 - val_loss: 0.0088 - val_rmse: 0.0939 - val_mape: 7.5701 - val_smape: 0.0646\n",
      "Epoch 21/50\n",
      "39/39 - 1s - loss: 0.1524 - rmse: 0.3904 - mape: 108.7127 - smape: 0.3408 - val_loss: 0.0087 - val_rmse: 0.0933 - val_mape: 7.6396 - val_smape: 0.0657\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test MAPE: 105.152\n",
      "Test sMAPE: 62.102\n",
      "Test RMSE: 38.855\n",
      "{'mape': 105.15213946784382, 'smape': 62.10231163756866, 'rmse': 38.85482901150395}\n",
      "Epoch 1/50\n",
      "39/39 - 10s - loss: 0.4760 - rmse: 0.6899 - mape: 183.5762 - smape: 0.4923 - val_loss: 0.0126 - val_rmse: 0.1121 - val_mape: 8.8938 - val_smape: 0.0733\n",
      "Epoch 2/50\n",
      "39/39 - 1s - loss: 0.1597 - rmse: 0.3997 - mape: 97.1101 - smape: 0.4394 - val_loss: 0.0121 - val_rmse: 0.1099 - val_mape: 11.3295 - val_smape: 0.1075\n",
      "Epoch 3/50\n",
      "39/39 - 1s - loss: 0.1433 - rmse: 0.3785 - mape: 94.9194 - smape: 0.4031 - val_loss: 0.0143 - val_rmse: 0.1195 - val_mape: 12.5412 - val_smape: 0.1212\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1412 - rmse: 0.3757 - mape: 92.1706 - smape: 0.4095 - val_loss: 0.0119 - val_rmse: 0.1091 - val_mape: 11.2426 - val_smape: 0.1066\n",
      "Epoch 5/50\n",
      "39/39 - 1s - loss: 0.1477 - rmse: 0.3843 - mape: 94.7066 - smape: 0.4154 - val_loss: 0.0096 - val_rmse: 0.0980 - val_mape: 7.7242 - val_smape: 0.0651\n",
      "Epoch 6/50\n",
      "39/39 - 2s - loss: 0.1612 - rmse: 0.4015 - mape: 97.5338 - smape: 0.4350 - val_loss: 0.0124 - val_rmse: 0.1114 - val_mape: 8.7540 - val_smape: 0.0722\n",
      "Epoch 7/50\n",
      "39/39 - 1s - loss: 0.1608 - rmse: 0.4010 - mape: 98.3581 - smape: 0.4256 - val_loss: 0.0105 - val_rmse: 0.1025 - val_mape: 7.8302 - val_smape: 0.0650\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1658 - rmse: 0.4072 - mape: 100.3076 - smape: 0.4341 - val_loss: 0.0373 - val_rmse: 0.1932 - val_mape: 20.2741 - val_smape: 0.1670\n",
      "Epoch 9/50\n",
      "39/39 - 1s - loss: 0.1864 - rmse: 0.4318 - mape: 112.1345 - smape: 0.4307 - val_loss: 0.0411 - val_rmse: 0.2026 - val_mape: 21.4949 - val_smape: 0.1766\n",
      "Epoch 10/50\n",
      "39/39 - 2s - loss: 0.1836 - rmse: 0.4285 - mape: 113.5296 - smape: 0.4091 - val_loss: 0.0393 - val_rmse: 0.1981 - val_mape: 20.9283 - val_smape: 0.1722\n",
      "Epoch 11/50\n",
      "39/39 - 1s - loss: 0.1833 - rmse: 0.4281 - mape: 114.2433 - smape: 0.4015 - val_loss: 0.0310 - val_rmse: 0.1761 - val_mape: 18.0997 - val_smape: 0.1498\n",
      "Epoch 12/50\n",
      "39/39 - 1s - loss: 0.1807 - rmse: 0.4251 - mape: 115.5362 - smape: 0.3853 - val_loss: 0.0242 - val_rmse: 0.1557 - val_mape: 15.3456 - val_smape: 0.1274\n",
      "Epoch 13/50\n",
      "39/39 - 2s - loss: 0.1715 - rmse: 0.4142 - mape: 112.7366 - smape: 0.3695 - val_loss: 0.0265 - val_rmse: 0.1628 - val_mape: 16.3133 - val_smape: 0.1354\n",
      "Epoch 14/50\n",
      "39/39 - 2s - loss: 0.1754 - rmse: 0.4188 - mape: 114.9465 - smape: 0.3804 - val_loss: 0.0159 - val_rmse: 0.1261 - val_mape: 10.8824 - val_smape: 0.0900\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1691 - rmse: 0.4112 - mape: 113.9453 - smape: 0.3635 - val_loss: 0.0123 - val_rmse: 0.1110 - val_mape: 8.6930 - val_smape: 0.0716\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1616 - rmse: 0.4020 - mape: 111.2827 - smape: 0.3532 - val_loss: 0.0109 - val_rmse: 0.1044 - val_mape: 7.9309 - val_smape: 0.0655\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1583 - rmse: 0.3978 - mape: 110.5653 - smape: 0.3508 - val_loss: 0.0107 - val_rmse: 0.1036 - val_mape: 7.8602 - val_smape: 0.0650\n",
      "Epoch 18/50\n",
      "39/39 - 1s - loss: 0.1577 - rmse: 0.3971 - mape: 110.5822 - smape: 0.3477 - val_loss: 0.0101 - val_rmse: 0.1003 - val_mape: 7.6365 - val_smape: 0.0635\n",
      "Epoch 19/50\n",
      "39/39 - 2s - loss: 0.1576 - rmse: 0.3970 - mape: 110.5176 - smape: 0.3477 - val_loss: 0.0096 - val_rmse: 0.0980 - val_mape: 7.5793 - val_smape: 0.0635\n",
      "Epoch 20/50\n",
      "39/39 - 1s - loss: 0.1547 - rmse: 0.3934 - mape: 109.7090 - smape: 0.3437 - val_loss: 0.0097 - val_rmse: 0.0983 - val_mape: 7.5913 - val_smape: 0.0635\n",
      "Epoch 21/50\n",
      "39/39 - 1s - loss: 0.1556 - rmse: 0.3944 - mape: 109.9416 - smape: 0.3448 - val_loss: 0.0095 - val_rmse: 0.0974 - val_mape: 7.5904 - val_smape: 0.0638\n",
      "Epoch 22/50\n",
      "39/39 - 1s - loss: 0.1543 - rmse: 0.3929 - mape: 108.9847 - smape: 0.3426 - val_loss: 0.0093 - val_rmse: 0.0966 - val_mape: 7.5808 - val_smape: 0.0639\n",
      "Epoch 23/50\n",
      "39/39 - 2s - loss: 0.1522 - rmse: 0.3901 - mape: 109.1188 - smape: 0.3389 - val_loss: 0.0097 - val_rmse: 0.0982 - val_mape: 7.6184 - val_smape: 0.0638\n",
      "Epoch 24/50\n",
      "39/39 - 2s - loss: 0.1539 - rmse: 0.3923 - mape: 108.4370 - smape: 0.3391 - val_loss: 0.0099 - val_rmse: 0.0994 - val_mape: 7.5984 - val_smape: 0.0633\n",
      "Epoch 25/50\n",
      "39/39 - 1s - loss: 0.1505 - rmse: 0.3879 - mape: 107.3934 - smape: 0.3258 - val_loss: 0.0191 - val_rmse: 0.1383 - val_mape: 12.8106 - val_smape: 0.1064\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test MAPE: 74.289\n",
      "Test sMAPE: 59.909\n",
      "Test RMSE: 41.016\n",
      "{'mape': 74.28929171786433, 'smape': 59.90860288015601, 'rmse': 41.01648841119865}\n",
      "Epoch 1/50\n",
      "39/39 - 9s - loss: 0.4256 - rmse: 0.6524 - mape: 172.8704 - smape: 0.5087 - val_loss: 0.0112 - val_rmse: 0.1057 - val_mape: 10.7735 - val_smape: 0.1014\n",
      "Epoch 2/50\n",
      "39/39 - 1s - loss: 0.1474 - rmse: 0.3840 - mape: 95.1264 - smape: 0.4184 - val_loss: 0.0152 - val_rmse: 0.1232 - val_mape: 12.9629 - val_smape: 0.1261\n",
      "Epoch 3/50\n",
      "39/39 - 1s - loss: 0.1380 - rmse: 0.3714 - mape: 91.1593 - smape: 0.4030 - val_loss: 0.0109 - val_rmse: 0.1042 - val_mape: 10.5432 - val_smape: 0.0987\n",
      "Epoch 4/50\n",
      "39/39 - 2s - loss: 0.1427 - rmse: 0.3777 - mape: 93.3023 - smape: 0.4041 - val_loss: 0.0097 - val_rmse: 0.0987 - val_mape: 9.6147 - val_smape: 0.0883\n",
      "Epoch 5/50\n",
      "39/39 - 2s - loss: 0.1524 - rmse: 0.3904 - mape: 94.9664 - smape: 0.4237 - val_loss: 0.0131 - val_rmse: 0.1146 - val_mape: 9.1316 - val_smape: 0.0753\n",
      "Epoch 6/50\n",
      "39/39 - 1s - loss: 0.1694 - rmse: 0.4115 - mape: 101.1715 - smape: 0.4450 - val_loss: 0.0244 - val_rmse: 0.1563 - val_mape: 15.3672 - val_smape: 0.1276\n",
      "Epoch 7/50\n",
      "39/39 - 1s - loss: 0.1756 - rmse: 0.4190 - mape: 106.0992 - smape: 0.4378 - val_loss: 0.0289 - val_rmse: 0.1700 - val_mape: 17.2303 - val_smape: 0.1427\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1792 - rmse: 0.4233 - mape: 108.3462 - smape: 0.4297 - val_loss: 0.0301 - val_rmse: 0.1736 - val_mape: 17.7286 - val_smape: 0.1468\n",
      "Epoch 9/50\n",
      "39/39 - 2s - loss: 0.1786 - rmse: 0.4227 - mape: 110.2839 - smape: 0.4203 - val_loss: 0.0384 - val_rmse: 0.1961 - val_mape: 20.6535 - val_smape: 0.1700\n",
      "Epoch 10/50\n",
      "39/39 - 1s - loss: 0.1828 - rmse: 0.4276 - mape: 113.9694 - smape: 0.4067 - val_loss: 0.0332 - val_rmse: 0.1823 - val_mape: 18.8899 - val_smape: 0.1561\n",
      "Epoch 11/50\n",
      "39/39 - 1s - loss: 0.1821 - rmse: 0.4267 - mape: 115.4157 - smape: 0.3899 - val_loss: 0.0236 - val_rmse: 0.1535 - val_mape: 15.0209 - val_smape: 0.1248\n",
      "Epoch 12/50\n",
      "39/39 - 1s - loss: 0.1765 - rmse: 0.4202 - mape: 115.3786 - smape: 0.3770 - val_loss: 0.0161 - val_rmse: 0.1268 - val_mape: 11.0155 - val_smape: 0.0912\n",
      "Epoch 13/50\n",
      "39/39 - 1s - loss: 0.1688 - rmse: 0.4109 - mape: 113.4253 - smape: 0.3646 - val_loss: 0.0128 - val_rmse: 0.1130 - val_mape: 8.9578 - val_smape: 0.0738\n",
      "Epoch 14/50\n",
      "39/39 - 2s - loss: 0.1639 - rmse: 0.4048 - mape: 112.5583 - smape: 0.3580 - val_loss: 0.0117 - val_rmse: 0.1080 - val_mape: 8.3358 - val_smape: 0.0687\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1617 - rmse: 0.4021 - mape: 111.6909 - smape: 0.3541 - val_loss: 0.0108 - val_rmse: 0.1038 - val_mape: 7.8793 - val_smape: 0.0651\n",
      "Epoch 16/50\n",
      "39/39 - 2s - loss: 0.1588 - rmse: 0.3986 - mape: 110.4910 - smape: 0.3500 - val_loss: 0.0104 - val_rmse: 0.1019 - val_mape: 7.7441 - val_smape: 0.0642\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1578 - rmse: 0.3972 - mape: 110.5165 - smape: 0.3486 - val_loss: 0.0099 - val_rmse: 0.0997 - val_mape: 7.6239 - val_smape: 0.0635\n",
      "Epoch 18/50\n",
      "39/39 - 2s - loss: 0.1569 - rmse: 0.3961 - mape: 110.1176 - smape: 0.3463 - val_loss: 0.0099 - val_rmse: 0.0994 - val_mape: 7.6347 - val_smape: 0.0637\n",
      "Epoch 19/50\n",
      "39/39 - 1s - loss: 0.1547 - rmse: 0.3933 - mape: 109.1670 - smape: 0.3432 - val_loss: 0.0102 - val_rmse: 0.1010 - val_mape: 7.6788 - val_smape: 0.0638\n",
      "Epoch 20/50\n",
      "39/39 - 2s - loss: 0.1551 - rmse: 0.3938 - mape: 109.3364 - smape: 0.3442 - val_loss: 0.0099 - val_rmse: 0.0995 - val_mape: 7.6092 - val_smape: 0.0634\n",
      "Epoch 21/50\n",
      "39/39 - 1s - loss: 0.1540 - rmse: 0.3925 - mape: 108.8945 - smape: 0.3419 - val_loss: 0.0101 - val_rmse: 0.1006 - val_mape: 7.6967 - val_smape: 0.0640\n",
      "Epoch 22/50\n",
      "39/39 - 1s - loss: 0.1541 - rmse: 0.3925 - mape: 109.2169 - smape: 0.3419 - val_loss: 0.0100 - val_rmse: 0.1001 - val_mape: 7.6592 - val_smape: 0.0638\n",
      "Epoch 23/50\n",
      "39/39 - 1s - loss: 0.1537 - rmse: 0.3921 - mape: 108.8652 - smape: 0.3419 - val_loss: 0.0098 - val_rmse: 0.0990 - val_mape: 7.6324 - val_smape: 0.0638\n",
      "Epoch 24/50\n",
      "39/39 - 2s - loss: 0.1530 - rmse: 0.3911 - mape: 108.7840 - smape: 0.3406 - val_loss: 0.0097 - val_rmse: 0.0984 - val_mape: 7.6681 - val_smape: 0.0643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test MAPE: 159.001\n",
      "Test sMAPE: 74.963\n",
      "Test RMSE: 41.306\n",
      "{'mape': 159.00059223502112, 'smape': 74.96290338645419, 'rmse': 41.305510685134735}\n",
      "Epoch 1/50\n",
      "39/39 - 9s - loss: 0.4861 - rmse: 0.6972 - mape: 188.2265 - smape: 0.4830 - val_loss: 0.0343 - val_rmse: 0.1853 - val_mape: 19.2952 - val_smape: 0.1593\n",
      "Epoch 2/50\n",
      "39/39 - 1s - loss: 0.1779 - rmse: 0.4218 - mape: 98.1820 - smape: 0.4765 - val_loss: 0.0112 - val_rmse: 0.1056 - val_mape: 10.7654 - val_smape: 0.1012\n",
      "Epoch 3/50\n",
      "39/39 - 1s - loss: 0.1495 - rmse: 0.3867 - mape: 96.3260 - smape: 0.4045 - val_loss: 0.0087 - val_rmse: 0.0935 - val_mape: 7.9653 - val_smape: 0.0694\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1605 - rmse: 0.4006 - mape: 97.8232 - smape: 0.4366 - val_loss: 0.0089 - val_rmse: 0.0941 - val_mape: 7.9248 - val_smape: 0.0687\n",
      "Epoch 5/50\n",
      "39/39 - 2s - loss: 0.1578 - rmse: 0.3972 - mape: 94.4646 - smape: 0.4343 - val_loss: 0.0142 - val_rmse: 0.1193 - val_mape: 9.7514 - val_smape: 0.0804\n",
      "Epoch 6/50\n",
      "39/39 - 2s - loss: 0.1673 - rmse: 0.4090 - mape: 100.7875 - smape: 0.4287 - val_loss: 0.0278 - val_rmse: 0.1669 - val_mape: 16.8178 - val_smape: 0.1394\n",
      "Epoch 7/50\n",
      "39/39 - 1s - loss: 0.1797 - rmse: 0.4239 - mape: 109.2210 - smape: 0.4325 - val_loss: 0.0392 - val_rmse: 0.1980 - val_mape: 20.8902 - val_smape: 0.1718\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1874 - rmse: 0.4329 - mape: 114.4329 - smape: 0.4124 - val_loss: 0.0362 - val_rmse: 0.1904 - val_mape: 19.9415 - val_smape: 0.1644\n",
      "Epoch 9/50\n",
      "39/39 - 2s - loss: 0.1802 - rmse: 0.4245 - mape: 114.8190 - smape: 0.3921 - val_loss: 0.0274 - val_rmse: 0.1655 - val_mape: 16.6672 - val_smape: 0.1382\n",
      "Epoch 10/50\n",
      "39/39 - 1s - loss: 0.1775 - rmse: 0.4213 - mape: 116.2102 - smape: 0.3793 - val_loss: 0.0206 - val_rmse: 0.1436 - val_mape: 13.6087 - val_smape: 0.1131\n",
      "Epoch 11/50\n",
      "39/39 - 1s - loss: 0.1727 - rmse: 0.4155 - mape: 115.1149 - smape: 0.3701 - val_loss: 0.0158 - val_rmse: 0.1256 - val_mape: 10.8335 - val_smape: 0.0896\n",
      "Epoch 12/50\n",
      "39/39 - 1s - loss: 0.1666 - rmse: 0.4081 - mape: 112.2883 - smape: 0.3623 - val_loss: 0.0128 - val_rmse: 0.1133 - val_mape: 8.9951 - val_smape: 0.0741\n",
      "Epoch 13/50\n",
      "39/39 - 2s - loss: 0.1639 - rmse: 0.4049 - mape: 112.3874 - smape: 0.3584 - val_loss: 0.0121 - val_rmse: 0.1102 - val_mape: 8.5934 - val_smape: 0.0708\n",
      "Epoch 14/50\n",
      "39/39 - 2s - loss: 0.1616 - rmse: 0.4020 - mape: 112.3251 - smape: 0.3543 - val_loss: 0.0114 - val_rmse: 0.1067 - val_mape: 8.1734 - val_smape: 0.0674\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1576 - rmse: 0.3970 - mape: 111.1533 - smape: 0.3462 - val_loss: 0.0117 - val_rmse: 0.1080 - val_mape: 8.3247 - val_smape: 0.0686\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1584 - rmse: 0.3980 - mape: 111.1010 - smape: 0.3505 - val_loss: 0.0112 - val_rmse: 0.1056 - val_mape: 8.0532 - val_smape: 0.0664\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1590 - rmse: 0.3987 - mape: 110.9584 - smape: 0.3490 - val_loss: 0.0105 - val_rmse: 0.1023 - val_mape: 7.7484 - val_smape: 0.0642\n",
      "Epoch 18/50\n",
      "39/39 - 2s - loss: 0.1579 - rmse: 0.3974 - mape: 110.9206 - smape: 0.3491 - val_loss: 0.0101 - val_rmse: 0.1003 - val_mape: 7.6151 - val_smape: 0.0633\n",
      "Epoch 19/50\n",
      "39/39 - 1s - loss: 0.1557 - rmse: 0.3946 - mape: 109.4690 - smape: 0.3456 - val_loss: 0.0099 - val_rmse: 0.0994 - val_mape: 7.5878 - val_smape: 0.0632\n",
      "Epoch 20/50\n",
      "39/39 - 1s - loss: 0.1549 - rmse: 0.3936 - mape: 109.3745 - smape: 0.3436 - val_loss: 0.0098 - val_rmse: 0.0989 - val_mape: 7.5755 - val_smape: 0.0632\n",
      "Epoch 21/50\n",
      "39/39 - 1s - loss: 0.1537 - rmse: 0.3920 - mape: 109.9459 - smape: 0.3402 - val_loss: 0.0098 - val_rmse: 0.0990 - val_mape: 7.5776 - val_smape: 0.0632\n",
      "Epoch 22/50\n",
      "39/39 - 2s - loss: 0.1535 - rmse: 0.3918 - mape: 110.1343 - smape: 0.3423 - val_loss: 0.0097 - val_rmse: 0.0983 - val_mape: 7.5901 - val_smape: 0.0636\n",
      "Epoch 23/50\n",
      "39/39 - 1s - loss: 0.1508 - rmse: 0.3884 - mape: 107.3791 - smape: 0.3370 - val_loss: 0.0098 - val_rmse: 0.0989 - val_mape: 7.5713 - val_smape: 0.0632\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Test MAPE: 104.154\n",
      "Test sMAPE: 62.791\n",
      "Test RMSE: 39.122\n",
      "{'mape': 104.15361549066718, 'smape': 62.791112247750775, 'rmse': 39.122323889781654}\n",
      "Epoch 1/50\n",
      "39/39 - 8s - loss: 0.4968 - rmse: 0.7049 - mape: 198.7920 - smape: 0.5256 - val_loss: 0.0093 - val_rmse: 0.0967 - val_mape: 9.2422 - val_smape: 0.0843\n",
      "Epoch 2/50\n",
      "39/39 - 2s - loss: 0.1505 - rmse: 0.3880 - mape: 97.9377 - smape: 0.4180 - val_loss: 0.0141 - val_rmse: 0.1185 - val_mape: 12.4111 - val_smape: 0.1198\n",
      "Epoch 3/50\n",
      "39/39 - 2s - loss: 0.1435 - rmse: 0.3788 - mape: 94.1550 - smape: 0.4072 - val_loss: 0.0133 - val_rmse: 0.1152 - val_mape: 12.0192 - val_smape: 0.1153\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1416 - rmse: 0.3763 - mape: 91.7721 - smape: 0.4083 - val_loss: 0.0094 - val_rmse: 0.0969 - val_mape: 9.3318 - val_smape: 0.0854\n",
      "Epoch 5/50\n",
      "39/39 - 1s - loss: 0.1426 - rmse: 0.3776 - mape: 91.5608 - smape: 0.4104 - val_loss: 0.0088 - val_rmse: 0.0936 - val_mape: 8.4993 - val_smape: 0.0760\n",
      "Epoch 6/50\n",
      "39/39 - 1s - loss: 0.1496 - rmse: 0.3868 - mape: 95.9620 - smape: 0.4111 - val_loss: 0.0116 - val_rmse: 0.1078 - val_mape: 8.3204 - val_smape: 0.0686\n",
      "Epoch 7/50\n",
      "39/39 - 2s - loss: 0.1641 - rmse: 0.4051 - mape: 99.8133 - smape: 0.4303 - val_loss: 0.0216 - val_rmse: 0.1470 - val_mape: 14.1302 - val_smape: 0.1174\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1726 - rmse: 0.4155 - mape: 105.3422 - smape: 0.4239 - val_loss: 0.0309 - val_rmse: 0.1757 - val_mape: 18.0550 - val_smape: 0.1494\n",
      "Epoch 9/50\n",
      "39/39 - 1s - loss: 0.1788 - rmse: 0.4229 - mape: 109.4672 - smape: 0.4188 - val_loss: 0.0383 - val_rmse: 0.1956 - val_mape: 20.6182 - val_smape: 0.1698\n",
      "Epoch 10/50\n",
      "39/39 - 1s - loss: 0.1834 - rmse: 0.4283 - mape: 114.0718 - smape: 0.4029 - val_loss: 0.0330 - val_rmse: 0.1816 - val_mape: 18.8289 - val_smape: 0.1556\n",
      "Epoch 11/50\n",
      "39/39 - 2s - loss: 0.1815 - rmse: 0.4261 - mape: 115.5505 - smape: 0.3852 - val_loss: 0.0233 - val_rmse: 0.1526 - val_mape: 14.9247 - val_smape: 0.1240\n",
      "Epoch 12/50\n",
      "39/39 - 2s - loss: 0.1749 - rmse: 0.4183 - mape: 114.9419 - smape: 0.3737 - val_loss: 0.0153 - val_rmse: 0.1239 - val_mape: 10.5639 - val_smape: 0.0874\n",
      "Epoch 13/50\n",
      "39/39 - 1s - loss: 0.1673 - rmse: 0.4090 - mape: 113.0922 - smape: 0.3605 - val_loss: 0.0118 - val_rmse: 0.1087 - val_mape: 8.4034 - val_smape: 0.0692\n",
      "Epoch 14/50\n",
      "39/39 - 1s - loss: 0.1613 - rmse: 0.4016 - mape: 111.0840 - smape: 0.3523 - val_loss: 0.0107 - val_rmse: 0.1037 - val_mape: 7.8495 - val_smape: 0.0648\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1580 - rmse: 0.3975 - mape: 109.6685 - smape: 0.3482 - val_loss: 0.0102 - val_rmse: 0.1010 - val_mape: 7.6490 - val_smape: 0.0634\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1579 - rmse: 0.3974 - mape: 110.6856 - smape: 0.3479 - val_loss: 0.0097 - val_rmse: 0.0984 - val_mape: 7.5539 - val_smape: 0.0631\n",
      "Epoch 17/50\n",
      "39/39 - 2s - loss: 0.1549 - rmse: 0.3936 - mape: 109.4000 - smape: 0.3430 - val_loss: 0.0094 - val_rmse: 0.0969 - val_mape: 7.5095 - val_smape: 0.0631\n",
      "Epoch 18/50\n",
      "39/39 - 1s - loss: 0.1541 - rmse: 0.3926 - mape: 109.4403 - smape: 0.3402 - val_loss: 0.0110 - val_rmse: 0.1051 - val_mape: 8.0074 - val_smape: 0.0661\n",
      "Epoch 19/50\n",
      "39/39 - 2s - loss: 0.1564 - rmse: 0.3955 - mape: 108.7904 - smape: 0.3439 - val_loss: 0.0145 - val_rmse: 0.1204 - val_mape: 10.0185 - val_smape: 0.0827\n",
      "Epoch 20/50\n",
      "39/39 - 2s - loss: 0.1590 - rmse: 0.3987 - mape: 110.3461 - smape: 0.3418 - val_loss: 0.0170 - val_rmse: 0.1302 - val_mape: 11.6195 - val_smape: 0.0964\n",
      "Epoch 21/50\n",
      "39/39 - 2s - loss: 0.1611 - rmse: 0.4014 - mape: 111.2393 - smape: 0.3515 - val_loss: 0.0135 - val_rmse: 0.1160 - val_mape: 9.3590 - val_smape: 0.0771\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test MAPE: 150.322\n",
      "Test sMAPE: 72.432\n",
      "Test RMSE: 40.453\n",
      "{'mape': 150.32156160368822, 'smape': 72.432179687928, 'rmse': 40.45332025830571}\n",
      "Epoch 1/50\n",
      "39/39 - 8s - loss: 0.5786 - rmse: 0.7606 - mape: 216.3315 - smape: 0.5581 - val_loss: 0.0110 - val_rmse: 0.1050 - val_mape: 10.6462 - val_smape: 0.0999\n",
      "Epoch 2/50\n",
      "39/39 - 1s - loss: 0.1451 - rmse: 0.3809 - mape: 96.1487 - smape: 0.4066 - val_loss: 0.0123 - val_rmse: 0.1109 - val_mape: 11.4944 - val_smape: 0.1092\n",
      "Epoch 3/50\n",
      "39/39 - 1s - loss: 0.1460 - rmse: 0.3821 - mape: 94.4235 - smape: 0.4173 - val_loss: 0.0153 - val_rmse: 0.1237 - val_mape: 13.0472 - val_smape: 0.1268\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1391 - rmse: 0.3730 - mape: 90.6714 - smape: 0.4057 - val_loss: 0.0090 - val_rmse: 0.0949 - val_mape: 8.2973 - val_smape: 0.0730\n",
      "Epoch 5/50\n",
      "39/39 - 2s - loss: 0.1540 - rmse: 0.3925 - mape: 95.4514 - smape: 0.4244 - val_loss: 0.0093 - val_rmse: 0.0965 - val_mape: 8.8735 - val_smape: 0.0796\n",
      "Epoch 6/50\n",
      "39/39 - 1s - loss: 0.1504 - rmse: 0.3878 - mape: 92.8803 - smape: 0.4229 - val_loss: 0.0107 - val_rmse: 0.1036 - val_mape: 8.1555 - val_smape: 0.0682\n",
      "Epoch 7/50\n",
      "39/39 - 1s - loss: 0.1620 - rmse: 0.4026 - mape: 97.9641 - smape: 0.4349 - val_loss: 0.0188 - val_rmse: 0.1370 - val_mape: 12.3656 - val_smape: 0.1024\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1728 - rmse: 0.4156 - mape: 104.1020 - smape: 0.4409 - val_loss: 0.0367 - val_rmse: 0.1916 - val_mape: 19.9733 - val_smape: 0.1646\n",
      "Epoch 9/50\n",
      "39/39 - 2s - loss: 0.1908 - rmse: 0.4368 - mape: 113.5026 - smape: 0.4387 - val_loss: 0.0421 - val_rmse: 0.2052 - val_mape: 21.7535 - val_smape: 0.1786\n",
      "Epoch 10/50\n",
      "39/39 - 1s - loss: 0.1880 - rmse: 0.4336 - mape: 116.0956 - smape: 0.4066 - val_loss: 0.0366 - val_rmse: 0.1914 - val_mape: 20.0469 - val_smape: 0.1652\n",
      "Epoch 11/50\n",
      "39/39 - 1s - loss: 0.1833 - rmse: 0.4282 - mape: 115.4877 - smape: 0.3945 - val_loss: 0.0281 - val_rmse: 0.1675 - val_mape: 16.9312 - val_smape: 0.1404\n",
      "Epoch 12/50\n",
      "39/39 - 1s - loss: 0.1778 - rmse: 0.4216 - mape: 115.4379 - smape: 0.3802 - val_loss: 0.0194 - val_rmse: 0.1393 - val_mape: 12.9632 - val_smape: 0.1077\n",
      "Epoch 13/50\n",
      "39/39 - 2s - loss: 0.1737 - rmse: 0.4168 - mape: 114.5736 - smape: 0.3725 - val_loss: 0.0152 - val_rmse: 0.1234 - val_mape: 10.4769 - val_smape: 0.0866\n",
      "Epoch 14/50\n",
      "39/39 - 2s - loss: 0.1667 - rmse: 0.4083 - mape: 113.7849 - smape: 0.3623 - val_loss: 0.0135 - val_rmse: 0.1161 - val_mape: 9.3947 - val_smape: 0.0775\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1646 - rmse: 0.4057 - mape: 112.0180 - smape: 0.3579 - val_loss: 0.0123 - val_rmse: 0.1109 - val_mape: 8.7440 - val_smape: 0.0721\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1629 - rmse: 0.4036 - mape: 112.0376 - smape: 0.3553 - val_loss: 0.0114 - val_rmse: 0.1067 - val_mape: 8.2394 - val_smape: 0.0680\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1595 - rmse: 0.3994 - mape: 110.6685 - smape: 0.3503 - val_loss: 0.0112 - val_rmse: 0.1058 - val_mape: 8.1440 - val_smape: 0.0673\n",
      "Epoch 18/50\n",
      "39/39 - 2s - loss: 0.1593 - rmse: 0.3991 - mape: 110.6826 - smape: 0.3508 - val_loss: 0.0105 - val_rmse: 0.1027 - val_mape: 7.7982 - val_smape: 0.0645\n",
      "Epoch 19/50\n",
      "39/39 - 2s - loss: 0.1567 - rmse: 0.3958 - mape: 110.3778 - smape: 0.3460 - val_loss: 0.0102 - val_rmse: 0.1008 - val_mape: 7.6562 - val_smape: 0.0636\n",
      "Epoch 20/50\n",
      "39/39 - 1s - loss: 0.1559 - rmse: 0.3949 - mape: 110.0397 - smape: 0.3458 - val_loss: 0.0098 - val_rmse: 0.0992 - val_mape: 7.5772 - val_smape: 0.0632\n",
      "Epoch 21/50\n",
      "39/39 - 1s - loss: 0.1553 - rmse: 0.3941 - mape: 109.9553 - smape: 0.3448 - val_loss: 0.0097 - val_rmse: 0.0983 - val_mape: 7.5320 - val_smape: 0.0629\n",
      "Epoch 22/50\n",
      "39/39 - 1s - loss: 0.1542 - rmse: 0.3927 - mape: 109.4109 - smape: 0.3419 - val_loss: 0.0097 - val_rmse: 0.0985 - val_mape: 7.6107 - val_smape: 0.0637\n",
      "Epoch 23/50\n",
      "39/39 - 1s - loss: 0.1527 - rmse: 0.3908 - mape: 108.8469 - smape: 0.3401 - val_loss: 0.0097 - val_rmse: 0.0982 - val_mape: 7.5187 - val_smape: 0.0628\n",
      "Epoch 24/50\n",
      "39/39 - 2s - loss: 0.1530 - rmse: 0.3912 - mape: 108.5206 - smape: 0.3397 - val_loss: 0.0097 - val_rmse: 0.0983 - val_mape: 7.5549 - val_smape: 0.0632\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test MAPE: 114.404\n",
      "Test sMAPE: 66.539\n",
      "Test RMSE: 39.698\n",
      "{'mape': 114.40437271660997, 'smape': 66.53930970154481, 'rmse': 39.697660824101206}\n",
      "Epoch 1/50\n",
      "39/39 - 9s - loss: 0.6172 - rmse: 0.7856 - mape: 217.6706 - smape: 0.5479 - val_loss: 0.0158 - val_rmse: 0.1257 - val_mape: 13.2421 - val_smape: 0.1292\n",
      "Epoch 2/50\n",
      "39/39 - 1s - loss: 0.1455 - rmse: 0.3815 - mape: 93.7860 - smape: 0.4069 - val_loss: 0.0131 - val_rmse: 0.1143 - val_mape: 11.9163 - val_smape: 0.1141\n",
      "Epoch 3/50\n",
      "39/39 - 2s - loss: 0.1482 - rmse: 0.3850 - mape: 93.1219 - smape: 0.4238 - val_loss: 0.0089 - val_rmse: 0.0943 - val_mape: 8.6942 - val_smape: 0.0781\n",
      "Epoch 4/50\n",
      "39/39 - 2s - loss: 0.1594 - rmse: 0.3993 - mape: 97.1034 - smape: 0.4394 - val_loss: 0.0139 - val_rmse: 0.1179 - val_mape: 9.6227 - val_smape: 0.0794\n",
      "Epoch 5/50\n",
      "39/39 - 1s - loss: 0.1667 - rmse: 0.4083 - mape: 99.0348 - smape: 0.4362 - val_loss: 0.0145 - val_rmse: 0.1204 - val_mape: 9.9561 - val_smape: 0.0822\n",
      "Epoch 6/50\n",
      "39/39 - 1s - loss: 0.1609 - rmse: 0.4011 - mape: 98.7836 - smape: 0.4227 - val_loss: 0.0177 - val_rmse: 0.1331 - val_mape: 11.9344 - val_smape: 0.0989\n",
      "Epoch 7/50\n",
      "39/39 - 2s - loss: 0.1702 - rmse: 0.4126 - mape: 105.8845 - smape: 0.4239 - val_loss: 0.0241 - val_rmse: 0.1552 - val_mape: 15.2311 - val_smape: 0.1265\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1732 - rmse: 0.4162 - mape: 105.6775 - smape: 0.4315 - val_loss: 0.0389 - val_rmse: 0.1973 - val_mape: 20.7974 - val_smape: 0.1711\n",
      "Epoch 9/50\n",
      "39/39 - 1s - loss: 0.1881 - rmse: 0.4337 - mape: 110.8617 - smape: 0.4263 - val_loss: 0.0342 - val_rmse: 0.1850 - val_mape: 19.2202 - val_smape: 0.1587\n",
      "Epoch 10/50\n",
      "39/39 - 2s - loss: 0.1860 - rmse: 0.4312 - mape: 116.9025 - smape: 0.3940 - val_loss: 0.0207 - val_rmse: 0.1439 - val_mape: 13.6362 - val_smape: 0.1133\n",
      "Epoch 11/50\n",
      "39/39 - 1s - loss: 0.1743 - rmse: 0.4175 - mape: 115.8207 - smape: 0.3732 - val_loss: 0.0138 - val_rmse: 0.1174 - val_mape: 9.5214 - val_smape: 0.0785\n",
      "Epoch 12/50\n",
      "39/39 - 1s - loss: 0.1634 - rmse: 0.4042 - mape: 111.4413 - smape: 0.3552 - val_loss: 0.0120 - val_rmse: 0.1098 - val_mape: 8.5266 - val_smape: 0.0702\n",
      "Epoch 13/50\n",
      "39/39 - 1s - loss: 0.1625 - rmse: 0.4031 - mape: 111.0864 - smape: 0.3558 - val_loss: 0.0116 - val_rmse: 0.1075 - val_mape: 8.2692 - val_smape: 0.0682\n",
      "Epoch 14/50\n",
      "39/39 - 1s - loss: 0.1612 - rmse: 0.4015 - mape: 111.6305 - smape: 0.3546 - val_loss: 0.0109 - val_rmse: 0.1046 - val_mape: 7.9466 - val_smape: 0.0656\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1600 - rmse: 0.4000 - mape: 111.3624 - smape: 0.3515 - val_loss: 0.0102 - val_rmse: 0.1010 - val_mape: 7.6724 - val_smape: 0.0637\n",
      "Epoch 16/50\n",
      "39/39 - 2s - loss: 0.1582 - rmse: 0.3978 - mape: 110.0806 - smape: 0.3485 - val_loss: 0.0102 - val_rmse: 0.1008 - val_mape: 7.6509 - val_smape: 0.0635\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1581 - rmse: 0.3976 - mape: 110.7457 - smape: 0.3464 - val_loss: 0.0100 - val_rmse: 0.1002 - val_mape: 7.6327 - val_smape: 0.0635\n",
      "Epoch 18/50\n",
      "39/39 - 2s - loss: 0.1571 - rmse: 0.3964 - mape: 110.0367 - smape: 0.3461 - val_loss: 0.0101 - val_rmse: 0.1006 - val_mape: 7.6902 - val_smape: 0.0640\n",
      "Epoch 19/50\n",
      "39/39 - 1s - loss: 0.1551 - rmse: 0.3938 - mape: 109.7279 - smape: 0.3425 - val_loss: 0.0105 - val_rmse: 0.1025 - val_mape: 7.7490 - val_smape: 0.0641\n",
      "Epoch 20/50\n",
      "39/39 - 1s - loss: 0.1573 - rmse: 0.3966 - mape: 110.5378 - smape: 0.3453 - val_loss: 0.0109 - val_rmse: 0.1046 - val_mape: 7.9452 - val_smape: 0.0656\n",
      "Epoch 21/50\n",
      "39/39 - 2s - loss: 0.1561 - rmse: 0.3951 - mape: 108.3999 - smape: 0.3438 - val_loss: 0.0111 - val_rmse: 0.1056 - val_mape: 8.0482 - val_smape: 0.0664\n",
      "Epoch 22/50\n",
      "39/39 - 2s - loss: 0.1491 - rmse: 0.3862 - mape: 107.9508 - smape: 0.3191 - val_loss: 0.0214 - val_rmse: 0.1463 - val_mape: 14.0177 - val_smape: 0.1165\n",
      "Epoch 23/50\n",
      "39/39 - 1s - loss: 0.1583 - rmse: 0.3979 - mape: 108.4836 - smape: 0.3637 - val_loss: 0.0253 - val_rmse: 0.1592 - val_mape: 15.8356 - val_smape: 0.1315\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Test MAPE: 132.386\n",
      "Test sMAPE: 68.758\n",
      "Test RMSE: 39.458\n",
      "{'mape': 132.38636232691746, 'smape': 68.7580986010315, 'rmse': 39.457824146723944}\n",
      "Epoch 1/50\n",
      "39/39 - 10s - loss: 0.4941 - rmse: 0.7029 - mape: 188.1114 - smape: 0.5409 - val_loss: 0.0130 - val_rmse: 0.1141 - val_mape: 11.8714 - val_smape: 0.1136\n",
      "Epoch 2/50\n",
      "39/39 - 1s - loss: 0.1406 - rmse: 0.3750 - mape: 92.7128 - smape: 0.4082 - val_loss: 0.0133 - val_rmse: 0.1153 - val_mape: 12.0557 - val_smape: 0.1157\n",
      "Epoch 3/50\n",
      "39/39 - 2s - loss: 0.1424 - rmse: 0.3773 - mape: 91.8583 - smape: 0.4101 - val_loss: 0.0130 - val_rmse: 0.1140 - val_mape: 11.9009 - val_smape: 0.1139\n",
      "Epoch 4/50\n",
      "39/39 - 1s - loss: 0.1406 - rmse: 0.3750 - mape: 91.5667 - smape: 0.4085 - val_loss: 0.0102 - val_rmse: 0.1008 - val_mape: 9.9487 - val_smape: 0.0920\n",
      "Epoch 5/50\n",
      "39/39 - 1s - loss: 0.1424 - rmse: 0.3774 - mape: 93.1238 - smape: 0.4062 - val_loss: 0.0109 - val_rmse: 0.1043 - val_mape: 10.5282 - val_smape: 0.0985\n",
      "Epoch 6/50\n",
      "39/39 - 2s - loss: 0.1445 - rmse: 0.3802 - mape: 92.5129 - smape: 0.4130 - val_loss: 0.0090 - val_rmse: 0.0950 - val_mape: 8.2651 - val_smape: 0.0726\n",
      "Epoch 7/50\n",
      "39/39 - 1s - loss: 0.1480 - rmse: 0.3847 - mape: 92.8836 - smape: 0.4148 - val_loss: 0.0092 - val_rmse: 0.0960 - val_mape: 8.1767 - val_smape: 0.0712\n",
      "Epoch 8/50\n",
      "39/39 - 1s - loss: 0.1530 - rmse: 0.3911 - mape: 97.3246 - smape: 0.4145 - val_loss: 0.0115 - val_rmse: 0.1073 - val_mape: 8.2752 - val_smape: 0.0685\n",
      "Epoch 9/50\n",
      "39/39 - 1s - loss: 0.1650 - rmse: 0.4062 - mape: 100.6665 - smape: 0.4370 - val_loss: 0.0284 - val_rmse: 0.1687 - val_mape: 16.8758 - val_smape: 0.1397\n",
      "Epoch 10/50\n",
      "39/39 - 1s - loss: 0.1820 - rmse: 0.4266 - mape: 107.5433 - smape: 0.4464 - val_loss: 0.0374 - val_rmse: 0.1935 - val_mape: 20.2115 - val_smape: 0.1664\n",
      "Epoch 11/50\n",
      "39/39 - 2s - loss: 0.1852 - rmse: 0.4304 - mape: 111.2574 - smape: 0.4315 - val_loss: 0.0384 - val_rmse: 0.1960 - val_mape: 20.5858 - val_smape: 0.1694\n",
      "Epoch 12/50\n",
      "39/39 - 2s - loss: 0.1860 - rmse: 0.4313 - mape: 113.7620 - smape: 0.4144 - val_loss: 0.0372 - val_rmse: 0.1930 - val_mape: 20.2247 - val_smape: 0.1666\n",
      "Epoch 13/50\n",
      "39/39 - 1s - loss: 0.1852 - rmse: 0.4304 - mape: 114.0449 - smape: 0.4000 - val_loss: 0.0272 - val_rmse: 0.1648 - val_mape: 16.5524 - val_smape: 0.1373\n",
      "Epoch 14/50\n",
      "39/39 - 1s - loss: 0.1782 - rmse: 0.4221 - mape: 115.6951 - smape: 0.3812 - val_loss: 0.0181 - val_rmse: 0.1347 - val_mape: 12.2166 - val_smape: 0.1013\n",
      "Epoch 15/50\n",
      "39/39 - 1s - loss: 0.1716 - rmse: 0.4142 - mape: 114.0165 - smape: 0.3720 - val_loss: 0.0134 - val_rmse: 0.1157 - val_mape: 9.3045 - val_smape: 0.0767\n",
      "Epoch 16/50\n",
      "39/39 - 1s - loss: 0.1644 - rmse: 0.4055 - mape: 112.0994 - smape: 0.3597 - val_loss: 0.0122 - val_rmse: 0.1106 - val_mape: 8.6512 - val_smape: 0.0713\n",
      "Epoch 17/50\n",
      "39/39 - 1s - loss: 0.1633 - rmse: 0.4041 - mape: 111.5833 - smape: 0.3581 - val_loss: 0.0108 - val_rmse: 0.1038 - val_mape: 7.8831 - val_smape: 0.0652\n",
      "Epoch 18/50\n",
      "39/39 - 1s - loss: 0.1592 - rmse: 0.3990 - mape: 109.9788 - smape: 0.3516 - val_loss: 0.0108 - val_rmse: 0.1041 - val_mape: 7.9163 - val_smape: 0.0654\n",
      "Epoch 19/50\n",
      "39/39 - 2s - loss: 0.1566 - rmse: 0.3957 - mape: 109.8274 - smape: 0.3453 - val_loss: 0.0115 - val_rmse: 0.1071 - val_mape: 8.2459 - val_smape: 0.0680\n",
      "Epoch 20/50\n",
      "39/39 - 1s - loss: 0.1600 - rmse: 0.4000 - mape: 111.4960 - smape: 0.3563 - val_loss: 0.0097 - val_rmse: 0.0985 - val_mape: 7.5684 - val_smape: 0.0633\n",
      "Epoch 21/50\n",
      "39/39 - 2s - loss: 0.1554 - rmse: 0.3942 - mape: 109.5425 - smape: 0.3470 - val_loss: 0.0093 - val_rmse: 0.0966 - val_mape: 7.5939 - val_smape: 0.0641\n",
      "Epoch 22/50\n",
      "39/39 - 1s - loss: 0.1541 - rmse: 0.3926 - mape: 109.1056 - smape: 0.3448 - val_loss: 0.0090 - val_rmse: 0.0951 - val_mape: 7.6273 - val_smape: 0.0649\n",
      "Epoch 23/50\n",
      "39/39 - 1s - loss: 0.1529 - rmse: 0.3910 - mape: 108.7052 - smape: 0.3424 - val_loss: 0.0089 - val_rmse: 0.0943 - val_mape: 7.6877 - val_smape: 0.0658\n",
      "Epoch 24/50\n",
      "39/39 - 1s - loss: 0.1514 - rmse: 0.3891 - mape: 108.0857 - smape: 0.3411 - val_loss: 0.0088 - val_rmse: 0.0940 - val_mape: 7.7133 - val_smape: 0.0662\n",
      "Epoch 25/50\n",
      "39/39 - 2s - loss: 0.1509 - rmse: 0.3884 - mape: 108.6808 - smape: 0.3403 - val_loss: 0.0088 - val_rmse: 0.0937 - val_mape: 7.7598 - val_smape: 0.0668\n",
      "Epoch 26/50\n",
      "39/39 - 2s - loss: 0.1499 - rmse: 0.3871 - mape: 107.9567 - smape: 0.3388 - val_loss: 0.0088 - val_rmse: 0.0935 - val_mape: 7.8180 - val_smape: 0.0676\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test MAPE: 113.330\n",
      "Test sMAPE: 66.221\n",
      "Test RMSE: 39.777\n",
      "{'mape': 113.32958075131343, 'smape': 66.2210442910503, 'rmse': 39.77690829000443}\n",
      "rmse : average=40.051, std=0.945\n",
      "mape : average=124.504, std=26.695\n",
      "smape : average=67.699, std=5.117\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b1324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
