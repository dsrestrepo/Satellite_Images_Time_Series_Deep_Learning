{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ec5497",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b095e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc83cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d532a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = 'Tabular_data/precipitation_all.csv'\n",
    "features2 = 'Tabular_data/temperature_all 2.csv'\n",
    "\n",
    "labels = 'Tabular_data/dengue_tabular.csv'\n",
    "Municipalities = ['Medellín', 'Cali', 'Villavicencio', 'Cúcuta', 'Ibagué']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef64c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities =  {\n",
    "  \"76001\":\t\"Cali\",\n",
    "  \"05001\":\t\"Medellín\",\n",
    "  \"50001\":\t\"Villavicencio\",\n",
    "  \"54001\":\t\"Cúcuta\",\n",
    "  \"73001\":\t\"Ibagué\",\n",
    "  \"68001\":\t\"Bucaramanga\",\n",
    "  \"05360\":\t\"Itagüí\",\n",
    "  \"08001\":\t\"Barranquilla\",\n",
    "  \"41001\":\t\"Neiva\",\n",
    "  \"23001\":\t\"Montería\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47748c88",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d1cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f90223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c06fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "        \n",
    "        df.index = pd.to_numeric(df.index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3d353",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77b5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(MUNICIPALITY):\n",
    "    for code, city in cities.items():\n",
    "        if city == MUNICIPALITY:\n",
    "            return code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf082d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(MUNICIPALITY):\n",
    "    \n",
    "    code = get_code(MUNICIPALITY)\n",
    "    \n",
    "    # Temperature\n",
    "    for col in pd.read_csv(features2).columns:\n",
    "        if code in col:\n",
    "            column = col\n",
    "            continue\n",
    "\n",
    "    temperature_df = pd.read_csv(features2)[['LastDayWeek', column]]\n",
    "    \n",
    "    # Precipitation\n",
    "    for col in pd.read_csv(features1).columns:\n",
    "        if code in col:\n",
    "            column = col\n",
    "            continue\n",
    "    precipitation_df = pd.read_csv(features1)[['LastDayWeek', column]]\n",
    "\n",
    "    # Merge\n",
    "    features_df = temperature_df.merge(precipitation_df, how='inner', on='LastDayWeek')\n",
    "\n",
    "    features_df['LastDayWeek'] = features_df['LastDayWeek'].apply(epiweek_from_date)\n",
    "    features_df = features_df.set_index('LastDayWeek')\n",
    "    features_df.index.name = None\n",
    "    \n",
    "    features_df.columns = ['temperature', 'precipitation']\n",
    "    \n",
    "    print(f'Obtaining dataframe for the city of {MUNICIPALITY} only...')\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaaef83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataframe for the city of Medellín only...\n",
      "Obtaining dataframe for the city of Cali only...\n",
      "Obtaining dataframe for the city of Villavicencio only...\n",
      "Obtaining dataframe for the city of Cúcuta only...\n",
      "Obtaining dataframe for the city of Ibagué only...\n"
     ]
    }
   ],
   "source": [
    "features_df = [get_features(MUNICIPALITY=municipality) for municipality in Municipalities]\n",
    "#features_df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5642f3c6",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1d5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = [read_labels(path=labels, Municipality=municipality) for municipality in Municipalities]\n",
    "#labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515160b",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f793da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = [features_df[i].merge(labels_df[i], how='inner', left_index=True, right_index=True) for i in range(len(labels_df))]\n",
    "#dengue_df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cd372",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5154057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1891a5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (540, 3)\n",
      "The test shape is: (136, 3)\n",
      "The train shape is: (540, 3)\n",
      "The test shape is: (136, 3)\n",
      "The train shape is: (540, 3)\n",
      "The test shape is: (136, 3)\n",
      "The train shape is: (540, 3)\n",
      "The test shape is: (136, 3)\n",
      "The train shape is: (540, 3)\n",
      "The test shape is: (136, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "test_df = []\n",
    "\n",
    "for i in range(len(dengue_df)):\n",
    "    train_df_aux, test_df_aux = train_test_split(dengue_df[i], train_percentage = 80)\n",
    "    train_df.append(train_df_aux)\n",
    "    test_df.append(test_df_aux)\n",
    "    \n",
    "#test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f74a8",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2c9a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), scaler=True):\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, scaler=True):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "        \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if not scaler:\n",
    "            if (i == len(df.columns) - 1):\n",
    "                continue\n",
    "        \n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91013823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge:\n",
    "train_df = pd.concat([train_df[0], train_df[1], train_df[2], train_df[3], train_df[4]], keys=Municipalities)\n",
    "test_df = pd.concat([test_df[0], test_df[1], test_df[2], test_df[3], test_df[4]], keys=Municipalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe3366b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac593963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "temperature     -1.0\n",
      "precipitation   -1.0\n",
      "Labels          -1.0\n",
      "dtype: float64\n",
      " Max values are: \n",
      "temperature      1.0\n",
      "precipitation    1.0\n",
      "Labels           1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Medellín</th>\n",
       "      <th>200701</th>\n",
       "      <td>-0.411726</td>\n",
       "      <td>-0.942675</td>\n",
       "      <td>-0.997616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200702</th>\n",
       "      <td>-0.149935</td>\n",
       "      <td>-0.838083</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200703</th>\n",
       "      <td>-0.147233</td>\n",
       "      <td>-0.989354</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200704</th>\n",
       "      <td>-0.047203</td>\n",
       "      <td>-0.873163</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200705</th>\n",
       "      <td>0.094315</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 temperature  precipitation    Labels\n",
       "Medellín 200701    -0.411726      -0.942675 -0.997616\n",
       "         200702    -0.149935      -0.838083 -1.000000\n",
       "         200703    -0.147233      -0.989354 -1.000000\n",
       "         200704    -0.047203      -0.873163 -1.000000\n",
       "         200705     0.094315      -1.000000 -1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range)\n",
    "train_df = [train_df[train_df.index.get_level_values(0) == municipality] for municipality in Municipalities]\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c237482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "temperature     -0.750252\n",
      "precipitation   -1.000000\n",
      "Labels          -0.995232\n",
      "dtype: float64\n",
      " Max values are: \n",
      "temperature      0.830570\n",
      "precipitation    0.529255\n",
      "Labels          -0.246722\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Medellín</th>\n",
       "      <th>201721</th>\n",
       "      <td>0.018283</td>\n",
       "      <td>-0.820583</td>\n",
       "      <td>-0.887962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201722</th>\n",
       "      <td>0.024643</td>\n",
       "      <td>-0.914407</td>\n",
       "      <td>-0.899881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201723</th>\n",
       "      <td>0.134048</td>\n",
       "      <td>-0.738527</td>\n",
       "      <td>-0.921335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201724</th>\n",
       "      <td>-0.123104</td>\n",
       "      <td>-0.563092</td>\n",
       "      <td>-0.907032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201725</th>\n",
       "      <td>-0.039496</td>\n",
       "      <td>-0.630932</td>\n",
       "      <td>-0.942789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 temperature  precipitation    Labels\n",
       "Medellín 201721     0.018283      -0.820583 -0.887962\n",
       "         201722     0.024643      -0.914407 -0.899881\n",
       "         201723     0.134048      -0.738527 -0.921335\n",
       "         201724    -0.123104      -0.563092 -0.907032\n",
       "         201725    -0.039496      -0.630932 -0.942789"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers)\n",
    "test_df = [test_df[test_df.index.get_level_values(0) == municipality] for municipality in Municipalities]\n",
    "\n",
    "test_df[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6fa540",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a6f2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True, no_autoregressive=None):\n",
    "    if no_autoregressive:\n",
    "        n_in = n_in - 1\n",
    "        \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        if no_autoregressive:\n",
    "            cols.append(df.shift(i).iloc[:,:-1])\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars-1)]\n",
    "        else:\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b3855eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "no_autoregressive = True\n",
    "\n",
    "# frame as supervised learning\n",
    "train = [series_to_supervised(df, n_in=days, no_autoregressive=no_autoregressive) for df in train_df]\n",
    "test = [series_to_supervised(df, n_in=days, no_autoregressive=no_autoregressive) for df in test_df]\n",
    "\n",
    "#DataFrame(train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbccd85",
   "metadata": {},
   "source": [
    "### Merge train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3581fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge:\n",
    "train = pd.concat([train[0], train[1], train[2], train[3], train[4]], keys=Municipalities)\n",
    "test = pd.concat([test[0], test[1], test[2], test[3], test[4]], keys=Municipalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbd310b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2655, 21)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e6198",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1897e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (Cases and media cloud)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-1])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use Covid cases in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-1])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ecd0401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (2655, 20)\n",
      "The shape of the labels is (2655, 1)\n",
      "Test:\n",
      "The shape of the features is (635, 20)\n",
      "The shape of the labels is (635, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df[0])\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd3457",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d404f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features, no_autoregressive=None):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    if no_autoregressive:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features-1))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features-1))\n",
    "    \n",
    "    else:\n",
    "        train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "        test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65fb956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (2655, 20)\n",
      "The test shape is (635, 20)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (2655, 10, 2)\n",
      "The test shape is (635, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features, no_autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6b0e0",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fb256a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    epsilon = 0.1\n",
    "    summ = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)\n",
    "    smape = K.abs(y_pred - y_true) / summ * 2.0\n",
    "    return smape\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = [\n",
    "        tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
    "        tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "        smape\n",
    "    ]\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=opt, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd9ce9",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e39dd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae89eb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, plot=None, epochs=50):\n",
    "    if monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb5c9a",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e2ad928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "def test_model(model, test_X, test_y, scaler, rnn = None):\n",
    "    \n",
    "    # If model is a classical machine learning model and test_X is a 3D tensor, then convert to 2D\n",
    "    if not rnn and (len(test_X.shape) == 3):\n",
    "        test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "    \n",
    "    # do the prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    # Invert scaling for forecast\n",
    "    # Inverse Scaler\n",
    "    \n",
    "    # Predicted\n",
    "    if not rnn:\n",
    "        yhat = yhat.reshape(-1, 1)\n",
    "        \n",
    "    if not scaler:\n",
    "        return yhat, test_y\n",
    "    \n",
    "    inv_yhat = scaler.inverse_transform(yhat)\n",
    "    \n",
    "    # Real:\n",
    "    inv_y = scaler.inverse_transform(test_y)\n",
    "    \n",
    "    return inv_yhat, inv_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee3e80f",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "$$\n",
    "MAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n}\\left |\\frac{x_i-y_i}{y_t}\\right|\n",
    "$$\n",
    "\n",
    "MAPE has a problem if there are zeros in the test data, so other metrics can be explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c095e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Test MAPE: %.3f' % mape)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc8ee1",
   "metadata": {},
   "source": [
    "### Symmetric Mean Absolute Percentage Error (sMAPE)\n",
    "\n",
    "$$\n",
    "sMAPE = \\displaystyle\\frac{100\\%}{n}\\sum_{t=1}^{n} \\frac{|x_i-y_i|}{|x_i|+|y_t|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca2b29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    smape = 1/len(y_true) * np.sum(2 * np.abs(y_pred-y_true) / (np.abs(y_true) + np.abs(y_pred))*100)\n",
    "    print('Test sMAPE: %.3f' % smape)\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e5776",
   "metadata": {},
   "source": [
    "### Mean Absoulte Error (MAE)\n",
    "$$\n",
    "RMSE = \\sqrt{(\\frac{1}{n})\\sum_{i=1}^{n}(x_i-y_i)^{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "563c3cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print('Test RMSE: %.3f' % rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aca15047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(inv_y, inv_yhat, model_name = ''):\n",
    "    data_predict = inv_yhat  ## predicted target cases\n",
    "    dataY_plot = inv_y  ##  real test-target cases\n",
    "\n",
    "    data_predict = data_predict.reshape(len(data_predict), 1)\n",
    "    dataY_plot = dataY_plot.reshape(len(dataY_plot), 1)\n",
    "\n",
    "    plt.plot(dataY_plot, label = 'actual')\n",
    "    plt.plot(data_predict, label = 'predicted')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.suptitle(f'Time-Series Prediction with {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55410512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_X, test_y, scaler):\n",
    "    stored_results = {}\n",
    "    \n",
    "    inv_yhat_lstm, inv_y_lstm = test_model(model=model, test_X=test_X, test_y=test_y, scaler=y_scaler, rnn = True)\n",
    "    stored_results['mape'] = mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['smape'] = symmetric_mean_absolute_percentage_error(inv_y_lstm, inv_yhat_lstm)\n",
    "    stored_results['rmse'] = root_mean_squared_error(inv_y_lstm, inv_yhat_lstm)\n",
    "\n",
    "    return stored_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19a85d",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95a34974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With LSTM:\n",
    "#print(f'The scalers are: {scalers.keys()}')\n",
    "y_scaler = scalers['scaler_Labels']\n",
    "\n",
    "def calculate_mean_std():\n",
    "    \n",
    "    metrics = {\n",
    "        \"rmse\": [],\n",
    "        \"mape\": [],\n",
    "        \"smape\": []\n",
    "    }\n",
    "    \n",
    "    for i in range(10):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor)\n",
    "        stored_results = evaluate(model, test_X, test_y, y_scaler)\n",
    "        print(stored_results)\n",
    "        \n",
    "        for key in metrics.keys():\n",
    "            metrics[key].append(stored_results[key])\n",
    "            \n",
    "    for key in metrics.keys():\n",
    "        results = metrics[key]\n",
    "        print(key, f\": average={np.average(results):.3f}, std={np.std(results):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fa88981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1448 - rmse: 0.3806 - mape: 71.1469 - smape: 0.3958 - val_loss: 0.0280 - val_rmse: 0.1674 - val_mape: 18.8315 - val_smape: 0.1769\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0874 - rmse: 0.2956 - mape: 63.8254 - smape: 0.2736 - val_loss: 0.0275 - val_rmse: 0.1660 - val_mape: 19.0002 - val_smape: 0.1748\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0788 - rmse: 0.2808 - mape: 62.0162 - smape: 0.2538 - val_loss: 0.0235 - val_rmse: 0.1532 - val_mape: 17.6015 - val_smape: 0.1546\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0757 - rmse: 0.2752 - mape: 61.5044 - smape: 0.2455 - val_loss: 0.0223 - val_rmse: 0.1494 - val_mape: 16.9116 - val_smape: 0.1439\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0741 - rmse: 0.2722 - mape: 61.4504 - smape: 0.2393 - val_loss: 0.0221 - val_rmse: 0.1487 - val_mape: 16.6809 - val_smape: 0.1400\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 61.5153 - smape: 0.2371 - val_loss: 0.0215 - val_rmse: 0.1468 - val_mape: 16.1706 - val_smape: 0.1327\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2699 - mape: 61.4120 - smape: 0.2331 - val_loss: 0.0225 - val_rmse: 0.1499 - val_mape: 16.7712 - val_smape: 0.1404\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 61.5075 - smape: 0.2318 - val_loss: 0.0235 - val_rmse: 0.1532 - val_mape: 17.3676 - val_smape: 0.1486\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0740 - rmse: 0.2719 - mape: 61.9888 - smape: 0.2339 - val_loss: 0.0233 - val_rmse: 0.1526 - val_mape: 17.5224 - val_smape: 0.1525\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0740 - rmse: 0.2721 - mape: 62.1741 - smape: 0.2369 - val_loss: 0.0232 - val_rmse: 0.1522 - val_mape: 17.4598 - val_smape: 0.1516\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 61.8947 - smape: 0.2337 - val_loss: 0.0231 - val_rmse: 0.1522 - val_mape: 17.2595 - val_smape: 0.1474\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2703 - mape: 61.7042 - smape: 0.2310 - val_loss: 0.0234 - val_rmse: 0.1529 - val_mape: 17.3864 - val_smape: 0.1492\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2708 - mape: 62.0559 - smape: 0.2326 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.1924 - val_smape: 0.1472\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2707 - mape: 62.0222 - smape: 0.2333 - val_loss: 0.0228 - val_rmse: 0.1508 - val_mape: 17.1201 - val_smape: 0.1459\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 62.0654 - smape: 0.2322 - val_loss: 0.0229 - val_rmse: 0.1512 - val_mape: 17.1581 - val_smape: 0.1462\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2703 - mape: 62.1445 - smape: 0.2323 - val_loss: 0.0227 - val_rmse: 0.1508 - val_mape: 17.1565 - val_smape: 0.1467\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2702 - mape: 62.0712 - smape: 0.2326 - val_loss: 0.0229 - val_rmse: 0.1513 - val_mape: 17.1424 - val_smape: 0.1458\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2702 - mape: 62.1457 - smape: 0.2327 - val_loss: 0.0228 - val_rmse: 0.1509 - val_mape: 17.1118 - val_smape: 0.1457\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2707 - mape: 62.2007 - smape: 0.2326 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.2401 - val_smape: 0.1482\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 61.7306 - smape: 0.2289 - val_loss: 0.0234 - val_rmse: 0.1529 - val_mape: 17.3369 - val_smape: 0.1479\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2710 - mape: 62.2660 - smape: 0.2320 - val_loss: 0.0226 - val_rmse: 0.1504 - val_mape: 17.0995 - val_smape: 0.1459\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2697 - mape: 61.8665 - smape: 0.2289 - val_loss: 0.0237 - val_rmse: 0.1541 - val_mape: 17.5929 - val_smape: 0.1520\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 62.4017 - smape: 0.2318 - val_loss: 0.0227 - val_rmse: 0.1507 - val_mape: 17.1737 - val_smape: 0.1471\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2695 - mape: 61.7851 - smape: 0.2289 - val_loss: 0.0232 - val_rmse: 0.1522 - val_mape: 17.3451 - val_smape: 0.1489\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test MAPE: 268.507\n",
      "Test sMAPE: 91.118\n",
      "Test RMSE: 62.664\n",
      "{'mape': 268.50741691721737, 'smape': 91.1184466832189, 'rmse': 62.664395807166905}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1445 - rmse: 0.3801 - mape: 71.9308 - smape: 0.3942 - val_loss: 0.0285 - val_rmse: 0.1688 - val_mape: 18.9011 - val_smape: 0.1784\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0890 - rmse: 0.2983 - mape: 64.0036 - smape: 0.2765 - val_loss: 0.0275 - val_rmse: 0.1659 - val_mape: 18.9886 - val_smape: 0.1751\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0801 - rmse: 0.2830 - mape: 62.2397 - smape: 0.2557 - val_loss: 0.0248 - val_rmse: 0.1575 - val_mape: 18.1490 - val_smape: 0.1622\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0761 - rmse: 0.2759 - mape: 61.4947 - smape: 0.2462 - val_loss: 0.0236 - val_rmse: 0.1537 - val_mape: 17.6297 - val_smape: 0.1541\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0749 - rmse: 0.2736 - mape: 61.4730 - smape: 0.2416 - val_loss: 0.0219 - val_rmse: 0.1480 - val_mape: 16.7255 - val_smape: 0.1415\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2715 - mape: 61.2658 - smape: 0.2358 - val_loss: 0.0230 - val_rmse: 0.1517 - val_mape: 17.2666 - val_smape: 0.1482\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2712 - mape: 61.4746 - smape: 0.2345 - val_loss: 0.0234 - val_rmse: 0.1530 - val_mape: 17.4219 - val_smape: 0.1500\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2712 - mape: 61.7173 - smape: 0.2342 - val_loss: 0.0234 - val_rmse: 0.1531 - val_mape: 17.4609 - val_smape: 0.1506\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0740 - rmse: 0.2721 - mape: 62.0994 - smape: 0.2362 - val_loss: 0.0232 - val_rmse: 0.1522 - val_mape: 17.4401 - val_smape: 0.1511\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2703 - mape: 61.5257 - smape: 0.2319 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.1069 - val_smape: 0.1455\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2702 - mape: 61.6428 - smape: 0.2299 - val_loss: 0.0236 - val_rmse: 0.1536 - val_mape: 17.5201 - val_smape: 0.1512\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0739 - rmse: 0.2718 - mape: 62.2255 - smape: 0.2335 - val_loss: 0.0229 - val_rmse: 0.1514 - val_mape: 17.3868 - val_smape: 0.1510\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2699 - mape: 61.6418 - smape: 0.2306 - val_loss: 0.0232 - val_rmse: 0.1524 - val_mape: 17.3648 - val_smape: 0.1492\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2702 - mape: 61.9737 - smape: 0.2306 - val_loss: 0.0234 - val_rmse: 0.1530 - val_mape: 17.4609 - val_smape: 0.1507\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2712 - mape: 62.1907 - smape: 0.2324 - val_loss: 0.0229 - val_rmse: 0.1514 - val_mape: 17.2985 - val_smape: 0.1490\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 61.6550 - smape: 0.2291 - val_loss: 0.0230 - val_rmse: 0.1518 - val_mape: 17.2376 - val_smape: 0.1473\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 62.0789 - smape: 0.2303 - val_loss: 0.0233 - val_rmse: 0.1526 - val_mape: 17.3817 - val_smape: 0.1493\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 62.2132 - smape: 0.2326 - val_loss: 0.0229 - val_rmse: 0.1512 - val_mape: 17.2427 - val_smape: 0.1480\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 61.7763 - smape: 0.2290 - val_loss: 0.0238 - val_rmse: 0.1544 - val_mape: 17.5858 - val_smape: 0.1515\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2714 - mape: 62.3676 - smape: 0.2330 - val_loss: 0.0227 - val_rmse: 0.1506 - val_mape: 17.0930 - val_smape: 0.1456\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 61.9066 - smape: 0.2307 - val_loss: 0.0222 - val_rmse: 0.1489 - val_mape: 16.7556 - val_smape: 0.1407\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2687 - mape: 62.0017 - smape: 0.2290 - val_loss: 0.0227 - val_rmse: 0.1506 - val_mape: 16.9735 - val_smape: 0.1430\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2690 - mape: 62.0435 - smape: 0.2304 - val_loss: 0.0219 - val_rmse: 0.1479 - val_mape: 16.4797 - val_smape: 0.1364\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0723 - rmse: 0.2689 - mape: 62.0239 - smape: 0.2292 - val_loss: 0.0224 - val_rmse: 0.1498 - val_mape: 16.8058 - val_smape: 0.1404\n",
      "Epoch 25/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2686 - mape: 61.9413 - smape: 0.2278 - val_loss: 0.0232 - val_rmse: 0.1523 - val_mape: 17.1128 - val_smape: 0.1435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test MAPE: 263.856\n",
      "Test sMAPE: 90.369\n",
      "Test RMSE: 62.103\n",
      "{'mape': 263.85593669817047, 'smape': 90.36901159862312, 'rmse': 62.10259376044748}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1406 - rmse: 0.3750 - mape: 69.7153 - smape: 0.3935 - val_loss: 0.0282 - val_rmse: 0.1679 - val_mape: 18.8841 - val_smape: 0.1777\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0870 - rmse: 0.2950 - mape: 63.2574 - smape: 0.2732 - val_loss: 0.0277 - val_rmse: 0.1664 - val_mape: 19.0502 - val_smape: 0.1756\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0790 - rmse: 0.2810 - mape: 62.0693 - smape: 0.2539 - val_loss: 0.0240 - val_rmse: 0.1550 - val_mape: 17.8383 - val_smape: 0.1579\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0758 - rmse: 0.2752 - mape: 61.5045 - smape: 0.2448 - val_loss: 0.0236 - val_rmse: 0.1535 - val_mape: 17.5971 - val_smape: 0.1535\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0746 - rmse: 0.2731 - mape: 61.5185 - smape: 0.2409 - val_loss: 0.0216 - val_rmse: 0.1470 - val_mape: 16.5084 - val_smape: 0.1385\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2712 - mape: 61.3938 - smape: 0.2371 - val_loss: 0.0215 - val_rmse: 0.1468 - val_mape: 16.3197 - val_smape: 0.1353\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2708 - mape: 61.4975 - smape: 0.2337 - val_loss: 0.0234 - val_rmse: 0.1529 - val_mape: 17.4206 - val_smape: 0.1501\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0743 - rmse: 0.2725 - mape: 62.0541 - smape: 0.2377 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.3129 - val_smape: 0.1497\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2713 - mape: 61.8909 - smape: 0.2350 - val_loss: 0.0230 - val_rmse: 0.1517 - val_mape: 17.2925 - val_smape: 0.1486\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2714 - mape: 61.9825 - smape: 0.2343 - val_loss: 0.0230 - val_rmse: 0.1518 - val_mape: 17.3612 - val_smape: 0.1499\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2703 - mape: 61.8063 - smape: 0.2314 - val_loss: 0.0233 - val_rmse: 0.1528 - val_mape: 17.4428 - val_smape: 0.1505\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0739 - rmse: 0.2719 - mape: 62.2940 - smape: 0.2349 - val_loss: 0.0227 - val_rmse: 0.1507 - val_mape: 17.2612 - val_smape: 0.1491\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 61.5416 - smape: 0.2296 - val_loss: 0.0229 - val_rmse: 0.1515 - val_mape: 17.1952 - val_smape: 0.1468\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 61.9135 - smape: 0.2295 - val_loss: 0.0235 - val_rmse: 0.1533 - val_mape: 17.4539 - val_smape: 0.1500\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2710 - mape: 62.1435 - smape: 0.2319 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.2789 - val_smape: 0.1490\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2705 - mape: 62.0787 - smape: 0.2331 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.1677 - val_smape: 0.1467\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 61.9038 - smape: 0.2306 - val_loss: 0.0235 - val_rmse: 0.1532 - val_mape: 17.4216 - val_smape: 0.1494\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2710 - mape: 62.2499 - smape: 0.2327 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.2228 - val_smape: 0.1478\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 61.7469 - smape: 0.2303 - val_loss: 0.0223 - val_rmse: 0.1494 - val_mape: 16.8253 - val_smape: 0.1415\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2690 - mape: 62.0711 - smape: 0.2307 - val_loss: 0.0217 - val_rmse: 0.1474 - val_mape: 16.3876 - val_smape: 0.1352\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2683 - mape: 61.8007 - smape: 0.2272 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 16.9667 - val_smape: 0.1423\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2698 - mape: 61.9474 - smape: 0.2283 - val_loss: 0.0238 - val_rmse: 0.1543 - val_mape: 17.5078 - val_smape: 0.1497\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2715 - mape: 62.3552 - smape: 0.2321 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.2345 - val_smape: 0.1480\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 61.8382 - smape: 0.2293 - val_loss: 0.0236 - val_rmse: 0.1537 - val_mape: 17.3687 - val_smape: 0.1474\n",
      "Epoch 25/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2697 - mape: 62.1664 - smape: 0.2300 - val_loss: 0.0238 - val_rmse: 0.1542 - val_mape: 17.4532 - val_smape: 0.1485\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test MAPE: 255.003\n",
      "Test sMAPE: 89.315\n",
      "Test RMSE: 61.669\n",
      "{'mape': 255.00313794215083, 'smape': 89.31517107652896, 'rmse': 61.66918163502544}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1453 - rmse: 0.3812 - mape: 72.0336 - smape: 0.3954 - val_loss: 0.0280 - val_rmse: 0.1674 - val_mape: 18.8667 - val_smape: 0.1776\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0872 - rmse: 0.2952 - mape: 63.4612 - smape: 0.2732 - val_loss: 0.0272 - val_rmse: 0.1649 - val_mape: 18.9076 - val_smape: 0.1737\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0790 - rmse: 0.2810 - mape: 62.1214 - smape: 0.2535 - val_loss: 0.0233 - val_rmse: 0.1527 - val_mape: 17.5518 - val_smape: 0.1540\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0756 - rmse: 0.2750 - mape: 61.4970 - smape: 0.2450 - val_loss: 0.0222 - val_rmse: 0.1490 - val_mape: 16.9144 - val_smape: 0.1443\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0741 - rmse: 0.2722 - mape: 61.3310 - smape: 0.2386 - val_loss: 0.0224 - val_rmse: 0.1495 - val_mape: 16.8881 - val_smape: 0.1431\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 61.3001 - smape: 0.2358 - val_loss: 0.0224 - val_rmse: 0.1498 - val_mape: 16.9027 - val_smape: 0.1430\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 61.4160 - smape: 0.2335 - val_loss: 0.0233 - val_rmse: 0.1527 - val_mape: 17.3428 - val_smape: 0.1487\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0744 - rmse: 0.2728 - mape: 62.2101 - smape: 0.2379 - val_loss: 0.0232 - val_rmse: 0.1523 - val_mape: 17.4835 - val_smape: 0.1520\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 61.8114 - smape: 0.2354 - val_loss: 0.0231 - val_rmse: 0.1519 - val_mape: 17.1998 - val_smape: 0.1466\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2707 - mape: 61.7814 - smape: 0.2331 - val_loss: 0.0234 - val_rmse: 0.1528 - val_mape: 17.3677 - val_smape: 0.1489\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0739 - rmse: 0.2718 - mape: 62.1720 - smape: 0.2354 - val_loss: 0.0229 - val_rmse: 0.1513 - val_mape: 17.3335 - val_smape: 0.1500\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 61.7151 - smape: 0.2320 - val_loss: 0.0230 - val_rmse: 0.1517 - val_mape: 17.1650 - val_smape: 0.1460\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2703 - mape: 61.7888 - smape: 0.2312 - val_loss: 0.0234 - val_rmse: 0.1528 - val_mape: 17.3729 - val_smape: 0.1490\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0738 - rmse: 0.2716 - mape: 62.2522 - smape: 0.2347 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.3181 - val_smape: 0.1499\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2698 - mape: 61.6539 - smape: 0.2308 - val_loss: 0.0232 - val_rmse: 0.1523 - val_mape: 17.2590 - val_smape: 0.1472\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2710 - mape: 62.1386 - smape: 0.2332 - val_loss: 0.0224 - val_rmse: 0.1495 - val_mape: 16.9684 - val_smape: 0.1444\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2695 - mape: 61.7830 - smape: 0.2291 - val_loss: 0.0231 - val_rmse: 0.1520 - val_mape: 17.3286 - val_smape: 0.1489\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2704 - mape: 62.1460 - smape: 0.2313 - val_loss: 0.0227 - val_rmse: 0.1507 - val_mape: 17.1560 - val_smape: 0.1468\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2705 - mape: 62.1755 - smape: 0.2324 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.2121 - val_smape: 0.1476\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2697 - mape: 61.9205 - smape: 0.2308 - val_loss: 0.0233 - val_rmse: 0.1525 - val_mape: 17.3660 - val_smape: 0.1491\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 62.3480 - smape: 0.2325 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.2774 - val_smape: 0.1490\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 61.6392 - smape: 0.2286 - val_loss: 0.0229 - val_rmse: 0.1512 - val_mape: 17.1764 - val_smape: 0.1467\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2697 - mape: 62.0843 - smape: 0.2295 - val_loss: 0.0233 - val_rmse: 0.1528 - val_mape: 17.4062 - val_smape: 0.1496\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2699 - mape: 62.0767 - smape: 0.2294 - val_loss: 0.0237 - val_rmse: 0.1538 - val_mape: 17.5947 - val_smape: 0.1525\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test MAPE: 271.372\n",
      "Test sMAPE: 91.313\n",
      "Test RMSE: 62.487\n",
      "{'mape': 271.37151127456735, 'smape': 91.31272733662351, 'rmse': 62.486594129958426}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1476 - rmse: 0.3841 - mape: 71.5714 - smape: 0.4018 - val_loss: 0.0285 - val_rmse: 0.1688 - val_mape: 18.8700 - val_smape: 0.1783\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0905 - rmse: 0.3008 - mape: 64.3249 - smape: 0.2813 - val_loss: 0.0284 - val_rmse: 0.1684 - val_mape: 19.2113 - val_smape: 0.1787\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0812 - rmse: 0.2849 - mape: 62.3633 - smape: 0.2590 - val_loss: 0.0254 - val_rmse: 0.1593 - val_mape: 18.3554 - val_smape: 0.1656\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0770 - rmse: 0.2776 - mape: 61.7041 - smape: 0.2487 - val_loss: 0.0233 - val_rmse: 0.1527 - val_mape: 17.5198 - val_smape: 0.1530\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0752 - rmse: 0.2743 - mape: 61.4568 - smape: 0.2430 - val_loss: 0.0221 - val_rmse: 0.1488 - val_mape: 16.8823 - val_smape: 0.1438\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0742 - rmse: 0.2724 - mape: 61.5803 - smape: 0.2399 - val_loss: 0.0214 - val_rmse: 0.1463 - val_mape: 16.3760 - val_smape: 0.1366\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 61.6761 - smape: 0.2378 - val_loss: 0.0213 - val_rmse: 0.1458 - val_mape: 16.0986 - val_smape: 0.1322\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2698 - mape: 61.2792 - smape: 0.2307 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.1859 - val_smape: 0.1467\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2704 - mape: 61.5697 - smape: 0.2312 - val_loss: 0.0234 - val_rmse: 0.1531 - val_mape: 17.4729 - val_smape: 0.1508\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0740 - rmse: 0.2720 - mape: 62.0900 - smape: 0.2337 - val_loss: 0.0233 - val_rmse: 0.1528 - val_mape: 17.5389 - val_smape: 0.1526\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2705 - mape: 61.7004 - smape: 0.2311 - val_loss: 0.0236 - val_rmse: 0.1538 - val_mape: 17.5933 - val_smape: 0.1526\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2712 - mape: 62.1805 - smape: 0.2326 - val_loss: 0.0233 - val_rmse: 0.1528 - val_mape: 17.4843 - val_smape: 0.1514\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2701 - mape: 61.7337 - smape: 0.2298 - val_loss: 0.0238 - val_rmse: 0.1544 - val_mape: 17.6892 - val_smape: 0.1540\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2701 - mape: 62.0028 - smape: 0.2289 - val_loss: 0.0241 - val_rmse: 0.1551 - val_mape: 17.8093 - val_smape: 0.1558\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 61.8790 - smape: 0.2290 - val_loss: 0.0236 - val_rmse: 0.1537 - val_mape: 17.5943 - val_smape: 0.1527\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2695 - mape: 61.8670 - smape: 0.2280 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.3047 - val_smape: 0.1490\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 62.0354 - smape: 0.2304 - val_loss: 0.0218 - val_rmse: 0.1475 - val_mape: 16.5681 - val_smape: 0.1387\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2703 - mape: 62.4222 - smape: 0.2341 - val_loss: 0.0204 - val_rmse: 0.1429 - val_mape: 15.6001 - val_smape: 0.1259\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2685 - mape: 61.8592 - smape: 0.2273 - val_loss: 0.0219 - val_rmse: 0.1480 - val_mape: 16.6155 - val_smape: 0.1389\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 62.1468 - smape: 0.2311 - val_loss: 0.0210 - val_rmse: 0.1450 - val_mape: 16.0329 - val_smape: 0.1314\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 62.0381 - smape: 0.2297 - val_loss: 0.0216 - val_rmse: 0.1469 - val_mape: 16.3678 - val_smape: 0.1354\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 61.8843 - smape: 0.2265 - val_loss: 0.0239 - val_rmse: 0.1546 - val_mape: 17.5763 - val_smape: 0.1510\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 62.2904 - smape: 0.2314 - val_loss: 0.0228 - val_rmse: 0.1509 - val_mape: 17.2233 - val_smape: 0.1479\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2697 - mape: 61.9400 - smape: 0.2287 - val_loss: 0.0241 - val_rmse: 0.1554 - val_mape: 17.7627 - val_smape: 0.1542\n",
      "Epoch 25/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2695 - mape: 62.1922 - smape: 0.2286 - val_loss: 0.0237 - val_rmse: 0.1538 - val_mape: 17.5093 - val_smape: 0.1505\n",
      "Epoch 26/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 62.1833 - smape: 0.2308 - val_loss: 0.0219 - val_rmse: 0.1478 - val_mape: 16.5000 - val_smape: 0.1367\n",
      "Epoch 27/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 62.4152 - smape: 0.2320 - val_loss: 0.0212 - val_rmse: 0.1455 - val_mape: 15.9727 - val_smape: 0.1295\n",
      "Epoch 28/50\n",
      "166/166 - 2s - loss: 0.0723 - rmse: 0.2689 - mape: 62.3452 - smape: 0.2301 - val_loss: 0.0213 - val_rmse: 0.1460 - val_mape: 15.9719 - val_smape: 0.1289\n",
      "Epoch 29/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2686 - mape: 62.2158 - smape: 0.2280 - val_loss: 0.0220 - val_rmse: 0.1482 - val_mape: 16.5361 - val_smape: 0.1368\n",
      "Epoch 30/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2686 - mape: 62.2406 - smape: 0.2298 - val_loss: 0.0223 - val_rmse: 0.1492 - val_mape: 16.5970 - val_smape: 0.1368\n",
      "Epoch 31/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2685 - mape: 62.0931 - smape: 0.2280 - val_loss: 0.0231 - val_rmse: 0.1521 - val_mape: 17.0925 - val_smape: 0.1432\n",
      "Epoch 32/50\n",
      "166/166 - 2s - loss: 0.0723 - rmse: 0.2689 - mape: 62.1331 - smape: 0.2266 - val_loss: 0.0247 - val_rmse: 0.1573 - val_mape: 17.8909 - val_smape: 0.1540\n",
      "Epoch 33/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2703 - mape: 62.4882 - smape: 0.2305 - val_loss: 0.0238 - val_rmse: 0.1544 - val_mape: 17.5067 - val_smape: 0.1494\n",
      "Epoch 34/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 61.9798 - smape: 0.2284 - val_loss: 0.0251 - val_rmse: 0.1583 - val_mape: 17.9890 - val_smape: 0.1550\n",
      "Epoch 35/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2698 - mape: 62.1506 - smape: 0.2284 - val_loss: 0.0236 - val_rmse: 0.1536 - val_mape: 17.3704 - val_smape: 0.1474\n",
      "Epoch 36/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 62.4006 - smape: 0.2324 - val_loss: 0.0222 - val_rmse: 0.1489 - val_mape: 16.3347 - val_smape: 0.1320\n",
      "Epoch 37/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2687 - mape: 62.4453 - smape: 0.2294 - val_loss: 0.0224 - val_rmse: 0.1496 - val_mape: 16.4508 - val_smape: 0.1332\n",
      "Epoch 38/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2685 - mape: 62.3671 - smape: 0.2293 - val_loss: 0.0230 - val_rmse: 0.1517 - val_mape: 16.6926 - val_smape: 0.1354\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "Test MAPE: 219.389\n",
      "Test sMAPE: 84.694\n",
      "Test RMSE: 59.957\n",
      "{'mape': 219.38900664585418, 'smape': 84.6937825477284, 'rmse': 59.95681407145918}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1431 - rmse: 0.3783 - mape: 70.3976 - smape: 0.3954 - val_loss: 0.0305 - val_rmse: 0.1748 - val_mape: 19.5094 - val_smape: 0.1864\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0889 - rmse: 0.2982 - mape: 63.6856 - smape: 0.2769 - val_loss: 0.0280 - val_rmse: 0.1674 - val_mape: 19.1288 - val_smape: 0.1769\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0801 - rmse: 0.2830 - mape: 61.8242 - smape: 0.2560 - val_loss: 0.0249 - val_rmse: 0.1579 - val_mape: 18.1864 - val_smape: 0.1627\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0763 - rmse: 0.2763 - mape: 61.5305 - smape: 0.2468 - val_loss: 0.0233 - val_rmse: 0.1527 - val_mape: 17.4834 - val_smape: 0.1520\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0746 - rmse: 0.2732 - mape: 61.3720 - smape: 0.2408 - val_loss: 0.0228 - val_rmse: 0.1508 - val_mape: 17.1387 - val_smape: 0.1466\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0738 - rmse: 0.2716 - mape: 61.3282 - smape: 0.2367 - val_loss: 0.0230 - val_rmse: 0.1515 - val_mape: 17.2147 - val_smape: 0.1474\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 61.4514 - smape: 0.2340 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.1785 - val_smape: 0.1465\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2714 - mape: 61.7530 - smape: 0.2356 - val_loss: 0.0234 - val_rmse: 0.1530 - val_mape: 17.4395 - val_smape: 0.1503\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0738 - rmse: 0.2717 - mape: 61.9624 - smape: 0.2351 - val_loss: 0.0234 - val_rmse: 0.1529 - val_mape: 17.4787 - val_smape: 0.1511\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0738 - rmse: 0.2717 - mape: 61.9973 - smape: 0.2347 - val_loss: 0.0233 - val_rmse: 0.1527 - val_mape: 17.4726 - val_smape: 0.1512\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0739 - rmse: 0.2718 - mape: 62.1643 - smape: 0.2356 - val_loss: 0.0232 - val_rmse: 0.1523 - val_mape: 17.5032 - val_smape: 0.1525\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2695 - mape: 61.5858 - smape: 0.2314 - val_loss: 0.0230 - val_rmse: 0.1515 - val_mape: 17.1262 - val_smape: 0.1454\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2705 - mape: 61.9101 - smape: 0.2313 - val_loss: 0.0234 - val_rmse: 0.1531 - val_mape: 17.4811 - val_smape: 0.1510\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 62.1136 - smape: 0.2324 - val_loss: 0.0231 - val_rmse: 0.1521 - val_mape: 17.4124 - val_smape: 0.1507\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2704 - mape: 62.0154 - smape: 0.2329 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.3093 - val_smape: 0.1490\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2703 - mape: 61.9945 - smape: 0.2320 - val_loss: 0.0235 - val_rmse: 0.1532 - val_mape: 17.4639 - val_smape: 0.1504\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 62.2084 - smape: 0.2324 - val_loss: 0.0232 - val_rmse: 0.1522 - val_mape: 17.3691 - val_smape: 0.1496\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 61.7758 - smape: 0.2296 - val_loss: 0.0240 - val_rmse: 0.1551 - val_mape: 17.6769 - val_smape: 0.1527\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 62.2374 - smape: 0.2319 - val_loss: 0.0231 - val_rmse: 0.1520 - val_mape: 17.2648 - val_smape: 0.1475\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 61.6978 - smape: 0.2282 - val_loss: 0.0235 - val_rmse: 0.1532 - val_mape: 17.5109 - val_smape: 0.1514\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2699 - mape: 62.1535 - smape: 0.2282 - val_loss: 0.0243 - val_rmse: 0.1560 - val_mape: 17.8768 - val_smape: 0.1561\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2713 - mape: 62.4474 - smape: 0.2319 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.2310 - val_smape: 0.1480\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2698 - mape: 62.2027 - smape: 0.2341 - val_loss: 0.0209 - val_rmse: 0.1446 - val_mape: 15.9047 - val_smape: 0.1294\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2697 - mape: 62.4285 - smape: 0.2320 - val_loss: 0.0208 - val_rmse: 0.1442 - val_mape: 15.6346 - val_smape: 0.1251\n",
      "Epoch 25/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2683 - mape: 62.0424 - smape: 0.2273 - val_loss: 0.0221 - val_rmse: 0.1486 - val_mape: 16.4806 - val_smape: 0.1355\n",
      "Epoch 26/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2683 - mape: 61.8583 - smape: 0.2275 - val_loss: 0.0232 - val_rmse: 0.1523 - val_mape: 17.1025 - val_smape: 0.1434\n",
      "Epoch 27/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2686 - mape: 62.0112 - smape: 0.2281 - val_loss: 0.0237 - val_rmse: 0.1540 - val_mape: 17.2774 - val_smape: 0.1450\n",
      "Epoch 28/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 62.1400 - smape: 0.2292 - val_loss: 0.0239 - val_rmse: 0.1547 - val_mape: 17.4962 - val_smape: 0.1490\n",
      "Epoch 29/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2697 - mape: 62.1374 - smape: 0.2303 - val_loss: 0.0238 - val_rmse: 0.1542 - val_mape: 17.4904 - val_smape: 0.1495\n",
      "Epoch 30/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2699 - mape: 62.2353 - smape: 0.2318 - val_loss: 0.0238 - val_rmse: 0.1544 - val_mape: 17.5040 - val_smape: 0.1494\n",
      "Epoch 31/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2693 - mape: 61.9478 - smape: 0.2283 - val_loss: 0.0245 - val_rmse: 0.1566 - val_mape: 17.7461 - val_smape: 0.1519\n",
      "Epoch 32/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2704 - mape: 62.0714 - smape: 0.2280 - val_loss: 0.0248 - val_rmse: 0.1575 - val_mape: 17.9244 - val_smape: 0.1549\n",
      "Epoch 33/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2695 - mape: 62.0494 - smape: 0.2287 - val_loss: 0.0234 - val_rmse: 0.1529 - val_mape: 17.2362 - val_smape: 0.1455\n",
      "Epoch 34/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 62.3225 - smape: 0.2331 - val_loss: 0.0222 - val_rmse: 0.1491 - val_mape: 16.1384 - val_smape: 0.1285\n",
      "Epoch 35/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 62.4677 - smape: 0.2301 - val_loss: 0.0223 - val_rmse: 0.1494 - val_mape: 16.2956 - val_smape: 0.1308\n",
      "Epoch 36/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2690 - mape: 62.3084 - smape: 0.2301 - val_loss: 0.0227 - val_rmse: 0.1507 - val_mape: 16.4964 - val_smape: 0.1329\n",
      "Epoch 37/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2684 - mape: 62.1219 - smape: 0.2291 - val_loss: 0.0238 - val_rmse: 0.1544 - val_mape: 17.1000 - val_smape: 0.1402\n",
      "Epoch 38/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2687 - mape: 62.2469 - smape: 0.2308 - val_loss: 0.0242 - val_rmse: 0.1556 - val_mape: 17.2396 - val_smape: 0.1415\n",
      "Epoch 39/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2692 - mape: 62.2553 - smape: 0.2313 - val_loss: 0.0243 - val_rmse: 0.1558 - val_mape: 17.1875 - val_smape: 0.1399\n",
      "Epoch 40/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2686 - mape: 62.1083 - smape: 0.2301 - val_loss: 0.0247 - val_rmse: 0.1572 - val_mape: 17.4340 - val_smape: 0.1434\n",
      "Epoch 41/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2684 - mape: 62.1199 - smape: 0.2305 - val_loss: 0.0251 - val_rmse: 0.1585 - val_mape: 17.5885 - val_smape: 0.1447\n",
      "Epoch 42/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2687 - mape: 62.0859 - smape: 0.2299 - val_loss: 0.0255 - val_rmse: 0.1598 - val_mape: 17.7811 - val_smape: 0.1473\n",
      "Epoch 43/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2687 - mape: 61.9658 - smape: 0.2304 - val_loss: 0.0254 - val_rmse: 0.1593 - val_mape: 17.7363 - val_smape: 0.1472\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00043: early stopping\n",
      "Test MAPE: 229.596\n",
      "Test sMAPE: 86.126\n",
      "Test RMSE: 60.677\n",
      "{'mape': 229.5962079915623, 'smape': 86.12625375281135, 'rmse': 60.676627616921365}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1420 - rmse: 0.3768 - mape: 70.2894 - smape: 0.3917 - val_loss: 0.0283 - val_rmse: 0.1683 - val_mape: 18.8559 - val_smape: 0.1781\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0882 - rmse: 0.2970 - mape: 63.7010 - smape: 0.2764 - val_loss: 0.0280 - val_rmse: 0.1672 - val_mape: 19.0762 - val_smape: 0.1758\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0792 - rmse: 0.2814 - mape: 62.1309 - smape: 0.2557 - val_loss: 0.0240 - val_rmse: 0.1548 - val_mape: 17.7721 - val_smape: 0.1569\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0762 - rmse: 0.2760 - mape: 61.5047 - smape: 0.2467 - val_loss: 0.0224 - val_rmse: 0.1498 - val_mape: 17.0183 - val_smape: 0.1458\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0744 - rmse: 0.2728 - mape: 61.2994 - smape: 0.2400 - val_loss: 0.0227 - val_rmse: 0.1508 - val_mape: 17.0969 - val_smape: 0.1460\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0738 - rmse: 0.2716 - mape: 61.4085 - smape: 0.2371 - val_loss: 0.0219 - val_rmse: 0.1479 - val_mape: 16.5572 - val_smape: 0.1385\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2704 - mape: 61.3302 - smape: 0.2333 - val_loss: 0.0231 - val_rmse: 0.1520 - val_mape: 17.2403 - val_smape: 0.1475\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2712 - mape: 61.6752 - smape: 0.2334 - val_loss: 0.0234 - val_rmse: 0.1531 - val_mape: 17.4290 - val_smape: 0.1500\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0744 - rmse: 0.2728 - mape: 62.3289 - smape: 0.2372 - val_loss: 0.0228 - val_rmse: 0.1512 - val_mape: 17.3352 - val_smape: 0.1502\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2698 - mape: 61.4995 - smape: 0.2316 - val_loss: 0.0230 - val_rmse: 0.1515 - val_mape: 17.1798 - val_smape: 0.1466\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0738 - rmse: 0.2717 - mape: 62.0708 - smape: 0.2339 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.2835 - val_smape: 0.1491\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2701 - mape: 61.8035 - smape: 0.2322 - val_loss: 0.0231 - val_rmse: 0.1520 - val_mape: 17.2996 - val_smape: 0.1484\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2715 - mape: 62.3178 - smape: 0.2351 - val_loss: 0.0229 - val_rmse: 0.1514 - val_mape: 17.3658 - val_smape: 0.1506\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 61.7603 - smape: 0.2309 - val_loss: 0.0234 - val_rmse: 0.1531 - val_mape: 17.4132 - val_smape: 0.1495\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 62.1297 - smape: 0.2324 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.1973 - val_smape: 0.1473\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2695 - mape: 61.7210 - smape: 0.2290 - val_loss: 0.0235 - val_rmse: 0.1532 - val_mape: 17.4528 - val_smape: 0.1502\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2713 - mape: 62.4594 - smape: 0.2333 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.3044 - val_smape: 0.1496\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 61.7636 - smape: 0.2292 - val_loss: 0.0233 - val_rmse: 0.1527 - val_mape: 17.4235 - val_smape: 0.1502\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2701 - mape: 62.1293 - smape: 0.2290 - val_loss: 0.0237 - val_rmse: 0.1540 - val_mape: 17.6287 - val_smape: 0.1531\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2703 - mape: 62.2192 - smape: 0.2308 - val_loss: 0.0229 - val_rmse: 0.1514 - val_mape: 17.2649 - val_smape: 0.1483\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 61.9807 - smape: 0.2294 - val_loss: 0.0238 - val_rmse: 0.1543 - val_mape: 17.6413 - val_smape: 0.1529\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2702 - mape: 62.2349 - smape: 0.2297 - val_loss: 0.0235 - val_rmse: 0.1533 - val_mape: 17.5392 - val_smape: 0.1520\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 62.0650 - smape: 0.2281 - val_loss: 0.0244 - val_rmse: 0.1561 - val_mape: 17.8860 - val_smape: 0.1563\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2701 - mape: 62.1909 - smape: 0.2292 - val_loss: 0.0235 - val_rmse: 0.1532 - val_mape: 17.4728 - val_smape: 0.1504\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test MAPE: 273.876\n",
      "Test sMAPE: 91.738\n",
      "Test RMSE: 62.825\n",
      "{'mape': 273.8756228515507, 'smape': 91.73765248362838, 'rmse': 62.824899583908675}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1454 - rmse: 0.3813 - mape: 71.7539 - smape: 0.3984 - val_loss: 0.0277 - val_rmse: 0.1665 - val_mape: 18.7257 - val_smape: 0.1759\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0887 - rmse: 0.2978 - mape: 63.6107 - smape: 0.2762 - val_loss: 0.0275 - val_rmse: 0.1658 - val_mape: 18.9884 - val_smape: 0.1747\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0793 - rmse: 0.2817 - mape: 62.2048 - smape: 0.2547 - val_loss: 0.0237 - val_rmse: 0.1540 - val_mape: 17.7092 - val_smape: 0.1562\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0760 - rmse: 0.2757 - mape: 61.6510 - smape: 0.2458 - val_loss: 0.0226 - val_rmse: 0.1502 - val_mape: 17.1087 - val_smape: 0.1469\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0743 - rmse: 0.2726 - mape: 61.4844 - smape: 0.2401 - val_loss: 0.0218 - val_rmse: 0.1475 - val_mape: 16.5631 - val_smape: 0.1390\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2713 - mape: 61.4287 - smape: 0.2370 - val_loss: 0.0214 - val_rmse: 0.1463 - val_mape: 16.2360 - val_smape: 0.1342\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 61.3350 - smape: 0.2319 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.1985 - val_smape: 0.1469\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2714 - mape: 61.8700 - smape: 0.2345 - val_loss: 0.0233 - val_rmse: 0.1527 - val_mape: 17.4886 - val_smape: 0.1516\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0740 - rmse: 0.2721 - mape: 62.2468 - smape: 0.2362 - val_loss: 0.0230 - val_rmse: 0.1518 - val_mape: 17.4367 - val_smape: 0.1517\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2710 - mape: 61.9113 - smape: 0.2348 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.3049 - val_smape: 0.1490\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2715 - mape: 62.1663 - smape: 0.2355 - val_loss: 0.0229 - val_rmse: 0.1512 - val_mape: 17.3690 - val_smape: 0.1508\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 61.5608 - smape: 0.2307 - val_loss: 0.0229 - val_rmse: 0.1513 - val_mape: 17.0745 - val_smape: 0.1447\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 61.9211 - smape: 0.2309 - val_loss: 0.0234 - val_rmse: 0.1530 - val_mape: 17.4766 - val_smape: 0.1510\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 62.2195 - smape: 0.2335 - val_loss: 0.0227 - val_rmse: 0.1506 - val_mape: 17.2555 - val_smape: 0.1491\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 61.6763 - smape: 0.2301 - val_loss: 0.0223 - val_rmse: 0.1494 - val_mape: 16.8529 - val_smape: 0.1423\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 61.8356 - smape: 0.2294 - val_loss: 0.0222 - val_rmse: 0.1491 - val_mape: 16.8198 - val_smape: 0.1418\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 62.1010 - smape: 0.2332 - val_loss: 0.0208 - val_rmse: 0.1443 - val_mape: 15.8777 - val_smape: 0.1293\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 61.9994 - smape: 0.2305 - val_loss: 0.0211 - val_rmse: 0.1451 - val_mape: 16.0667 - val_smape: 0.1318\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0723 - rmse: 0.2688 - mape: 61.7076 - smape: 0.2279 - val_loss: 0.0219 - val_rmse: 0.1480 - val_mape: 16.6786 - val_smape: 0.1402\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2704 - mape: 62.1984 - smape: 0.2316 - val_loss: 0.0223 - val_rmse: 0.1494 - val_mape: 17.0373 - val_smape: 0.1458\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2707 - mape: 62.2106 - smape: 0.2334 - val_loss: 0.0227 - val_rmse: 0.1505 - val_mape: 17.1592 - val_smape: 0.1471\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 62.2633 - smape: 0.2333 - val_loss: 0.0226 - val_rmse: 0.1503 - val_mape: 17.0897 - val_smape: 0.1459\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2696 - mape: 62.1131 - smape: 0.2315 - val_loss: 0.0232 - val_rmse: 0.1524 - val_mape: 17.3288 - val_smape: 0.1484\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 62.2786 - smape: 0.2318 - val_loss: 0.0231 - val_rmse: 0.1521 - val_mape: 17.4000 - val_smape: 0.1504\n",
      "Epoch 25/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2703 - mape: 62.1913 - smape: 0.2330 - val_loss: 0.0227 - val_rmse: 0.1508 - val_mape: 17.1649 - val_smape: 0.1469\n",
      "Epoch 26/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2695 - mape: 61.7558 - smape: 0.2279 - val_loss: 0.0243 - val_rmse: 0.1557 - val_mape: 17.8679 - val_smape: 0.1563\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test MAPE: 242.044\n",
      "Test sMAPE: 87.734\n",
      "Test RMSE: 61.359\n",
      "{'mape': 242.0435692847069, 'smape': 87.73372436358409, 'rmse': 61.35942711266776}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1406 - rmse: 0.3750 - mape: 69.3532 - smape: 0.3917 - val_loss: 0.0289 - val_rmse: 0.1699 - val_mape: 19.0601 - val_smape: 0.1801\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0877 - rmse: 0.2961 - mape: 63.4938 - smape: 0.2738 - val_loss: 0.0277 - val_rmse: 0.1664 - val_mape: 19.0593 - val_smape: 0.1759\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0790 - rmse: 0.2810 - mape: 62.0385 - smape: 0.2534 - val_loss: 0.0237 - val_rmse: 0.1540 - val_mape: 17.7386 - val_smape: 0.1569\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0757 - rmse: 0.2752 - mape: 61.5565 - smape: 0.2447 - val_loss: 0.0225 - val_rmse: 0.1499 - val_mape: 17.1096 - val_smape: 0.1472\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0743 - rmse: 0.2725 - mape: 61.4219 - smape: 0.2399 - val_loss: 0.0217 - val_rmse: 0.1474 - val_mape: 16.6114 - val_smape: 0.1400\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2715 - mape: 61.3234 - smape: 0.2349 - val_loss: 0.0230 - val_rmse: 0.1518 - val_mape: 17.3334 - val_smape: 0.1495\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2712 - mape: 61.6102 - smape: 0.2342 - val_loss: 0.0232 - val_rmse: 0.1525 - val_mape: 17.4015 - val_smape: 0.1501\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2715 - mape: 61.8997 - smape: 0.2351 - val_loss: 0.0232 - val_rmse: 0.1522 - val_mape: 17.3970 - val_smape: 0.1502\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 61.8290 - smape: 0.2337 - val_loss: 0.0230 - val_rmse: 0.1518 - val_mape: 17.3393 - val_smape: 0.1495\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0738 - rmse: 0.2717 - mape: 62.1520 - smape: 0.2344 - val_loss: 0.0230 - val_rmse: 0.1518 - val_mape: 17.4347 - val_smape: 0.1517\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2700 - mape: 61.5889 - smape: 0.2312 - val_loss: 0.0231 - val_rmse: 0.1520 - val_mape: 17.3097 - val_smape: 0.1487\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0739 - rmse: 0.2718 - mape: 62.1980 - smape: 0.2336 - val_loss: 0.0227 - val_rmse: 0.1506 - val_mape: 17.2895 - val_smape: 0.1500\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2693 - mape: 61.6008 - smape: 0.2296 - val_loss: 0.0227 - val_rmse: 0.1507 - val_mape: 17.1431 - val_smape: 0.1466\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2703 - mape: 62.1006 - smape: 0.2315 - val_loss: 0.0230 - val_rmse: 0.1515 - val_mape: 17.3030 - val_smape: 0.1490\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2707 - mape: 62.1128 - smape: 0.2320 - val_loss: 0.0228 - val_rmse: 0.1511 - val_mape: 17.3173 - val_smape: 0.1500\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 61.6539 - smape: 0.2292 - val_loss: 0.0232 - val_rmse: 0.1524 - val_mape: 17.3732 - val_smape: 0.1494\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2707 - mape: 62.2412 - smape: 0.2318 - val_loss: 0.0224 - val_rmse: 0.1497 - val_mape: 17.0902 - val_smape: 0.1467\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2699 - mape: 61.9909 - smape: 0.2303 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.3517 - val_smape: 0.1500\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2701 - mape: 62.2163 - smape: 0.2305 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.2600 - val_smape: 0.1488\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2693 - mape: 61.7705 - smape: 0.2279 - val_loss: 0.0237 - val_rmse: 0.1540 - val_mape: 17.6610 - val_smape: 0.1538\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2705 - mape: 62.2759 - smape: 0.2293 - val_loss: 0.0231 - val_rmse: 0.1519 - val_mape: 17.4165 - val_smape: 0.1511\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0732 - rmse: 0.2706 - mape: 62.4695 - smape: 0.2316 - val_loss: 0.0223 - val_rmse: 0.1494 - val_mape: 17.0544 - val_smape: 0.1462\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2686 - mape: 61.7756 - smape: 0.2282 - val_loss: 0.0222 - val_rmse: 0.1489 - val_mape: 16.9014 - val_smape: 0.1437\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2683 - mape: 61.9507 - smape: 0.2274 - val_loss: 0.0221 - val_rmse: 0.1487 - val_mape: 16.8160 - val_smape: 0.1422\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test MAPE: 280.699\n",
      "Test sMAPE: 92.249\n",
      "Test RMSE: 62.894\n",
      "{'mape': 280.69865034281617, 'smape': 92.24903832243248, 'rmse': 62.89414085557106}\n",
      "Epoch 1/50\n",
      "166/166 - 5s - loss: 0.1469 - rmse: 0.3833 - mape: 71.6609 - smape: 0.3999 - val_loss: 0.0304 - val_rmse: 0.1744 - val_mape: 19.4564 - val_smape: 0.1856\n",
      "Epoch 2/50\n",
      "166/166 - 2s - loss: 0.0889 - rmse: 0.2982 - mape: 63.3582 - smape: 0.2775 - val_loss: 0.0279 - val_rmse: 0.1670 - val_mape: 19.0933 - val_smape: 0.1767\n",
      "Epoch 3/50\n",
      "166/166 - 2s - loss: 0.0800 - rmse: 0.2829 - mape: 62.1478 - smape: 0.2565 - val_loss: 0.0248 - val_rmse: 0.1573 - val_mape: 18.1148 - val_smape: 0.1618\n",
      "Epoch 4/50\n",
      "166/166 - 2s - loss: 0.0764 - rmse: 0.2764 - mape: 61.5704 - smape: 0.2469 - val_loss: 0.0240 - val_rmse: 0.1551 - val_mape: 17.8047 - val_smape: 0.1565\n",
      "Epoch 5/50\n",
      "166/166 - 2s - loss: 0.0752 - rmse: 0.2742 - mape: 61.6837 - smape: 0.2430 - val_loss: 0.0218 - val_rmse: 0.1478 - val_mape: 16.6863 - val_smape: 0.1410\n",
      "Epoch 6/50\n",
      "166/166 - 2s - loss: 0.0740 - rmse: 0.2720 - mape: 61.6674 - smape: 0.2394 - val_loss: 0.0216 - val_rmse: 0.1470 - val_mape: 16.3898 - val_smape: 0.1363\n",
      "Epoch 7/50\n",
      "166/166 - 2s - loss: 0.0731 - rmse: 0.2704 - mape: 61.4926 - smape: 0.2353 - val_loss: 0.0218 - val_rmse: 0.1478 - val_mape: 16.4212 - val_smape: 0.1361\n",
      "Epoch 8/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2703 - mape: 61.3983 - smape: 0.2313 - val_loss: 0.0232 - val_rmse: 0.1523 - val_mape: 17.2760 - val_smape: 0.1478\n",
      "Epoch 9/50\n",
      "166/166 - 2s - loss: 0.0740 - rmse: 0.2721 - mape: 62.0861 - smape: 0.2358 - val_loss: 0.0232 - val_rmse: 0.1524 - val_mape: 17.5106 - val_smape: 0.1525\n",
      "Epoch 10/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2712 - mape: 61.9796 - smape: 0.2351 - val_loss: 0.0232 - val_rmse: 0.1523 - val_mape: 17.3379 - val_smape: 0.1489\n",
      "Epoch 11/50\n",
      "166/166 - 2s - loss: 0.0734 - rmse: 0.2709 - mape: 61.8235 - smape: 0.2325 - val_loss: 0.0234 - val_rmse: 0.1531 - val_mape: 17.4744 - val_smape: 0.1508\n",
      "Epoch 12/50\n",
      "166/166 - 2s - loss: 0.0737 - rmse: 0.2714 - mape: 62.1935 - smape: 0.2338 - val_loss: 0.0231 - val_rmse: 0.1519 - val_mape: 17.4453 - val_smape: 0.1517\n",
      "Epoch 13/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2693 - mape: 61.5361 - smape: 0.2301 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.1576 - val_smape: 0.1460\n",
      "Epoch 14/50\n",
      "166/166 - 2s - loss: 0.0730 - rmse: 0.2702 - mape: 61.7874 - smape: 0.2297 - val_loss: 0.0236 - val_rmse: 0.1537 - val_mape: 17.5594 - val_smape: 0.1519\n",
      "Epoch 15/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2714 - mape: 62.2442 - smape: 0.2323 - val_loss: 0.0227 - val_rmse: 0.1505 - val_mape: 17.2119 - val_smape: 0.1482\n",
      "Epoch 16/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2697 - mape: 61.7993 - smape: 0.2302 - val_loss: 0.0237 - val_rmse: 0.1540 - val_mape: 17.6245 - val_smape: 0.1529\n",
      "Epoch 17/50\n",
      "166/166 - 2s - loss: 0.0733 - rmse: 0.2707 - mape: 62.2358 - smape: 0.2322 - val_loss: 0.0229 - val_rmse: 0.1513 - val_mape: 17.2453 - val_smape: 0.1481\n",
      "Epoch 18/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 61.6712 - smape: 0.2283 - val_loss: 0.0228 - val_rmse: 0.1510 - val_mape: 17.1738 - val_smape: 0.1468\n",
      "Epoch 19/50\n",
      "166/166 - 2s - loss: 0.0728 - rmse: 0.2699 - mape: 61.9750 - smape: 0.2283 - val_loss: 0.0240 - val_rmse: 0.1548 - val_mape: 17.7339 - val_smape: 0.1545\n",
      "Epoch 20/50\n",
      "166/166 - 2s - loss: 0.0735 - rmse: 0.2711 - mape: 62.3769 - smape: 0.2324 - val_loss: 0.0225 - val_rmse: 0.1499 - val_mape: 17.0947 - val_smape: 0.1466\n",
      "Epoch 21/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 61.8812 - smape: 0.2303 - val_loss: 0.0218 - val_rmse: 0.1476 - val_mape: 16.6508 - val_smape: 0.1401\n",
      "Epoch 22/50\n",
      "166/166 - 2s - loss: 0.0723 - rmse: 0.2689 - mape: 62.1423 - smape: 0.2312 - val_loss: 0.0213 - val_rmse: 0.1458 - val_mape: 16.1540 - val_smape: 0.1325\n",
      "Epoch 23/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2692 - mape: 62.2691 - smape: 0.2317 - val_loss: 0.0206 - val_rmse: 0.1437 - val_mape: 15.6994 - val_smape: 0.1268\n",
      "Epoch 24/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2687 - mape: 61.8823 - smape: 0.2269 - val_loss: 0.0222 - val_rmse: 0.1491 - val_mape: 16.7912 - val_smape: 0.1410\n",
      "Epoch 25/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 62.0520 - smape: 0.2279 - val_loss: 0.0234 - val_rmse: 0.1530 - val_mape: 17.4177 - val_smape: 0.1495\n",
      "Epoch 26/50\n",
      "166/166 - 2s - loss: 0.0736 - rmse: 0.2714 - mape: 62.5016 - smape: 0.2329 - val_loss: 0.0229 - val_rmse: 0.1514 - val_mape: 17.2792 - val_smape: 0.1486\n",
      "Epoch 27/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2693 - mape: 61.7674 - smape: 0.2280 - val_loss: 0.0236 - val_rmse: 0.1538 - val_mape: 17.5439 - val_smape: 0.1514\n",
      "Epoch 28/50\n",
      "166/166 - 2s - loss: 0.0726 - rmse: 0.2694 - mape: 62.0952 - smape: 0.2268 - val_loss: 0.0238 - val_rmse: 0.1543 - val_mape: 17.6243 - val_smape: 0.1524\n",
      "Epoch 29/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2701 - mape: 62.1319 - smape: 0.2275 - val_loss: 0.0244 - val_rmse: 0.1562 - val_mape: 17.9113 - val_smape: 0.1567\n",
      "Epoch 30/50\n",
      "166/166 - 2s - loss: 0.0729 - rmse: 0.2701 - mape: 62.0601 - smape: 0.2272 - val_loss: 0.0242 - val_rmse: 0.1556 - val_mape: 17.8579 - val_smape: 0.1563\n",
      "Epoch 31/50\n",
      "166/166 - 2s - loss: 0.0724 - rmse: 0.2691 - mape: 62.0948 - smape: 0.2278 - val_loss: 0.0230 - val_rmse: 0.1516 - val_mape: 17.1727 - val_smape: 0.1458\n",
      "Epoch 32/50\n",
      "166/166 - 2s - loss: 0.0727 - rmse: 0.2697 - mape: 62.3609 - smape: 0.2330 - val_loss: 0.0210 - val_rmse: 0.1449 - val_mape: 15.8059 - val_smape: 0.1271\n",
      "Epoch 33/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2685 - mape: 62.3347 - smape: 0.2289 - val_loss: 0.0219 - val_rmse: 0.1479 - val_mape: 16.2596 - val_smape: 0.1319\n",
      "Epoch 34/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2686 - mape: 62.2194 - smape: 0.2301 - val_loss: 0.0221 - val_rmse: 0.1488 - val_mape: 16.3204 - val_smape: 0.1319\n",
      "Epoch 35/50\n",
      "166/166 - 2s - loss: 0.0718 - rmse: 0.2679 - mape: 62.1163 - smape: 0.2264 - val_loss: 0.0240 - val_rmse: 0.1549 - val_mape: 17.4245 - val_smape: 0.1464\n",
      "Epoch 36/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2683 - mape: 61.9717 - smape: 0.2281 - val_loss: 0.0246 - val_rmse: 0.1568 - val_mape: 17.6190 - val_smape: 0.1480\n",
      "Epoch 37/50\n",
      "166/166 - 2s - loss: 0.0723 - rmse: 0.2689 - mape: 62.0127 - smape: 0.2282 - val_loss: 0.0247 - val_rmse: 0.1573 - val_mape: 17.6953 - val_smape: 0.1492\n",
      "Epoch 38/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2683 - mape: 61.9625 - smape: 0.2276 - val_loss: 0.0250 - val_rmse: 0.1583 - val_mape: 17.7729 - val_smape: 0.1496\n",
      "Epoch 39/50\n",
      "166/166 - 2s - loss: 0.0725 - rmse: 0.2693 - mape: 62.1283 - smape: 0.2320 - val_loss: 0.0238 - val_rmse: 0.1542 - val_mape: 17.1245 - val_smape: 0.1409\n",
      "Epoch 40/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2684 - mape: 62.0997 - smape: 0.2305 - val_loss: 0.0238 - val_rmse: 0.1542 - val_mape: 17.0215 - val_smape: 0.1388\n",
      "Epoch 41/50\n",
      "166/166 - 2s - loss: 0.0722 - rmse: 0.2686 - mape: 62.3938 - smape: 0.2305 - val_loss: 0.0239 - val_rmse: 0.1547 - val_mape: 17.2067 - val_smape: 0.1419\n",
      "Epoch 42/50\n",
      "166/166 - 2s - loss: 0.0720 - rmse: 0.2684 - mape: 62.0776 - smape: 0.2293 - val_loss: 0.0244 - val_rmse: 0.1561 - val_mape: 17.3389 - val_smape: 0.1430\n",
      "Epoch 43/50\n",
      "166/166 - 2s - loss: 0.0721 - rmse: 0.2686 - mape: 62.1627 - smape: 0.2301 - val_loss: 0.0244 - val_rmse: 0.1562 - val_mape: 17.3851 - val_smape: 0.1439\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00043: early stopping\n",
      "Test MAPE: 221.290\n",
      "Test sMAPE: 85.108\n",
      "Test RMSE: 60.271\n",
      "{'mape': 221.28984488280574, 'smape': 85.10795158406694, 'rmse': 60.270698933786505}\n",
      "rmse : average=61.691, std=1.032\n",
      "mape : average=252.563, std=21.689\n",
      "smape : average=88.976, std=2.709\n"
     ]
    }
   ],
   "source": [
    "calculate_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa900b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
